{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-18 10:41:45.517562: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-11-18 10:41:45.520622: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-11-18 10:41:45.529609: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1731926505.545386   24736 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1731926505.549224   24736 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-11-18 10:41:45.563295: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, roc_auc_score, roc_curve, auc, f1_score, precision_score, recall_score\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "\n",
    "import nltk\n",
    "import mlflow\n",
    "from transformers import TFAutoModelForSequenceClassification, AutoTokenizer\n",
    "\n",
    "import re\n",
    "import time\n",
    "from gensim.models import Word2Vec, FastText\n",
    "from gensim.models import KeyedVectors\n",
    "from transformers import BertTokenizer, TFBertModel\n",
    "\n",
    "import tensorflow_hub as hub\n",
    "\n",
    "import pickle\n",
    "import requests\n",
    "import zipfile\n",
    "import os\n",
    "\n",
    "import mlflow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numpy version: 1.26.4\n",
      "TensorFlow version: 2.18.0\n",
      "Gensim version: 4.3.3\n",
      "Numba version: 0.60.0\n"
     ]
    }
   ],
   "source": [
    "import numpy\n",
    "import tensorflow\n",
    "import gensim\n",
    "import numba\n",
    "print(\"Numpy version:\", numpy.__version__)\n",
    "print(\"TensorFlow version:\", tensorflow.__version__)\n",
    "print(\"Gensim version:\", gensim.__version__)\n",
    "print(\"Numba version:\", numba.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Définir un nouveau répertoire de suivi, par exemple, un dossier spécifique pour les expériences MLflow\n",
    "tracking_dir = \"/tmp/mlruns\"  # Vous pouvez choisir un autre répertoire si nécessaire\n",
    "os.makedirs(tracking_dir, exist_ok=True)  # Crée le dossier s'il n'existe pas\n",
    "\n",
    "#mlflow.set_tracking_uri(f\"file://{tracking_dir}\")\n",
    "mlflow.set_tracking_uri(\"http://mlflow-server:5000\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 20000 entries, 0 to 19999\n",
      "Data columns (total 6 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   target  20000 non-null  int64 \n",
      " 1   ids     20000 non-null  int64 \n",
      " 2   date    20000 non-null  object\n",
      " 3   flag    20000 non-null  object\n",
      " 4   user    20000 non-null  object\n",
      " 5   text    20000 non-null  object\n",
      "dtypes: int64(2), object(4)\n",
      "memory usage: 937.6+ KB\n"
     ]
    }
   ],
   "source": [
    "# Recharger le DataFrame depuis le fichier pickle\n",
    "df = pd.read_pickle('download/df_sample_20000.pkl')\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "target\n",
       "0    10000\n",
       "1    10000\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    " #Vérifier si le DataFrame a au moins 16 000 lignes\n",
    "if len(df) != 20000:\n",
    "    raise ValueError(\"Le DataFrame ne contient pas de 20 000 lignes.\")\n",
    "\n",
    "# # Calculer la proportion nécessaire pour obtenir 16 000 lignes\n",
    "# sample_size = 16000 / len(df_sample)\n",
    "\n",
    "# # Utiliser train_test_split pour sélectionner un échantillon équilibré de 16 000 lignes\n",
    "# df_16000, _ = train_test_split(df_sample, train_size=sample_size, stratify=df_sample['target'], random_state=42)\n",
    "\n",
    "# # Vérifier le nombre d'éléments et l'équilibre des classes\n",
    "# print(f\"Nombre d'échantillons conservés: {len(df_16000)}\")\n",
    "# print(df_16000['target'].value_counts(normalize=True))  # Vérifier l'équilibre des classes\n",
    "df_sample = df\n",
    "display(df['target'].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Créer un histogramme des valeurs de la colonne 'target' avec des étiquettes spécifiques et le nombre total de valeurs\n",
    "\n",
    "# Compter les occurrences de chaque valeur unique dans 'target' avec les valeurs 0, 1\n",
    "target_counts = df_sample['target'].value_counts().reindex([0, 1], fill_value=0)\n",
    "\n",
    "# Configurer le graphique\n",
    "plt.figure(figsize=(8, 6))\n",
    "bars = plt.bar(['Negative (0)', 'Positive (1)'], target_counts, color='skyblue', edgecolor='black')\n",
    "\n",
    "# Ajouter les annotations (le nombre total au-dessus de chaque colonne)\n",
    "for bar, count in zip(bars, target_counts):\n",
    "    plt.text(bar.get_x() + bar.get_width() / 2, bar.get_height(), f'{count}', ha='center', va='bottom', fontsize=12)\n",
    "\n",
    "# Personnaliser l'apparence du graphique\n",
    "plt.title(\"Distribution des valeurs de la colonne 'target'\")\n",
    "plt.xlabel(\"Polarity of Tweet\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classe de prétraitement et vectorisation des tweets avec différentes méthodes\n",
    "types_of_embeddings = ['w2v', 'fasttext', 'bert', 'use']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classe de prétraitement et vectorisation des tweets avec différentes méthodes\n",
    "class TweetVectorizer:\n",
    "    def __init__(self, vectorizer_type='w2v', method='lemmatize'):\n",
    "        self.vectorizer_type = vectorizer_type\n",
    "        self.method = method\n",
    "        self.stemmer = PorterStemmer()\n",
    "        self.lemmatizer = WordNetLemmatizer()\n",
    "        \n",
    "        # Initialiser le vectorizer en fonction du type\n",
    "        if vectorizer_type == 'w2v':\n",
    "            self.model = None  # Placeholder pour Word2Vec qui sera entraîné explicitement\n",
    "        elif vectorizer_type == 'fasttext':\n",
    "            self.fasttext_model = FastText(vector_size=100, window=5, min_count=1)\n",
    "        elif vectorizer_type == 'bert':\n",
    "            self.tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "            self.model = TFAutoModelForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=2)\n",
    "        elif vectorizer_type == 'use':\n",
    "            self.use_model = hub.load(\"https://tfhub.dev/google/universal-sentence-encoder/4\")\n",
    "        else:\n",
    "            raise ValueError(\"vectorizer_type doit être 'w2v', 'fasttext', 'bert', ou 'use'\")\n",
    "    \n",
    "    def clean_tweet(self, tweet):\n",
    "        tweet = tweet.lower()\n",
    "        tweet = re.sub(r'www\\S+|http\\S+', '', tweet)\n",
    "        tweet = re.sub(r'@\\w+', '', tweet)\n",
    "        tweet = re.sub(r'#\\w+', '', tweet)\n",
    "        tweet = re.sub(r'[^A-Za-z ]+', ' ', tweet)\n",
    "        tweet = re.sub(r'\\s+', ' ', tweet)\n",
    "        return tweet.strip()\n",
    "        \n",
    "    def preprocess(self, tweet):\n",
    "        cleaned_tweet = self.clean_tweet(tweet)\n",
    "        tokens = cleaned_tweet.split()\n",
    "        \n",
    "        # Appliquer le stemming ou la lemmatisation\n",
    "        if self.method == 'stem':\n",
    "            tokens = [self.stemmer.stem(token) for token in tokens]\n",
    "        elif self.method == 'lemmatize':\n",
    "            tokens = [self.lemmatizer.lemmatize(token) for token in tokens]\n",
    "        \n",
    "        return ' '.join(tokens)\n",
    "    \n",
    "    # Méthode `fit_transform` mise à jour dans TweetVectorizer pour vérifier et ajuster la forme\n",
    "    def fit_transform(self, documents):\n",
    "        documents_preprocessed = [self.preprocess(doc) for doc in documents]\n",
    "        \n",
    "        if self.vectorizer_type == 'w2v':\n",
    "            tokenized_docs = [doc.split() for doc in documents_preprocessed]\n",
    "            self.model = Word2Vec(sentences=tokenized_docs, vector_size=100, window=5, min_count=1, workers=4)\n",
    "            X = np.array([np.mean([self.model.wv[word] for word in words if word in self.model.wv] or [np.zeros(100)], axis=0) for words in tokenized_docs])\n",
    "        elif self.vectorizer_type == 'fasttext':\n",
    "            tokenized_docs = [doc.split() for doc in documents_preprocessed]\n",
    "            self.fasttext_model.build_vocab(tokenized_docs)\n",
    "            self.fasttext_model.train(tokenized_docs, total_examples=len(tokenized_docs), epochs=10)\n",
    "            X = np.array([np.mean([self.fasttext_model.wv[word] for word in words if word in self.fasttext_model.wv] or [np.zeros(100)], axis=0) for words in tokenized_docs])\n",
    "        elif self.vectorizer_type == 'bert':\n",
    "            X = self._bert_vectorize(documents_preprocessed)\n",
    "        elif self.vectorizer_type == 'use':\n",
    "            X = self.use_model(documents_preprocessed)\n",
    "            X = np.array(X)\n",
    "        \n",
    "        # Assurer que X est bien en 2D\n",
    "        if X.ndim == 1:\n",
    "            X = X.reshape(-1, 1)\n",
    "        elif X.ndim == 2 and X.shape[1] == 1:\n",
    "            # S'assurer que la deuxième dimension correspond bien à l'embedding dimension\n",
    "            X = X.reshape(-1, X.shape[1])\n",
    "        \n",
    "        return X\n",
    "\n",
    "    def transform(self, documents):\n",
    "        documents_preprocessed = [self.preprocess(doc) for doc in documents]\n",
    "        \n",
    "        if self.vectorizer_type == 'w2v':\n",
    "            tokenized_docs = [doc.split() for doc in documents_preprocessed]\n",
    "            X = np.array([np.mean([self.model.wv[word] for word in words if word in self.model.wv] or [np.zeros(100)], axis=0) for words in tokenized_docs])\n",
    "        elif self.vectorizer_type == 'fasttext':\n",
    "            tokenized_docs = [doc.split() for doc in documents_preprocessed]\n",
    "            X = np.array([np.mean([self.fasttext_model.wv[word] for word in words if word in self.fasttext_model.wv] or [np.zeros(100)], axis=0) for words in tokenized_docs])\n",
    "        elif self.vectorizer_type == 'bert':\n",
    "            X = self._bert_vectorize(documents_preprocessed)\n",
    "        elif self.vectorizer_type == 'use':\n",
    "            X = self.use_model(documents_preprocessed)\n",
    "            X = np.array(X)\n",
    "    \n",
    "        # Assurer que X est bien en 2D\n",
    "        if X.ndim == 1:\n",
    "            X = X.reshape(-1, 1)\n",
    "        elif X.ndim == 2 and X.shape[1] == 1:\n",
    "            X = X.reshape(-1, X.shape[1])\n",
    "        \n",
    "        return X\n",
    "\n",
    "    def _bert_vectorize(self, documents):\n",
    "        batch_size = 16  # Réduction de la taille du batch pour éviter les erreurs OOM\n",
    "        batches = [documents[i:i + batch_size] for i in range(0, len(documents), batch_size)]\n",
    "        \n",
    "        outputs_list = []\n",
    "        for batch in batches:\n",
    "            tokenized_inputs = self.tokenizer(batch, return_tensors='tf', padding=True, truncation=True, max_length=32)\n",
    "            outputs = self.model(tokenized_inputs).logits\n",
    "            outputs_list.append(tf.reduce_mean(outputs, axis=1).numpy())\n",
    "        \n",
    "        return np.concatenate(outputs_list, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from io import BytesIO\n",
    "\n",
    "def log_plot_to_mlflow(figure, artifact_name):\n",
    "    \"\"\"\n",
    "    Enregistre une figure matplotlib dans MLflow en utilisant un buffer en mémoire.\n",
    "\n",
    "    :param figure: la figure matplotlib à sauvegarder\n",
    "    :param artifact_name: le nom de l'artefact pour MLflow (inclure \".png\")\n",
    "    \"\"\"\n",
    "    # Utilisation d'un buffer en mémoire\n",
    "    buffer = BytesIO()\n",
    "    figure.savefig(buffer, format=\"png\")\n",
    "    buffer.seek(0)\n",
    "    \n",
    "    # Sauvegarder dans MLflow à partir du buffer\n",
    "    with open(artifact_name, \"wb\") as f:\n",
    "        f.write(buffer.getvalue())\n",
    "    mlflow.log_artifact(artifact_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classe pour la classification avec régression logistique\n",
    "from sklearn.model_selection import learning_curve, cross_validate\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report, roc_curve, auc, roc_auc_score, f1_score, precision_score, recall_score\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "import numpy as np\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "all_validation_metrics = []\n",
    "\n",
    "class TweetClassifier:\n",
    "    def __init__(self, vectorizer_type='tfidf', method='lemmatize'):\n",
    "        self.model = LogisticRegression(C=1.0, solver='lbfgs', penalty='l2')\n",
    "        self.vectorizer_type = vectorizer_type\n",
    "        self.method = method\n",
    "\n",
    "    def train_and_evaluate(self, X_train, X_val, y_train, y_val):\n",
    "        # Suivi de l'entraînement du modèle dans MLflow comme sous-exécution\n",
    "        with mlflow.start_run(run_name=\"Classification\", nested=True):\n",
    "            mlflow.set_tag(\"Stage\", \"Classification\")\n",
    "            mlflow.set_tag(\"model\", \"Logistic Regression\")\n",
    "            \n",
    "            # Enregistrer les hyperparamètres du modèle\n",
    "            mlflow.log_param(\"C\", self.model.get_params()['C'])\n",
    "            mlflow.log_param(\"solver\", self.model.get_params()['solver'])\n",
    "            mlflow.log_param(\"penalty\", self.model.get_params()['penalty'])\n",
    "            \n",
    "            # Entraîner le modèle avec Cross-Validation sur le set d'entraînement\n",
    "            cv_results = cross_validate(self.model, X_train, y_train, cv=5, \n",
    "                                                            scoring=['roc_auc', 'f1', 'accuracy', 'precision', 'recall'],\n",
    "                                                            return_train_score=False)\n",
    "\n",
    "            # Stockage des résultats de cross-validation\n",
    "            metrics_dict = {\n",
    "                \"CrossVal ROC_AUC\": round(cv_results['test_roc_auc'].mean(), 3),\n",
    "                \"CrossVal F1\": round(cv_results['test_f1'].mean(), 3),\n",
    "                \"CrossVal Accuracy\": round(cv_results['test_accuracy'].mean(), 3),\n",
    "                \"CrossVal Precision\": round(cv_results['test_precision'].mean(), 3),\n",
    "                \"CrossVal Recall\": round(cv_results['test_recall'].mean(), 3),\n",
    "                \"CrossVal Fit Time\": round(cv_results['fit_time'].mean(), 3)\n",
    "            }\n",
    "            \n",
    "            # Enregistrer les métriques de cross-validation dans MLflow\n",
    "            mlflow.log_metrics(metrics_dict)\n",
    "            \n",
    "            # Entraîner sur l'ensemble d'entraînement complet\n",
    "            start_time = time.time()\n",
    "            self.model.fit(X_train, y_train)\n",
    "            end_time = time.time()\n",
    "            training_time = end_time - start_time\n",
    "            mlflow.log_metric(\"fit_time_seconds\", training_time)\n",
    "            \n",
    "            # Évaluation sur l'ensemble de validation\n",
    "            start_predict_time = time.time()\n",
    "            y_val_pred = self.model.predict(X_val)\n",
    "            end_predict_time = time.time()\n",
    "            predict_time = end_predict_time - start_predict_time\n",
    "            \n",
    "            val_accuracy = accuracy_score(y_val, y_val_pred)\n",
    "            mlflow.log_metric(\"validation_accuracy\", val_accuracy)\n",
    "            mlflow.log_text(classification_report(y_val, y_val_pred), \"validation_classification_report.txt\")\n",
    "            \n",
    "            # Calcul de la courbe ROC-AUC sur l'ensemble de validation\n",
    "            y_val_prob = self.model.predict_proba(X_val)[:, 1]\n",
    "            fpr, tpr, _ = roc_curve(y_val, y_val_prob)\n",
    "            roc_auc_val = auc(fpr, tpr)\n",
    "            mlflow.log_metric(\"validation_roc_auc\", roc_auc_val)\n",
    "\n",
    "            # Tracer et enregistrer la courbe ROC\n",
    "            plt.figure()\n",
    "            plt.plot(fpr, tpr, label=f\"ROC curve (area = {roc_auc_val:.2f})\")\n",
    "            plt.plot([0, 1], [0, 1], 'k--')\n",
    "            plt.xlabel(\"False Positive Rate\")\n",
    "            plt.ylabel(\"True Positive Rate\")\n",
    "            plt.title(\"ROC Curve - Validation Set\")\n",
    "            plt.legend(loc=\"lower right\")\n",
    "            log_plot_to_mlflow(plt.gcf(), \"roc_curve_val.png\")\n",
    "            plt.close()\n",
    "            \n",
    "            # Tracer et enregistrer la courbe d'apprentissage\n",
    "            train_sizes, train_scores, val_scores = learning_curve(\n",
    "                self.model, X_train, y_train, cv=5, scoring=\"accuracy\", n_jobs=-1, train_sizes=np.linspace(0.1, 1.0, 5)\n",
    "            )\n",
    "            \n",
    "            train_scores_mean = np.mean(train_scores, axis=1)\n",
    "            val_scores_mean = np.mean(val_scores, axis=1)\n",
    "            \n",
    "            plt.figure()\n",
    "            plt.plot(train_sizes, train_scores_mean, label=\"Training score\")\n",
    "            plt.plot(train_sizes, val_scores_mean, label=\"Validation score\")\n",
    "            plt.xlabel(\"Training Set Size\")\n",
    "            plt.ylabel(\"Accuracy\")\n",
    "            plt.title(\"Learning Curve\")\n",
    "            plt.legend(loc=\"best\")\n",
    "            plt.grid()\n",
    "            # plt.savefig(\"images/modele-simple/learning_curve.png\")\n",
    "            # mlflow.log_artifact(\"images/modele-simple/learning_curve.png\")\n",
    "            log_plot_to_mlflow(plt.gcf(), \"learning_curve.png\")\n",
    "            plt.close()\n",
    "            \n",
    "            # Calcul des métriques de validation uniquement\n",
    "            validation_metrics = {    \n",
    "                \"Validation Accuracy\": round(accuracy_score(y_val, y_val_pred), 3),\n",
    "                \"Validation ROC_AUC\": round(roc_auc_score(y_val, y_val_prob), 3),\n",
    "                \"Validation F1\": round(f1_score(y_val, y_val_pred), 3),\n",
    "                \"Validation Precision\": round(precision_score(y_val, y_val_pred), 3),\n",
    "                \"Validation Recall\": round(recall_score(y_val, y_val_pred), 3),\n",
    "                \"Validation Predict Time\": round(predict_time, 3)\n",
    "            }\n",
    "            \n",
    "            mlflow.log_table(validation_metrics, \"validation_metrics_table.json\")\n",
    "            # Sauvegarde du modèle pour reproductibilité\n",
    "            mlflow.sklearn.log_model(self.model, \"RegLog_\"+self.vectorizer_type+\"_\"+self.method)\n",
    "            # Enregistrer le modèle final}\n",
    "            #mlflow.sklearn.log_model(self.model, \"logistic_regression_model\")\n",
    "            run_id = mlflow.active_run().info.run_id\n",
    "            result = mlflow.register_model(\n",
    "                model_uri=f\"runs:/{run_id}/model\",\n",
    "                name=f\"RegLog_{self.vectorizer_type}_{self.method}\"\n",
    "            )\n",
    "\n",
    "             # Exemple d'ajout d'un dictionnaire pour chaque configuration\n",
    "            # Ajouter les métriques de validation à la liste\n",
    "            all_validation_metrics.append({\n",
    "                \"vectorizer_type\": self.vectorizer_type,\n",
    "                \"method\": self.method,\n",
    "                **validation_metrics\n",
    "            })\n",
    "            \n",
    "            print(f\"Validation Accuracy : {val_accuracy}\")\n",
    "            print(classification_report(y_val, y_val_pred))\n",
    "    \n",
    "    def final_evaluation(self, X_test, y_test):\n",
    "        # Évaluation finale sur le set de test\n",
    "        with mlflow.start_run(run_name=\"Final Test Evaluation\", nested=True):\n",
    "            mlflow.set_tag(\"Stage\", \"Final Test Evaluation\")\n",
    "            y_test_pred = self.model.predict(X_test)\n",
    "            test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "            mlflow.log_metric(\"test_accuracy\", test_accuracy)\n",
    "            mlflow.log_text(classification_report(y_test, y_test_pred), \"test_classification_report.txt\")\n",
    "            \n",
    "            # Calcul de la courbe ROC-AUC sur l'ensemble de test\n",
    "            y_test_prob = self.model.predict_proba(X_test)[:, 1]\n",
    "            fpr, tpr, _ = roc_curve(y_test, y_test_prob)\n",
    "            roc_auc_test = auc(fpr, tpr)\n",
    "            mlflow.log_metric(\"test_roc_auc\", roc_auc_test)\n",
    "            \n",
    "            metrics_dict = {\n",
    "                \"test_accuracy\": test_accuracy,\n",
    "                \"test_roc_auc\": roc_auc_test\n",
    "            }\n",
    "            \n",
    "            mlflow.log_table(metrics_dict, \"test_metrics_table.json\")\n",
    "            mlflow.set_tag(\"test_accuracy\", test_accuracy)\n",
    "            mlflow.set_tag(\"final_evaluation_metric\", \"test_roc_auc\")\n",
    "\n",
    "            # Tracer et enregistrer la courbe ROC pour le set de test\n",
    "            plt.figure()\n",
    "            plt.plot(fpr, tpr, label=f\"ROC curve (area = {roc_auc_test:.2f})\")\n",
    "            plt.plot([0, 1], [0, 1], 'k--')\n",
    "            plt.xlabel(\"False Positive Rate\")\n",
    "            plt.ylabel(\"True Positive Rate\")\n",
    "            plt.title(\"ROC Curve - Test Set\")\n",
    "            plt.legend(loc=\"lower right\")\n",
    "            log_plot_to_mlflow(plt.gcf(), \"roc_curve_test.png\")\n",
    "            plt.close()\n",
    "            \n",
    "            # Enregistrer le modèle final\n",
    "            mlflow.sklearn.log_model(self.model, \"logistic_regression_model\")\n",
    "            \n",
    "            print(f\"Test Accuracy : {test_accuracy}\")\n",
    "            print(classification_report(y_test, y_test_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Définition des combinaisons à tester\n",
    "configurations = [\n",
    "    {'vectorizer_type': 'w2v', 'method': 'lemmatize'},\n",
    "    {'vectorizer_type': 'w2v', 'method': 'stem'},\n",
    "    {'vectorizer_type': 'fasttext', 'method': 'lemmatize'},\n",
    "    {'vectorizer_type': 'fasttext', 'method': 'stem'},\n",
    "    {'vectorizer_type': 'bert', 'method': 'lemmatize'},\n",
    "    {'vectorizer_type': 'bert', 'method': 'stem'},\n",
    "    {'vectorizer_type': 'use', 'method': 'lemmatize'},\n",
    "    {'vectorizer_type': 'use', 'method': 'stem'}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment = mlflow.set_experiment(\"advanced-models\")\n",
    "# Séparer les données en Train, Validation et Test une seule fois\n",
    "# Utiliser les tweets originaux pour diviser les ensembles de manière cohérente\n",
    "y = df_sample['target']\n",
    "tweets = df_sample['text']\n",
    "y_train_val, y_test = train_test_split(y, test_size=0.2, random_state=42)\n",
    "tweets_train_val, tweets_test = train_test_split(tweets, test_size=0.2, random_state=42)\n",
    "\n",
    "# Rediviser l'ensemble Train + Validation en Train et Validation\n",
    "y_train, y_val = train_test_split(y_train_val, test_size=0.25, random_state=42)\n",
    "tweets_train, tweets_val = train_test_split(tweets_train_val, test_size=0.25, random_state=42)\n",
    "\n",
    "# Boucle pour tester chaque configuration\n",
    "for config in configurations:\n",
    "    # Démarrer une nouvelle exécution parent pour chaque configuration\n",
    "    with mlflow.start_run(run_name=f\"{config['vectorizer_type']} + {config['method']}\", nested=False):\n",
    "        print(f\"Testing configuration: {config}\")\n",
    "        \n",
    "        # Enregistrer les paramètres de configuration comme tags\n",
    "        mlflow.set_tag(\"vectorizer_type\", config['vectorizer_type'])\n",
    "        mlflow.set_tag(\"preprocessing_method\", config['method'])\n",
    "        \n",
    "        # Initialiser et appliquer la vectorisation avec TweetVectorizer\n",
    "        tweet_vectorizer = TweetVectorizer(vectorizer_type=config['vectorizer_type'], method=config['method'])\n",
    "        \n",
    "        # Vectorisation des ensembles Train, Validation et Test\n",
    "        X_train = tweet_vectorizer.fit_transform(tweets_train)\n",
    "        X_val = tweet_vectorizer.transform(tweets_val)\n",
    "        X_test = tweet_vectorizer.transform(tweets_test)\n",
    "        \n",
    "        # Initialiser le classificateur\n",
    "        classifier = TweetClassifier(vectorizer_type=config['vectorizer_type'], method=config['method'])\n",
    "        \n",
    "        # Entraîner et évaluer le modèle avec Train et Validation\n",
    "        classifier.train_and_evaluate(X_train, X_val, y_train, y_val)\n",
    "\n",
    "        # Évaluation finale sur le set de Test\n",
    "        classifier.final_evaluation(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(pd.DataFrame(all_validation_metrics))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Embedding, Bidirectional  # Ajout de Bidirectional\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from gensim.models import Word2Vec, FastText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "all_validation_metrics = []\n",
    "class LSTMTweetClassifier:\n",
    "    def __init__(self, embedding_type='w2v', embedding_dim=100, lstm_units=128, max_length=100):\n",
    "        self.embedding_type = embedding_type\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.lstm_units = lstm_units\n",
    "        self.max_length = max_length\n",
    "        self.tokenizer = Tokenizer()\n",
    "        self.model = None\n",
    "        self.stop_words = set(stopwords.words('english'))\n",
    "\n",
    "    def clean_tweet(self, tweet):\n",
    "        \"\"\"Nettoie le texte du tweet en supprimant les liens, mentions, hashtags et caractères spéciaux.\"\"\"\n",
    "        tweet = tweet.lower()\n",
    "        tweet = re.sub(r'www\\S+|http\\S+', '', tweet)  # Supprime les liens\n",
    "        tweet = re.sub(r'@\\w+', '', tweet)            # Supprime les mentions\n",
    "        tweet = re.sub(r'#\\w+', '', tweet)            # Supprime les hashtags\n",
    "        tweet = re.sub(r'[^A-Za-z ]+', ' ', tweet)    # Supprime les caractères spéciaux\n",
    "        tweet = re.sub(r'\\s+', ' ', tweet)            # Remplace les multiples espaces par un seul espace\n",
    "        return tweet.strip()\n",
    "\n",
    "    def preprocess_and_tokenize(self, documents):\n",
    "        # Nettoyage et suppression des stopwords\n",
    "        cleaned_docs = []\n",
    "        for doc in documents:\n",
    "            cleaned_doc = self.clean_tweet(doc)\n",
    "            words = cleaned_doc.split()\n",
    "            filtered_words = [word for word in words if word not in self.stop_words]\n",
    "            cleaned_docs.append(' '.join(filtered_words))\n",
    "        \n",
    "        # Convertir les documents nettoyés en tokens\n",
    "        self.tokenizer.fit_on_texts(cleaned_docs)\n",
    "        sequences = self.tokenizer.texts_to_sequences(cleaned_docs)\n",
    "        padded_sequences = pad_sequences(sequences, maxlen=self.max_length, padding='post')\n",
    "        return padded_sequences\n",
    "\n",
    "    def build_embedding_matrix(self, documents):\n",
    "        word_index = self.tokenizer.word_index\n",
    "        vocab_size = len(word_index) + 1\n",
    "        embedding_matrix = np.zeros((vocab_size, self.embedding_dim))\n",
    "        \n",
    "        # Préparation des phrases pour l'entraînement d'embeddings\n",
    "        sentences = [self.clean_tweet(doc).split() for doc in documents]\n",
    "        \n",
    "        if self.embedding_type == 'w2v':\n",
    "            model = Word2Vec(sentences=sentences, vector_size=self.embedding_dim, window=5, min_count=1, workers=4)\n",
    "        elif self.embedding_type == 'fasttext':\n",
    "            model = FastText(sentences=sentences, vector_size=self.embedding_dim, window=5, min_count=1, workers=4)\n",
    "        else:\n",
    "            raise ValueError(\"embedding_type must be 'w2v' or 'fasttext'\")\n",
    "        \n",
    "        for word, i in word_index.items():\n",
    "            if word in model.wv:\n",
    "                embedding_matrix[i] = model.wv[word]\n",
    "        \n",
    "        return embedding_matrix\n",
    "\n",
    "    # def build_model(self, vocab_size, embedding_matrix):\n",
    "    #     \"\"\"Construit le modèle LSTM avec les paramètres spécifiés.\"\"\"\n",
    "    #     self.model = Sequential()\n",
    "    #     self.model.add(Embedding(input_dim=vocab_size, output_dim=self.embedding_dim, \n",
    "    #                              weights=[embedding_matrix], input_length=self.max_length, trainable=False))\n",
    "    #     self.model.add(Bidirectional(LSTM(self.lstm_units, return_sequences=False)))\n",
    "    #     self.model.add(Dense(1, activation='sigmoid'))\n",
    "    #     self.model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    def build_model(self, vocab_size, embedding_matrix):\n",
    "        \"\"\"\n",
    "        Fonction pour construire un modèle LSTM bidirectionnel pour une tâche de classification binaire.\n",
    "        Arguments :\n",
    "            vocab_size (int) : Taille du vocabulaire, c'est-à-dire le nombre de mots uniques dans les données.\n",
    "            embedding_matrix (numpy.array) : Matrice d'embedding pré-entraînée contenant les vecteurs des mots.\n",
    "        Retourne :\n",
    "            model (Sequential) : Modèle LSTM construit.\n",
    "        \"\"\"\n",
    "\n",
    "        # Initialisation d'un modèle séquentiel où les couches sont empilées linéairement\n",
    "        self.model = Sequential()\n",
    "\n",
    "        # Ajout d'une couche d'embedding pour transformer les tokens en vecteurs denses\n",
    "        # input_dim : Nombre total de mots dans le vocabulaire (vocab_size).\n",
    "        # output_dim : Dimension des vecteurs d'embedding (ici, 100).\n",
    "        # weights : Utilisation de la matrice pré-entraînée `embedding_matrix`.\n",
    "        # input_length : Longueur maximale des séquences d'entrée.\n",
    "        # trainable=False : Les poids de l'embedding sont figés et non entraînés.\n",
    "        self.model.add(Embedding(input_dim=vocab_size, output_dim=self.embedding_dim, \n",
    "                            weights=[embedding_matrix], input_length=self.max_length, trainable=False))\n",
    "\n",
    "        # Ajout d'une première couche LSTM bidirectionnelle\n",
    "        # 256 : Nombre d'unités LSTM dans chaque direction (forward et backward).\n",
    "        # return_sequences=True : Indique que cette couche retourne une séquence complète (pas uniquement la dernière sortie).\n",
    "        # dropout : Taux de dropout sur les connexions de la couche LSTM pour éviter l'overfitting.\n",
    "        # recurrent_dropout : Taux de dropout sur les connexions récurrentes (mémoire de l'état).\n",
    "        self.model.add(Bidirectional(LSTM(256, return_sequences=True, dropout=0.3, recurrent_dropout=0.3)))\n",
    "\n",
    "        # Ajout d'une seconde couche LSTM bidirectionnelle\n",
    "        # 128 : Moins d'unités que la précédente couche pour capturer des relations plus générales.\n",
    "        # return_sequences=False : Retourne uniquement la dernière sortie (pas la séquence complète).\n",
    "        self.model.add(Bidirectional(LSTM(128, return_sequences=False, dropout=0.3, recurrent_dropout=0.3)))\n",
    "\n",
    "        # Ajout d'une couche Dense entièrement connectée\n",
    "        # 64 : Nombre de neurones dans la couche dense pour capturer des caractéristiques abstraites.\n",
    "        # activation='relu' : Fonction d'activation ReLU pour introduire la non-linéarité.\n",
    "        # kernel_regularizer : Ajout de régularisation L2 pour réduire l'overfitting.\n",
    "        self.model.add(Dense(64, activation='relu', kernel_regularizer=regularizers.l2(0.01)))\n",
    "\n",
    "        # Ajout de la couche de sortie\n",
    "        # 1 : Une seule unité pour une tâche de classification binaire.\n",
    "        # activation='sigmoid' : Fonction d'activation sigmoid pour produire une probabilité entre 0 et 1.\n",
    "        self.model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "        # Compilation du modèle\n",
    "        # optimizer='adam' : Algorithme Adam pour l'optimisation avec un taux d'apprentissage ajustable.\n",
    "        # loss='binary_crossentropy' : Fonction de perte pour une tâche de classification binaire.\n",
    "        # metrics=['accuracy', 'AUC'] : Mesures pour suivre la précision et l'AUC pendant l'entraînement.\n",
    "        self.model.compile(optimizer=Adam(learning_rate=0.0001), loss='binary_crossentropy', metrics=['accuracy', 'AUC'])\n",
    "\n",
    "        return self.model  # Retourne le modèle final prêt à être entraîné.\n",
    "\n",
    "\n",
    "    def track_metrics(self, y_true, y_pred, prefix=\"\"):\n",
    "        \"\"\"Enregistre les métriques de classification dans MLflow.\"\"\"\n",
    "        accuracy = np.mean((y_pred > 0.5).flatten() == y_true)\n",
    "        auc = roc_auc_score(y_true, y_pred)\n",
    "        mlflow.log_metric(f\"{prefix}_accuracy\", accuracy)\n",
    "        mlflow.log_metric(f\"{prefix}_auc\", auc)\n",
    "        return accuracy, auc\n",
    "\n",
    "    def train_and_evaluate(self, X_train, y_train, X_val, y_val, epochs, batch_size):\n",
    "        \"\"\"Entraîne le modèle et enregistre les métriques et modèles dans MLflow.\"\"\"\n",
    "        if self.model is None:\n",
    "            raise RuntimeError(\"Model has not been built. Call build_model() before training.\")\n",
    "        \n",
    "        with mlflow.start_run(run_name=f\"LSTM + {config['embedding_type']}-{config['epochs']}\", nested=True):\n",
    "            # Log des hyperparamètres spécifiques à cette configuration\n",
    "            mlflow.log_param(\"embedding_type\", self.embedding_type)\n",
    "            mlflow.log_param(\"embedding_dim\", self.embedding_dim)\n",
    "            mlflow.log_param(\"lstm_units\", self.lstm_units)\n",
    "            mlflow.log_param(\"epochs\", epochs)\n",
    "            mlflow.log_param(\"batch_size\", batch_size)\n",
    "\n",
    "            start_time = time.time()\n",
    "            history = self.model.fit(\n",
    "                X_train, y_train,\n",
    "                validation_data=(X_val, y_val),\n",
    "                epochs=epochs, batch_size=batch_size\n",
    "            )\n",
    "            train_duration = time.time() - start_time\n",
    "            mlflow.log_metric(\"train_duration\", train_duration)\n",
    "\n",
    "            # Log des métriques d'entraînement et de validation\n",
    "            for epoch in range(epochs):\n",
    "                mlflow.log_metric(\"train_loss\", history.history['loss'][epoch], step=epoch)\n",
    "                mlflow.log_metric(\"val_loss\", history.history['val_loss'][epoch], step=epoch)\n",
    "                mlflow.log_metric(\"train_accuracy\", history.history['accuracy'][epoch], step=epoch)\n",
    "                mlflow.log_metric(\"val_accuracy\", history.history['val_accuracy'][epoch], step=epoch)\n",
    "        \n",
    "            # Évaluation sur l'ensemble de validation\n",
    "            start_predict_time = time.time()\n",
    "            y_val_pred = self.model.predict(X_val).flatten()\n",
    "            predict_time = time.time() - start_predict_time\n",
    "            #self.track_metrics(y_val, y_val_pred, prefix=\"val\")\n",
    "            \n",
    "            # Calcul des métriques de validation\n",
    "            validation_metrics = {    \n",
    "                \"Validation Accuracy\": round(accuracy_score(y_val, (y_val_pred > 0.5).astype(int)), 3),\n",
    "                \"Validation ROC_AUC\": round(roc_auc_score(y_val, y_val_pred), 3),\n",
    "                \"Validation F1\": round(f1_score(y_val, (y_val_pred > 0.5).astype(int)), 3),\n",
    "                \"Validation Precision\": round(precision_score(y_val, (y_val_pred > 0.5).astype(int)), 3),\n",
    "                \"Validation Recall\": round(recall_score(y_val, (y_val_pred > 0.5).astype(int)), 3),\n",
    "                \"Validation Predict Time\": round(predict_time, 3)\n",
    "            }\n",
    "            mlflow.log_table(validation_metrics, \"validation_metrics_table.json\")\n",
    "            # Enregistrer les métriques de validation dans MLflow\n",
    "            mlflow.log_metrics(validation_metrics)\n",
    "            \n",
    "            # Log des métriques dans MLflow\n",
    "            for key, value in validation_metrics.items():\n",
    "             mlflow.log_metric(key, value)\n",
    "\n",
    "            # Log du modèle\n",
    "            mlflow.keras.log_model(self.model, \"LSTM\"+self.embedding_type+\"_\"+str(self.embedding_dim)+\"_\"+str(self.lstm_units))\n",
    "            run_id = mlflow.active_run().info.run_id\n",
    "            result = mlflow.register_model(\n",
    "                model_uri=f\"runs:/{run_id}/model\",\n",
    "                name=f\"LSTM_{self.embedding_type}_{self.embedding_dim}_{self.lstm_units}\"\n",
    "            )\n",
    "\n",
    "             # Exemple d'ajout d'un dictionnaire pour chaque configuration\n",
    "            # Ajouter les métriques de validation à la liste\n",
    "            all_validation_metrics.append({\n",
    "                \"vectorizer_type\": self.embedding_type,\n",
    "                \"method\": self.embedding_dim,\n",
    "                **validation_metrics\n",
    "            })\n",
    "\n",
    "    def fit(self, documents, labels, test_size=0.2, val_split=0.2, epochs=10, batch_size=32):\n",
    "        # Nettoyage, tokenisation et padding des données\n",
    "        padded_sequences = self.preprocess_and_tokenize(documents)\n",
    "        vocab_size = len(self.tokenizer.word_index) + 1\n",
    "        embedding_matrix = self.build_embedding_matrix(documents)\n",
    "\n",
    "        # Construire le modèle\n",
    "        self.build_model(vocab_size, embedding_matrix)\n",
    "\n",
    "        # Découper les données en train/test\n",
    "        X_train_val, X_test, y_train_val, y_test = train_test_split(\n",
    "            padded_sequences, labels, test_size=test_size, random_state=42\n",
    "        )\n",
    "\n",
    "        # Découper l'ensemble train en train/validation\n",
    "        val_split_index = int(len(X_train_val) * (1 - val_split))\n",
    "        X_train, X_val = X_train_val[:val_split_index], X_train_val[val_split_index:]\n",
    "        y_train, y_val = y_train_val[:val_split_index], y_train_val[val_split_index:]\n",
    "\n",
    "        print(f\"Training data: {len(X_train)} samples\")\n",
    "        print(f\"Validation data: {len(X_val)} samples\")\n",
    "        print(f\"Test data: {len(X_test)} samples\")\n",
    "\n",
    "        # Entraîner et évaluer\n",
    "        self.train_and_evaluate(X_train, y_train, X_val, y_val, epochs=epochs, batch_size=batch_size)\n",
    "\n",
    "        # Évaluation finale sur l'ensemble de test\n",
    "        print(\"\\nFinal Evaluation on Test Set:\")\n",
    "        y_test_pred = self.model.predict(X_test).flatten()\n",
    "        test_metrics = {    \n",
    "            \"Test Accuracy\": round(accuracy_score(y_test, (y_test_pred > 0.5).astype(int)), 3),\n",
    "            \"Test ROC_AUC\": round(roc_auc_score(y_test, y_test_pred), 3),\n",
    "            \"Test F1\": round(f1_score(y_test, (y_test_pred > 0.5).astype(int)), 3),\n",
    "            \"Test Precision\": round(precision_score(y_test, (y_test_pred > 0.5).astype(int)), 3),\n",
    "            \"Test Recall\": round(recall_score(y_test, (y_test_pred > 0.5).astype(int)), 3),\n",
    "        }\n",
    "        \n",
    "        print(test_metrics)\n",
    "        for key, value in test_metrics.items():\n",
    "            mlflow.log_metric(f\"test_{key.lower()}\", value)\n",
    "            \n",
    "    def predict(self, documents):\n",
    "        padded_sequences = self.preprocess_and_tokenize(documents)\n",
    "        predictions = self.model.predict(padded_sequences)\n",
    "        return (predictions > 0.5).astype(int).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "configurations = [\n",
    "    {\n",
    "        \"embedding_type\": \"w2v\",\n",
    "        \"embedding_dim\": 100,\n",
    "        \"lstm_units\": 128,\n",
    "        \"epochs\": 10,\n",
    "        \"batch_size\": 32\n",
    "    },\n",
    "    {\n",
    "        \"embedding_type\": \"fasttext\",\n",
    "        \"embedding_dim\": 100,\n",
    "        \"lstm_units\": 128,\n",
    "        \"epochs\": 10,\n",
    "        \"batch_size\": 32\n",
    "    },\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Testing configuration: {'embedding_type': 'w2v', 'embedding_dim': 100, 'lstm_units': 128, 'epochs': 10, 'batch_size': 32} \n",
      "\n",
      "Training data: 12800 samples\n",
      "Validation data: 3200 samples\n",
      "Test data: 4000 samples\n",
      "Epoch 1/10\n",
      "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m135s\u001b[0m 325ms/step - AUC: 0.5311 - accuracy: 0.5249 - loss: 1.5340 - val_AUC: 0.5978 - val_accuracy: 0.5572 - val_loss: 1.1229\n",
      "Epoch 2/10\n",
      "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m135s\u001b[0m 338ms/step - AUC: 0.5604 - accuracy: 0.5428 - loss: 1.0457 - val_AUC: 0.6125 - val_accuracy: 0.5669 - val_loss: 0.8593\n",
      "Epoch 3/10\n",
      "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m135s\u001b[0m 337ms/step - AUC: 0.5824 - accuracy: 0.5622 - loss: 0.8277 - val_AUC: 0.6195 - val_accuracy: 0.5850 - val_loss: 0.7439\n",
      "Epoch 4/10\n",
      "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m131s\u001b[0m 327ms/step - AUC: 0.5951 - accuracy: 0.5638 - loss: 0.7363 - val_AUC: 0.6268 - val_accuracy: 0.5938 - val_loss: 0.6986\n",
      "Epoch 5/10\n",
      "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m165s\u001b[0m 385ms/step - AUC: 0.6007 - accuracy: 0.5785 - loss: 0.7013 - val_AUC: 0.6321 - val_accuracy: 0.5900 - val_loss: 0.6816\n",
      "Epoch 6/10\n",
      "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m137s\u001b[0m 344ms/step - AUC: 0.5947 - accuracy: 0.5669 - loss: 0.6902 - val_AUC: 0.6392 - val_accuracy: 0.5959 - val_loss: 0.6724\n",
      "Epoch 7/10\n",
      "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m138s\u001b[0m 335ms/step - AUC: 0.5994 - accuracy: 0.5720 - loss: 0.6835 - val_AUC: 0.6422 - val_accuracy: 0.6003 - val_loss: 0.6711\n",
      "Epoch 8/10\n",
      "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m148s\u001b[0m 369ms/step - AUC: 0.6052 - accuracy: 0.5800 - loss: 0.6797 - val_AUC: 0.6447 - val_accuracy: 0.5888 - val_loss: 0.6734\n",
      "Epoch 9/10\n",
      "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m155s\u001b[0m 388ms/step - AUC: 0.6053 - accuracy: 0.5751 - loss: 0.6780 - val_AUC: 0.6479 - val_accuracy: 0.5894 - val_loss: 0.6694\n",
      "Epoch 10/10\n",
      "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m197s\u001b[0m 376ms/step - AUC: 0.6147 - accuracy: 0.5756 - loss: 0.6745 - val_AUC: 0.6531 - val_accuracy: 0.6053 - val_loss: 0.6644\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 106ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/11/18 19:33:45 WARNING mlflow.keras.save: You are saving a Keras model without specifying model signature.\n",
      "2024/11/18 19:33:49 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "Registered model 'LSTM_w2v_100_128' already exists. Creating a new version of this model...\n",
      "2024/11/18 19:33:49 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: LSTM_w2v_100_128, version 3\n",
      "Created version '3' of model 'LSTM_w2v_100_128'.\n",
      "2024/11/18 19:33:49 INFO mlflow.tracking._tracking_service.client: 🏃 View run LSTM + w2v-10 at: http://mlflow-server:5000/#/experiments/5/runs/b78390c125bd4d8083f2d8bf1f587436.\n",
      "2024/11/18 19:33:49 INFO mlflow.tracking._tracking_service.client: 🧪 View experiment at: http://mlflow-server:5000/#/experiments/5.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final Evaluation on Test Set:\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 106ms/step\n",
      "{'Test Accuracy': 0.597, 'Test ROC_AUC': 0.637, 'Test F1': 0.608, 'Test Precision': 0.586, 'Test Recall': 0.632}\n",
      "Finished testing configuration: {'embedding_type': 'w2v', 'embedding_dim': 100, 'lstm_units': 128, 'epochs': 10, 'batch_size': 32}\n",
      "\n",
      "\n",
      " Testing configuration: {'embedding_type': 'fasttext', 'embedding_dim': 100, 'lstm_units': 128, 'epochs': 10, 'batch_size': 32} \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/lib/python3.11/site-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data: 12800 samples\n",
      "Validation data: 3200 samples\n",
      "Test data: 4000 samples\n",
      "Epoch 1/10\n",
      "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m166s\u001b[0m 406ms/step - AUC: 0.5363 - accuracy: 0.5220 - loss: 1.5370 - val_AUC: 0.5926 - val_accuracy: 0.5519 - val_loss: 1.1396\n",
      "Epoch 2/10\n",
      "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m140s\u001b[0m 350ms/step - AUC: 0.5492 - accuracy: 0.5396 - loss: 1.0619 - val_AUC: 0.6011 - val_accuracy: 0.5650 - val_loss: 0.8746\n",
      "Epoch 3/10\n",
      "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m136s\u001b[0m 341ms/step - AUC: 0.5655 - accuracy: 0.5491 - loss: 0.8449 - val_AUC: 0.6021 - val_accuracy: 0.5625 - val_loss: 0.7646\n",
      "Epoch 4/10\n",
      "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m122s\u001b[0m 304ms/step - AUC: 0.5732 - accuracy: 0.5497 - loss: 0.7511 - val_AUC: 0.6093 - val_accuracy: 0.5738 - val_loss: 0.7131\n",
      "Epoch 5/10\n",
      "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m154s\u001b[0m 335ms/step - AUC: 0.5738 - accuracy: 0.5541 - loss: 0.7136 - val_AUC: 0.6114 - val_accuracy: 0.5794 - val_loss: 0.6935\n",
      "Epoch 6/10\n",
      "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 309ms/step - AUC: 0.5815 - accuracy: 0.5618 - loss: 0.6971 - val_AUC: 0.6140 - val_accuracy: 0.5653 - val_loss: 0.6890\n",
      "Epoch 7/10\n",
      "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 307ms/step - AUC: 0.5889 - accuracy: 0.5626 - loss: 0.6894 - val_AUC: 0.6129 - val_accuracy: 0.5641 - val_loss: 0.6854\n",
      "Epoch 8/10\n",
      "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m115s\u001b[0m 288ms/step - AUC: 0.5774 - accuracy: 0.5526 - loss: 0.6886 - val_AUC: 0.6146 - val_accuracy: 0.5694 - val_loss: 0.6816\n",
      "Epoch 9/10\n",
      "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m113s\u001b[0m 283ms/step - AUC: 0.5885 - accuracy: 0.5629 - loss: 0.6845 - val_AUC: 0.6163 - val_accuracy: 0.5903 - val_loss: 0.6774\n",
      "Epoch 10/10\n",
      "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m113s\u001b[0m 283ms/step - AUC: 0.5908 - accuracy: 0.5652 - loss: 0.6830 - val_AUC: 0.6176 - val_accuracy: 0.5847 - val_loss: 0.6771\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 78ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/11/18 19:56:03 WARNING mlflow.keras.save: You are saving a Keras model without specifying model signature.\n",
      "2024/11/18 19:56:06 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "Registered model 'LSTM_fasttext_100_128' already exists. Creating a new version of this model...\n",
      "2024/11/18 19:56:06 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: LSTM_fasttext_100_128, version 3\n",
      "Created version '3' of model 'LSTM_fasttext_100_128'.\n",
      "2024/11/18 19:56:06 INFO mlflow.tracking._tracking_service.client: 🏃 View run LSTM + fasttext-10 at: http://mlflow-server:5000/#/experiments/5/runs/e1dbe4139fe540f3b18902a1eaa5f446.\n",
      "2024/11/18 19:56:06 INFO mlflow.tracking._tracking_service.client: 🧪 View experiment at: http://mlflow-server:5000/#/experiments/5.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final Evaluation on Test Set:\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 77ms/step\n",
      "{'Test Accuracy': 0.565, 'Test ROC_AUC': 0.596, 'Test F1': 0.547, 'Test Precision': 0.565, 'Test Recall': 0.531}\n",
      "Finished testing configuration: {'embedding_type': 'fasttext', 'embedding_dim': 100, 'lstm_units': 128, 'epochs': 10, 'batch_size': 32}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "experiment = mlflow.set_experiment(\"LSTM\")\n",
    "documents = df_sample['text']\n",
    "labels = df_sample['target']\n",
    "\n",
    "# Boucle sur chaque configuration pour tester\n",
    "for config in configurations:\n",
    "    print(f\"\\n Testing configuration: {config} \\n\")\n",
    "    # with mlflow.start_run(run_name=f\"LSTM + {config['embedding_type']}-{config['epochs']}\", nested=False):\n",
    "    #     mlflow.set_tag(\"Model_Type\", \"LSTM\")\n",
    "    #     mlflow.set_tag(\"embedding_type\", config[\"embedding_type\"])\n",
    "    #     mlflow.set_tag(\"epochs\", config[\"epochs\"])\n",
    "    #     mlflow.log_params(config)\n",
    "    \n",
    "    model = LSTMTweetClassifier(\n",
    "        embedding_type=config[\"embedding_type\"],\n",
    "        embedding_dim=config[\"embedding_dim\"],\n",
    "        max_length=100  # Vous pouvez ajuster cette valeur si nécessaire\n",
    "    )\n",
    "    # Entraînement du modèle avec la configuration actuelle\n",
    "    model.fit(\n",
    "        documents, \n",
    "        labels, \n",
    "        epochs=config[\"epochs\"], \n",
    "        batch_size=config[\"batch_size\"]\n",
    "    )\n",
    "    \n",
    "    # Ici, vous pouvez ajouter des étapes pour enregistrer ou comparer les résultats, par exemple :\n",
    "    # - Enregistrer les métriques dans un dictionnaire ou un fichier pour une analyse ultérieure\n",
    "    # - Comparer les résultats dans MLFlow\n",
    "    print(f\"Finished testing configuration: {config}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>vectorizer_type</th>\n",
       "      <th>method</th>\n",
       "      <th>Validation Accuracy</th>\n",
       "      <th>Validation ROC_AUC</th>\n",
       "      <th>Validation F1</th>\n",
       "      <th>Validation Precision</th>\n",
       "      <th>Validation Recall</th>\n",
       "      <th>Validation Predict Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>w2v</td>\n",
       "      <td>100</td>\n",
       "      <td>0.605</td>\n",
       "      <td>0.653</td>\n",
       "      <td>0.618</td>\n",
       "      <td>0.611</td>\n",
       "      <td>0.624</td>\n",
       "      <td>11.082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fasttext</td>\n",
       "      <td>100</td>\n",
       "      <td>0.585</td>\n",
       "      <td>0.618</td>\n",
       "      <td>0.567</td>\n",
       "      <td>0.607</td>\n",
       "      <td>0.531</td>\n",
       "      <td>8.368</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  vectorizer_type  method  Validation Accuracy  Validation ROC_AUC  \\\n",
       "0             w2v     100                0.605               0.653   \n",
       "1        fasttext     100                0.585               0.618   \n",
       "\n",
       "   Validation F1  Validation Precision  Validation Recall  \\\n",
       "0          0.618                 0.611              0.624   \n",
       "1          0.567                 0.607              0.531   \n",
       "\n",
       "   Validation Predict Time  \n",
       "0                   11.082  \n",
       "1                    8.368  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(pd.DataFrame(all_validation_metrics))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "target\n",
       "0    10000\n",
       "1    10000\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sample['target'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import emoji\n",
    "from transformers import AutoTokenizer, TFAutoModelForSequenceClassification, AutoConfig\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# 1. Prétraitement des tweets\n",
    "def tokenize_hashtags(text):\n",
    "    \"\"\"\n",
    "    Tokenise les hashtags en séparant les mots (ex. #HappyBirthday -> happy birthday).\n",
    "    \"\"\"\n",
    "    return re.sub(r'#(\\w+)', lambda m: ' '.join(re.findall(r'[A-Z]?[a-z]+|[A-Z]+(?=[A-Z]|$)', m.group(1))), text)\n",
    "\n",
    "def remove_urls(text):\n",
    "    \"\"\"Supprime les URLs du texte.\"\"\"\n",
    "    return re.sub(r'http\\S+|www\\S+|https\\S+', '', text, flags=re.MULTILINE)\n",
    "\n",
    "def remove_mentions(text):\n",
    "    \"\"\"Supprime les mentions (@user) du texte.\"\"\"\n",
    "    return re.sub(r'@\\w+', '', text)\n",
    "\n",
    "def remove_emojis(text):\n",
    "    \"\"\"Supprime les emojis du texte.\"\"\"\n",
    "    return emoji.demojize(text)\n",
    "\n",
    "def to_lowercase(text):\n",
    "    \"\"\"Convertit le texte en minuscules.\"\"\"\n",
    "    return text.lower()\n",
    "\n",
    "def remove_special_characters(text):\n",
    "    \"\"\"Supprime les caractères spéciaux du texte.\"\"\"\n",
    "    return re.sub(r'[^a-zA-Z0-9\\s]', '', text)\n",
    "\n",
    "def remove_extra_whitespace(text):\n",
    "    \"\"\"Supprime les espaces en trop.\"\"\"\n",
    "    return re.sub(r'\\s+', ' ', text).strip()\n",
    "\n",
    "def preprocess_tweet(tweet):\n",
    "    \"\"\"\n",
    "    Nettoie et prétraite un tweet.\n",
    "    - Conserve les hashtags mais les tokenise en mots.\n",
    "    - Supprime les URLs, mentions, emojis et caractères spéciaux.\n",
    "    \"\"\"\n",
    "    tweet = remove_urls(tweet)\n",
    "    tweet = remove_mentions(tweet)\n",
    "    tweet = tokenize_hashtags(tweet)\n",
    "    tweet = remove_emojis(tweet)\n",
    "    tweet = to_lowercase(tweet)\n",
    "    tweet = remove_special_characters(tweet)\n",
    "    tweet = remove_extra_whitespace(tweet)\n",
    "    return tweet\n",
    "\n",
    "# Nettoyer les tweets\n",
    "df_sample['cleaned_text'] = df_sample['text'].apply(preprocess_tweet)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='/tmp/mlruns/7', creation_time=1731940223943, experiment_id='7', last_update_time=1731940223943, lifecycle_stage='active', name='pretrained-models', tags={}>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Liste pour stocker les métriques de validation pour comparaison\n",
    "all_validation_metrics = []\n",
    "mlflow.set_experiment(\"pretrained-models\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 2. Fonction de remapping des prédictions\n",
    "def map_predictions(predictions):\n",
    "    \"\"\"\n",
    "    Remap classe 2 (neutre) à 1 (positif) pour une classification binaire.\n",
    "    \"\"\"\n",
    "    return [0 if pred == 0 else 1 for pred in predictions]\n",
    "\n",
    "# 3. Fonction pour évaluer un modèle\n",
    "# Fonction pour évaluer un modèle avec analyse des erreurs\n",
    "def evaluate_model(model_name, documents, labels, max_length=128, test_size=0.2):\n",
    "    \"\"\"\n",
    "    Évalue un modèle pré-entraîné sur un ensemble de validation et collecte les métriques.\n",
    "    Ajoute une analyse des faux positifs et faux négatifs.\n",
    "    \"\"\"\n",
    "    # Charger la configuration, tokenizer et modèle\n",
    "    config = AutoConfig.from_pretrained(model_name)\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    try:\n",
    "        # Charger le modèle TensorFlow\n",
    "        model = TFAutoModelForSequenceClassification.from_pretrained(model_name, config=config)\n",
    "    except OSError:\n",
    "        # Charger le modèle PyTorch si TensorFlow n'est pas disponible\n",
    "        print(f\"Model {model_name} is in PyTorch format, converting to TensorFlow using `from_pt=True`.\")\n",
    "        model = TFAutoModelForSequenceClassification.from_pretrained(model_name, config=config, from_pt=True)\n",
    "\n",
    "    # Diviser les données en ensemble d'entraînement et de validation\n",
    "    X_train, X_val, y_train, y_val = train_test_split(documents, labels, test_size=test_size, random_state=42)\n",
    "\n",
    "    # Tokenisation des données\n",
    "    def tokenize_texts(texts):\n",
    "        encoding = tokenizer(\n",
    "            texts.tolist(),\n",
    "            add_special_tokens=True,\n",
    "            max_length=max_length,\n",
    "            padding=\"max_length\",\n",
    "            truncation=True,\n",
    "            return_tensors=\"np\"\n",
    "        )\n",
    "        return encoding[\"input_ids\"], encoding[\"attention_mask\"]\n",
    "\n",
    "    input_ids_val, attention_masks_val = tokenize_texts(X_val)\n",
    "\n",
    "    with mlflow.start_run(run_name=f\"Evaluation {model_name}\"):\n",
    "        mlflow.set_tag(\"model\", model_name)\n",
    "\n",
    "        # Prédictions sur l'ensemble de validation\n",
    "        start_predict_time = time.time()\n",
    "        outputs = model.predict([input_ids_val, attention_masks_val])\n",
    "        predict_time = time.time() - start_predict_time\n",
    "\n",
    "        logits = outputs.logits\n",
    "        y_val_prob = tf.nn.softmax(logits, axis=-1).numpy()[:, 1]\n",
    "        y_val_pred = np.argmax(logits, axis=-1)\n",
    "\n",
    "        # Remap des prédictions si le modèle utilise 3 classes\n",
    "        if config.num_labels == 3:\n",
    "            print(f\"Remapping predictions for binary classification (Model: {model_name})...\")\n",
    "            y_val_pred = map_predictions(y_val_pred)\n",
    "\n",
    "                # Calcul des métriques de validation\n",
    "        validation_metrics = {\n",
    "            \"Validation Accuracy\": round(accuracy_score(y_val, y_val_pred), 3),\n",
    "           # \"Validation ROC_AUC\": round(roc_auc_score(y_val, y_val_prob, multi_class='ovr'), 3),\n",
    "            \"Validation F1\": round(f1_score(y_val, y_val_pred, average=\"weighted\"), 3),\n",
    "            \"Validation Precision\": round(precision_score(y_val, y_val_pred, average=\"weighted\"), 3),\n",
    "            \"Validation Recall\": round(recall_score(y_val, y_val_pred, average=\"weighted\"), 3),\n",
    "            \"Validation Predict Time\": round(predict_time, 3)\n",
    "        }\n",
    "\n",
    "        # Enregistrer les métriques dans MLflow\n",
    "        mlflow.log_metrics(validation_metrics)\n",
    "\n",
    "        # Analyse des erreurs (faux positifs et faux négatifs)\n",
    "        false_positives = pd.DataFrame({\"text\": X_val[(y_val == 0) & (y_val_pred == 1)]})\n",
    "        false_negatives = pd.DataFrame({\"text\": X_val[(y_val == 1) & (y_val_pred == 0)]})\n",
    "\n",
    "        # Calculer les taux\n",
    "        fp_rate = len(false_positives) / sum(y_val == 0)\n",
    "        fn_rate = len(false_negatives) / sum(y_val == 1)\n",
    "\n",
    "        # Ajouter les longueurs des textes pour l'analyse\n",
    "        false_positives[\"text_length\"] = false_positives[\"text\"].apply(len)\n",
    "        false_negatives[\"text_length\"] = false_negatives[\"text\"].apply(len)\n",
    "\n",
    "        # Log des taux dans MLflow\n",
    "        mlflow.log_metric(\"False Positive Rate\", fp_rate * 100)\n",
    "        mlflow.log_metric(\"False Negative Rate\", fn_rate * 100)\n",
    "\n",
    "        # Graphique de distribution des longueurs pour les erreurs\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        plt.hist(false_positives[\"text_length\"], bins=20, alpha=0.5, label=\"Faux Positifs\")\n",
    "        plt.hist(false_negatives[\"text_length\"], bins=20, alpha=0.5, label=\"Faux Négatifs\")\n",
    "        plt.legend()\n",
    "        plt.title(f\"Distribution des longueurs de tweets pour les erreurs - {model_name}\")\n",
    "        plt.xlabel(\"Longueur du tweet\")\n",
    "        plt.ylabel(\"Fréquence\")\n",
    "\n",
    "        # Sauvegarder et enregistrer dans MLflow\n",
    "        #plt.savefig(f\"errors_text_length_distribution_{model_name}.png\")\n",
    "        #mlflow.log_artifact(f\"errors_text_length_distribution_{model_name}.png\")\n",
    "        mlflow.log_figure(plt.gcf(), f\"errors_text_length_distribution_{model_name}.png\")\n",
    "        plt.close()\n",
    "\n",
    "        # Courbe ROC\n",
    "        fpr, tpr, _ = roc_curve(y_val, y_val_prob)\n",
    "        roc_auc_val = auc(fpr, tpr)\n",
    "        plt.figure()\n",
    "        plt.plot(fpr, tpr, label=f\"ROC curve (area = {roc_auc_val:.2f})\")\n",
    "        plt.plot([0, 1], [0, 1], \"k--\")\n",
    "        plt.xlabel(\"False Positive Rate\")\n",
    "        plt.ylabel(\"True Positive Rate\")\n",
    "        plt.title(f\"ROC Curve - {model_name}\")\n",
    "        plt.legend(loc=\"lower right\")\n",
    "        mlflow.log_figure(plt.gcf(), f\"roc_curve_{model_name}.png\")\n",
    "        plt.close()\n",
    "\n",
    "        # Ajout des métriques pour la comparaison\n",
    "        all_validation_metrics.append({\n",
    "            \"model_name\": model_name,\n",
    "            **validation_metrics,\n",
    "            # \"False Positive Rate\": round(fp_rate * 100, 3),\n",
    "            # \"False Negative Rate\": round(fn_rate * 100, 3),\n",
    "        })\n",
    "\n",
    "        # Affichage des résultats\n",
    "        print(f\"Model: {model_name}\")\n",
    "        print(validation_metrics)\n",
    "        print(f\"False Positive Rate: {fp_rate * 100:.2f}%\")\n",
    "        print(f\"False Negative Rate: {fn_rate * 100:.2f}%\")\n",
    "        print(\"Classification Report:\")\n",
    "        print(classification_report(y_val, y_val_pred))\n",
    "        print(\"-\" * 50)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some weights or buffers of the TF 2.0 model TFBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125/125 [==============================] - 184s 1s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/11/18 15:36:04 INFO mlflow.tracking._tracking_service.client: 🏃 View run Evaluation bert-base-uncased at: http://mlflow-server:5000/#/experiments/7/runs/521e65cbc2044ff9a3c9207616db711b.\n",
      "2024/11/18 15:36:04 INFO mlflow.tracking._tracking_service.client: 🧪 View experiment at: http://mlflow-server:5000/#/experiments/7.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: bert-base-uncased\n",
      "{'Validation Accuracy': 0.495, 'Validation ROC_AUC': 0.498, 'Validation F1': 0.334, 'Validation Precision': 0.488, 'Validation Recall': 0.495, 'Validation Predict Time': 184.249}\n",
      "False Positive Rate: 99.36%\n",
      "False Negative Rate: 0.71%\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.48      0.01      0.01      2019\n",
      "           1       0.50      0.99      0.66      1981\n",
      "\n",
      "    accuracy                           0.49      4000\n",
      "   macro avg       0.49      0.50      0.34      4000\n",
      "weighted avg       0.49      0.49      0.33      4000\n",
      "\n",
      "--------------------------------------------------\n",
      "Model textattack/bert-base-uncased-imdb is in PyTorch format, converting to TensorFlow using `from_pt=True`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "All the weights of TFBertForSequenceClassification were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertForSequenceClassification for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125/125 [==============================] - 185s 1s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/11/18 15:39:11 INFO mlflow.tracking._tracking_service.client: 🏃 View run Evaluation textattack/bert-base-uncased-imdb at: http://mlflow-server:5000/#/experiments/7/runs/32402af3c0644b9889faa24832aee1ba.\n",
      "2024/11/18 15:39:11 INFO mlflow.tracking._tracking_service.client: 🧪 View experiment at: http://mlflow-server:5000/#/experiments/7.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: textattack/bert-base-uncased-imdb\n",
      "{'Validation Accuracy': 0.649, 'Validation ROC_AUC': 0.699, 'Validation F1': 0.649, 'Validation Precision': 0.65, 'Validation Recall': 0.649, 'Validation Predict Time': 184.607}\n",
      "False Positive Rate: 38.53%\n",
      "False Negative Rate: 31.60%\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.61      0.64      2019\n",
      "           1       0.64      0.68      0.66      1981\n",
      "\n",
      "    accuracy                           0.65      4000\n",
      "   macro avg       0.65      0.65      0.65      4000\n",
      "weighted avg       0.65      0.65      0.65      4000\n",
      "\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFRobertaForSequenceClassification.\n",
      "\n",
      "All the layers of TFRobertaForSequenceClassification were initialized from the model checkpoint at cardiffnlp/twitter-roberta-base-sentiment.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaForSequenceClassification for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125/125 [==============================] - 188s 1s/step\n",
      "Remapping predictions for binary classification (Model: cardiffnlp/twitter-roberta-base-sentiment)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/11/18 15:42:22 INFO mlflow.tracking._tracking_service.client: 🏃 View run Evaluation cardiffnlp/twitter-roberta-base-sentiment at: http://mlflow-server:5000/#/experiments/7/runs/4f7bb4c63292415db850adcbace3c06f.\n",
      "2024/11/18 15:42:22 INFO mlflow.tracking._tracking_service.client: 🧪 View experiment at: http://mlflow-server:5000/#/experiments/7.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: cardiffnlp/twitter-roberta-base-sentiment\n",
      "{'Validation Accuracy': 0.728, 'Validation ROC_AUC': 0.5, 'Validation F1': 0.717, 'Validation Precision': 0.771, 'Validation Recall': 0.728, 'Validation Predict Time': 188.355}\n",
      "False Positive Rate: 0.00%\n",
      "False Negative Rate: 0.00%\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.53      0.66      2019\n",
      "           1       0.66      0.93      0.77      1981\n",
      "\n",
      "    accuracy                           0.73      4000\n",
      "   macro avg       0.77      0.73      0.72      4000\n",
      "weighted avg       0.77      0.73      0.72      4000\n",
      "\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFRobertaForSequenceClassification.\n",
      "\n",
      "All the layers of TFRobertaForSequenceClassification were initialized from the model checkpoint at finiteautomata/bertweet-base-sentiment-analysis.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaForSequenceClassification for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125/125 [==============================] - 189s 1s/step\n",
      "Remapping predictions for binary classification (Model: finiteautomata/bertweet-base-sentiment-analysis)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/11/18 15:45:33 INFO mlflow.tracking._tracking_service.client: 🏃 View run Evaluation finiteautomata/bertweet-base-sentiment-analysis at: http://mlflow-server:5000/#/experiments/7/runs/1eeca746a09d408587d5bffe7e0b5632.\n",
      "2024/11/18 15:45:33 INFO mlflow.tracking._tracking_service.client: 🧪 View experiment at: http://mlflow-server:5000/#/experiments/7.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: finiteautomata/bertweet-base-sentiment-analysis\n",
      "{'Validation Accuracy': 0.731, 'Validation ROC_AUC': 0.501, 'Validation F1': 0.723, 'Validation Precision': 0.761, 'Validation Recall': 0.731, 'Validation Predict Time': 188.707}\n",
      "False Positive Rate: 0.00%\n",
      "False Negative Rate: 0.00%\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.57      0.68      2019\n",
      "           1       0.67      0.90      0.77      1981\n",
      "\n",
      "    accuracy                           0.73      4000\n",
      "   macro avg       0.76      0.73      0.72      4000\n",
      "weighted avg       0.76      0.73      0.72      4000\n",
      "\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFRobertaForSequenceClassification.\n",
      "\n",
      "Some layers of TFRobertaForSequenceClassification were not initialized from the model checkpoint at vinai/bertweet-base and are newly initialized: ['classifier']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125/125 [==============================] - 181s 1s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/11/18 15:48:37 INFO mlflow.tracking._tracking_service.client: 🏃 View run Evaluation vinai/bertweet-base at: http://mlflow-server:5000/#/experiments/7/runs/6cbb265445964b389a4f346fb868519b.\n",
      "2024/11/18 15:48:37 INFO mlflow.tracking._tracking_service.client: 🧪 View experiment at: http://mlflow-server:5000/#/experiments/7.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: vinai/bertweet-base\n",
      "{'Validation Accuracy': 0.487, 'Validation ROC_AUC': 0.416, 'Validation F1': 0.336, 'Validation Precision': 0.404, 'Validation Recall': 0.487, 'Validation Predict Time': 181.269}\n",
      "False Positive Rate: 98.61%\n",
      "False Negative Rate: 3.03%\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.32      0.01      0.03      2019\n",
      "           1       0.49      0.97      0.65      1981\n",
      "\n",
      "    accuracy                           0.49      4000\n",
      "   macro avg       0.40      0.49      0.34      4000\n",
      "weighted avg       0.40      0.49      0.34      4000\n",
      "\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at nlptown/bert-base-multilingual-uncased-sentiment were not used when initializing TFBertForSequenceClassification: ['dropout_37']\n",
      "- This IS expected if you are initializing TFBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFBertForSequenceClassification were initialized from the model checkpoint at nlptown/bert-base-multilingual-uncased-sentiment.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertForSequenceClassification for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125/125 [==============================] - 172s 1s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "2024/11/18 15:51:32 INFO mlflow.tracking._tracking_service.client: 🏃 View run Evaluation nlptown/bert-base-multilingual-uncased-sentiment at: http://mlflow-server:5000/#/experiments/7/runs/f800ce74a5714b369263fbc5ae4a46ac.\n",
      "2024/11/18 15:51:32 INFO mlflow.tracking._tracking_service.client: 🧪 View experiment at: http://mlflow-server:5000/#/experiments/7.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: nlptown/bert-base-multilingual-uncased-sentiment\n",
      "{'Validation Accuracy': 0.273, 'Validation ROC_AUC': 0.264, 'Validation F1': 0.332, 'Validation Precision': 0.486, 'Validation Recall': 0.273, 'Validation Predict Time': 172.43}\n",
      "False Positive Rate: 12.18%\n",
      "False Negative Rate: 20.90%\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.50      0.59      2019\n",
      "           1       0.26      0.04      0.07      1981\n",
      "           2       0.00      0.00      0.00         0\n",
      "           3       0.00      0.00      0.00         0\n",
      "           4       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.27      4000\n",
      "   macro avg       0.19      0.11      0.13      4000\n",
      "weighted avg       0.49      0.27      0.33      4000\n",
      "\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFDistilBertForSequenceClassification: ['vocab_transform.bias', 'vocab_layer_norm.bias', 'vocab_projector.bias', 'vocab_layer_norm.weight', 'vocab_transform.weight']\n",
      "- This IS expected if you are initializing TFDistilBertForSequenceClassification from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFDistilBertForSequenceClassification from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights or buffers of the TF 2.0 model TFDistilBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['pre_classifier.weight', 'pre_classifier.bias', 'classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125/125 [==============================] - 85s 672ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/11/18 15:52:58 INFO mlflow.tracking._tracking_service.client: 🏃 View run Evaluation distilbert-base-uncased at: http://mlflow-server:5000/#/experiments/7/runs/e59855034dbf4205bd6d78433123ca92.\n",
      "2024/11/18 15:52:58 INFO mlflow.tracking._tracking_service.client: 🧪 View experiment at: http://mlflow-server:5000/#/experiments/7.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: distilbert-base-uncased\n",
      "{'Validation Accuracy': 0.504, 'Validation ROC_AUC': 0.49, 'Validation F1': 0.342, 'Validation Precision': 0.453, 'Validation Recall': 0.504, 'Validation Predict Time': 84.671}\n",
      "False Positive Rate: 0.59%\n",
      "False Negative Rate: 99.60%\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.99      0.67      2019\n",
      "           1       0.40      0.00      0.01      1981\n",
      "\n",
      "    accuracy                           0.50      4000\n",
      "   macro avg       0.45      0.50      0.34      4000\n",
      "weighted avg       0.45      0.50      0.34      4000\n",
      "\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Données : textes et labels nettoyés\n",
    "documents = df_sample['cleaned_text']\n",
    "labels = df_sample['target']\n",
    "\n",
    "# 4. Évaluation des modèles\n",
    "evaluate_model('bert-base-uncased', documents, labels, max_length=80)\n",
    "evaluate_model('textattack/bert-base-uncased-imdb', documents, labels, max_length=80)  # Modèle fine-tuné pour sentiments\n",
    "evaluate_model('cardiffnlp/twitter-roberta-base-sentiment', documents, labels, max_length=80)\n",
    "evaluate_model('finiteautomata/bertweet-base-sentiment-analysis', documents, labels, max_length=80)  # Modèle fine-tuné pour tweets\n",
    "evaluate_model('vinai/bertweet-base', documents, labels, max_length=80)\n",
    "evaluate_model('nlptown/bert-base-multilingual-uncased-sentiment', documents, labels, max_length=80)\n",
    "evaluate_model('distilbert-base-uncased', documents, labels, max_length=80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_name</th>\n",
       "      <th>Validation Accuracy</th>\n",
       "      <th>Validation ROC_AUC</th>\n",
       "      <th>Validation F1</th>\n",
       "      <th>Validation Precision</th>\n",
       "      <th>Validation Recall</th>\n",
       "      <th>Validation Predict Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bert-base-uncased</td>\n",
       "      <td>0.495</td>\n",
       "      <td>0.482</td>\n",
       "      <td>0.662</td>\n",
       "      <td>0.495</td>\n",
       "      <td>0.998</td>\n",
       "      <td>169.424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bert-base-uncased</td>\n",
       "      <td>0.495</td>\n",
       "      <td>0.451</td>\n",
       "      <td>0.663</td>\n",
       "      <td>0.495</td>\n",
       "      <td>1.000</td>\n",
       "      <td>170.922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>textattack/bert-base-uncased-imdb</td>\n",
       "      <td>0.649</td>\n",
       "      <td>0.699</td>\n",
       "      <td>0.659</td>\n",
       "      <td>0.635</td>\n",
       "      <td>0.684</td>\n",
       "      <td>167.922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cardiffnlp/twitter-roberta-base-sentiment</td>\n",
       "      <td>0.728</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.771</td>\n",
       "      <td>0.660</td>\n",
       "      <td>0.926</td>\n",
       "      <td>171.567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>finiteautomata/bertweet-base-sentiment-analysis</td>\n",
       "      <td>0.731</td>\n",
       "      <td>0.501</td>\n",
       "      <td>0.768</td>\n",
       "      <td>0.670</td>\n",
       "      <td>0.898</td>\n",
       "      <td>168.517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>vinai/bertweet-base</td>\n",
       "      <td>0.497</td>\n",
       "      <td>0.489</td>\n",
       "      <td>0.663</td>\n",
       "      <td>0.496</td>\n",
       "      <td>0.996</td>\n",
       "      <td>171.640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>bert-base-uncased</td>\n",
       "      <td>0.495</td>\n",
       "      <td>0.498</td>\n",
       "      <td>0.334</td>\n",
       "      <td>0.488</td>\n",
       "      <td>0.495</td>\n",
       "      <td>184.249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>textattack/bert-base-uncased-imdb</td>\n",
       "      <td>0.649</td>\n",
       "      <td>0.699</td>\n",
       "      <td>0.649</td>\n",
       "      <td>0.650</td>\n",
       "      <td>0.649</td>\n",
       "      <td>184.607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>cardiffnlp/twitter-roberta-base-sentiment</td>\n",
       "      <td>0.728</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.717</td>\n",
       "      <td>0.771</td>\n",
       "      <td>0.728</td>\n",
       "      <td>188.355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>finiteautomata/bertweet-base-sentiment-analysis</td>\n",
       "      <td>0.731</td>\n",
       "      <td>0.501</td>\n",
       "      <td>0.723</td>\n",
       "      <td>0.761</td>\n",
       "      <td>0.731</td>\n",
       "      <td>188.707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>vinai/bertweet-base</td>\n",
       "      <td>0.487</td>\n",
       "      <td>0.416</td>\n",
       "      <td>0.336</td>\n",
       "      <td>0.404</td>\n",
       "      <td>0.487</td>\n",
       "      <td>181.269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>nlptown/bert-base-multilingual-uncased-sentiment</td>\n",
       "      <td>0.273</td>\n",
       "      <td>0.264</td>\n",
       "      <td>0.332</td>\n",
       "      <td>0.486</td>\n",
       "      <td>0.273</td>\n",
       "      <td>172.430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>distilbert-base-uncased</td>\n",
       "      <td>0.504</td>\n",
       "      <td>0.490</td>\n",
       "      <td>0.342</td>\n",
       "      <td>0.453</td>\n",
       "      <td>0.504</td>\n",
       "      <td>84.671</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          model_name  Validation Accuracy  \\\n",
       "0                                  bert-base-uncased                0.495   \n",
       "1                                  bert-base-uncased                0.495   \n",
       "2                  textattack/bert-base-uncased-imdb                0.649   \n",
       "3          cardiffnlp/twitter-roberta-base-sentiment                0.728   \n",
       "4    finiteautomata/bertweet-base-sentiment-analysis                0.731   \n",
       "5                                vinai/bertweet-base                0.497   \n",
       "6                                  bert-base-uncased                0.495   \n",
       "7                  textattack/bert-base-uncased-imdb                0.649   \n",
       "8          cardiffnlp/twitter-roberta-base-sentiment                0.728   \n",
       "9    finiteautomata/bertweet-base-sentiment-analysis                0.731   \n",
       "10                               vinai/bertweet-base                0.487   \n",
       "11  nlptown/bert-base-multilingual-uncased-sentiment                0.273   \n",
       "12                           distilbert-base-uncased                0.504   \n",
       "\n",
       "    Validation ROC_AUC  Validation F1  Validation Precision  \\\n",
       "0                0.482          0.662                 0.495   \n",
       "1                0.451          0.663                 0.495   \n",
       "2                0.699          0.659                 0.635   \n",
       "3                0.500          0.771                 0.660   \n",
       "4                0.501          0.768                 0.670   \n",
       "5                0.489          0.663                 0.496   \n",
       "6                0.498          0.334                 0.488   \n",
       "7                0.699          0.649                 0.650   \n",
       "8                0.500          0.717                 0.771   \n",
       "9                0.501          0.723                 0.761   \n",
       "10               0.416          0.336                 0.404   \n",
       "11               0.264          0.332                 0.486   \n",
       "12               0.490          0.342                 0.453   \n",
       "\n",
       "    Validation Recall  Validation Predict Time  \n",
       "0               0.998                  169.424  \n",
       "1               1.000                  170.922  \n",
       "2               0.684                  167.922  \n",
       "3               0.926                  171.567  \n",
       "4               0.898                  168.517  \n",
       "5               0.996                  171.640  \n",
       "6               0.495                  184.249  \n",
       "7               0.649                  184.607  \n",
       "8               0.728                  188.355  \n",
       "9               0.731                  188.707  \n",
       "10              0.487                  181.269  \n",
       "11              0.273                  172.430  \n",
       "12              0.504                   84.671  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(pd.DataFrame(all_validation_metrics))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| **Modèle**                                    | **Performance**        | **Recommandation**                                                  |\n",
    "|-----------------------------------------------|-------------------------|----------------------------------------------------------------------|\n",
    "| `finiteautomata/bertweet-base-sentiment-analysis` | **73.08%**            | 🏆 Meilleur choix pour un projet prêt à l'emploi. Fine-tuné pour les tweets. |\n",
    "| `cardiffnlp/twitter-roberta-base-sentiment`   | **72.75%**             | ✅ Alternative solide, surtout si on souhaite explorer les classes neutres.  |\n",
    "| `vinai/bertweet-base`                         | **49.53% (non fine-tuné)** | 🚀 Fine-tunez ce modèle pour un contrôle total sur les performances.         |\n",
    "| `textattack/bert-base-uncased-imdb`           | **64.90%**             | 🤔 Correct, mais non optimisé pour les tweets.                               |\n",
    "| `nlptown/bert-base-multilingual-uncased-sentiment` | **27.32%**           | ❌ À éviter, pas adapté à nos données.                                       |\n",
    "| `distilbert-base-uncased`                     | **50.48%**             | ❌ Trop généraliste et peu performant.                                       |\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
