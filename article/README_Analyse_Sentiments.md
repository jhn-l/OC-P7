
# ğŸŒŸ **Anticiper les Bad Buzz grÃ¢ce Ã  lâ€™Analyse de Sentiments avec Deep Learning** ğŸŒŸ

Dans un monde oÃ¹ la rÃ©putation en ligne est cruciale, les entreprises doivent anticiper les bad buzz sur les rÃ©seaux sociaux. 
Ce projet, rÃ©alisÃ© pour la compagnie aÃ©rienne _Air Paradis_, vise Ã  dÃ©velopper un prototype dâ€™intelligence artificielle capable de prÃ©dire 
les sentiments associÃ©s Ã  des tweets. DÃ©couvrez comment les approches classiques et avancÃ©es du Deep Learning, combinÃ©es aux principes 
du MLOps, ont permis de relever ce dÃ©fi ambitieux. ğŸš€

---

## **ğŸ“– Contexte et Objectif**

_Air Paradis_, confrontÃ©e Ã  des critiques rÃ©guliÃ¨res sur les rÃ©seaux sociaux, a sollicitÃ© une solution capable de dÃ©tecter rapidement 
les tweets nÃ©gatifs. Lâ€™objectif Ã©tait de concevoir un modÃ¨le dâ€™analyse de sentiments prÃ©disant si un tweet est **positif** ou **nÃ©gatif**, 
Ã  partir de donnÃ©es publiques issues de Twitter.

### Les DonnÃ©es ğŸ“Š

- **Dataset utilisÃ©** : Sentiment140 contenant 1,6 million de tweets, rÃ©partis en deux classes : nÃ©gative (0) et positive (4).
- **ProblÃ¨me binaire** : Le dataset ne contenait pas de tweets neutres, simplifiant la tÃ¢che Ã  une classification binaire.

---

## **ğŸ” Approches et MÃ©thodologie**

### **ModÃ¨le Classique (ğŸ© Baseline)**

La premiÃ¨re Ã©tape consistait Ã  dÃ©velopper une solution simple et robuste :

- **Algorithme** : RÃ©gression logistique.
- **Vectorisation** : TF-IDF et CountVectorizer.
- **PrÃ©traitement** : Suppression des doublons, lemmatisation et stemming.
- **RÃ©sultats** : Un modÃ¨le baseline permettant dâ€™obtenir une premiÃ¨re Ã©valuation des performances sur un sous-ensemble de 20 000 tweets.

_ğŸ’¡ Illustration suggÃ©rÃ©e : Un schÃ©ma de pipeline pour le modÃ¨le classique._

---

### **ModÃ¨le AvancÃ© (ğŸ”® Techniques modernes)**

Pour amÃ©liorer la prÃ©cision, des techniques plus complexes ont Ã©tÃ© explorÃ©es :

1. **Embeddings de mots** : 
   - ModÃ¨les utilisÃ©s : Word2Vec, FastText, GloVe.
   - IntÃ©gration dans des modÃ¨les Deep Learning avec des couches LSTM, capturant les relations contextuelles.

2. **BERT (âœ¨)** :
   - Fine-tuning dâ€™un modÃ¨le prÃ©entraÃ®nÃ© pour la classification.
   - Utilisation de _Hugging Face_ et de _TensorFlow_ pour intÃ©grer les embeddings de phrases.

_ğŸ’¡ Illustration suggÃ©rÃ©e : Comparaison des performances entre les modÃ¨les avancÃ©s et classiques (tableau ou courbe)._

---

### **Comparaison des ModÃ¨les ğŸ“ˆ**

Les modÃ¨les ont Ã©tÃ© Ã©valuÃ©s sur des mÃ©triques pertinentes :
- **AUC (Area Under Curve)**.
- **Matrice de confusion** pour analyser les faux positifs et les faux nÃ©gatifs.
- **Temps dâ€™entraÃ®nement** et dâ€™infÃ©rence.

_ğŸ’¡ Illustration suggÃ©rÃ©e : Matrice de confusion ou courbe ROC pour le meilleur modÃ¨le._

---

## **ğŸ› ï¸ Principes de MLOps**

Pour garantir lâ€™industrialisation du projet, une dÃ©marche MLOps complÃ¨te a Ã©tÃ© adoptÃ©e.

### Suivi des ExpÃ©rimentations avec MLFlow

- **Tracking** : Historisation des hyperparamÃ¨tres, des scores et des courbes ROC.
- **Gestion des modÃ¨les** : Enregistrement centralisÃ© des artefacts, facilitant le dÃ©ploiement et la comparaison des versions.

_ğŸ’¡ Illustration suggÃ©rÃ©e : Capture dâ€™Ã©cran de lâ€™interface MLFlow._

---

### API Flask pour le DÃ©ploiement ğŸŒ

Une API a Ã©tÃ© dÃ©veloppÃ©e pour exposer les prÃ©dictions du modÃ¨le en temps rÃ©el :
- Endpoint `/predict` : Recevant un tweet et retournant le sentiment associÃ©.
- Tests unitaires pour valider la robustesse de lâ€™API avant dÃ©ploiement.

_ğŸ’¡ Illustration suggÃ©rÃ©e : Exemple de rÃ©ponse JSON de lâ€™API._

---

### Monitoring en Production ğŸ“¡

- Utilisation dâ€™Azure Application Insights pour capturer les erreurs et analyser les performances en conditions rÃ©elles.
- Logs et alertes configurÃ©s pour garantir une fiabilitÃ© continue.

---

## **ğŸ“Š RÃ©sultats et Impact**

### Performances des ModÃ¨les

1. **ModÃ¨le classique** :
   - Simple mais limitÃ© en capacitÃ© de gÃ©nÃ©ralisation.

2. **ModÃ¨le avancÃ© (LSTM)** :
   - Meilleures performances grÃ¢ce Ã  lâ€™intÃ©gration des embeddings de mots.

3. **ModÃ¨le BERT** :
   - RÃ©sultats supÃ©rieurs, avec une meilleure capacitÃ© Ã  comprendre les subtilitÃ©s linguistiques.

---

### RÃ©sultats ClÃ©s âœ…

- Le modÃ¨le BERT fine-tunÃ© a atteint des scores dâ€™AUC proches de 0,9 sur le jeu de test.
- La classification binaire a permis dâ€™obtenir un Ã©quilibre parfait entre les classes, minimisant les biais.

_ğŸ’¡ Illustration suggÃ©rÃ©e : Tableau comparatif des mÃ©triques des trois modÃ¨les._

---

## **âš ï¸ DÃ©fis RencontrÃ©s**

- **ProblÃ¨mes de donnÃ©es** : Absence de tweets neutres, nÃ©cessitant une simplification Ã  deux classes.
- **Optimisation des hyperparamÃ¨tres** : Ajustement pour rÃ©duire le temps dâ€™entraÃ®nement tout en maintenant des performances Ã©levÃ©es.

---

## **ğŸ”® Perspectives**

1. **AmÃ©lioration des ModÃ¨les** :
   - IntÃ©grer des donnÃ©es supplÃ©mentaires pour inclure une classe neutre.
   - Explorer des architectures plus lÃ©gÃ¨res pour des prÃ©dictions en temps rÃ©el.

2. **Automatisation** :
   - Mise en place dâ€™un pipeline CI/CD complet pour dÃ©ployer rapidement les mises Ã  jour du modÃ¨le.

3. **Analyse en Production** :
   - Exploiter les mÃ©triques capturÃ©es dans Application Insights pour amÃ©liorer continuellement les performances du modÃ¨le.

---

## **ğŸ“Œ Conclusion**

Ce projet a dÃ©montrÃ© comment des technologies de pointe et une approche MLOps peuvent transformer une problÃ©matique mÃ©tier complexe en une solution pratique et efficace. Avec le modÃ¨le BERT, _Air Paradis_ est dÃ©sormais mieux Ã©quipÃ©e pour anticiper les crises et prÃ©server sa rÃ©putation en ligne.

---

## **ğŸ¤ Ã€ Vous de Contribuer !**

Lâ€™intÃ©gralitÃ© du code, des notebooks et des configurations est disponible sur GitHub. Testez les modÃ¨les, enrichissez les donnÃ©es, et aidez-nous Ã  faire Ã©voluer cette solution ! ğŸš€
