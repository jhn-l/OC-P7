{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-05 09:18:41.089469: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1730798321.102557   78776 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1730798321.106453   78776 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-11-05 09:18:41.120286: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, roc_auc_score, roc_curve, auc\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "\n",
    "import nltk\n",
    "import mlflow\n",
    "from transformers import TFAutoModelForSequenceClassification, AutoTokenizer\n",
    "\n",
    "import re\n",
    "import time\n",
    "from gensim.models import Word2Vec, FastText\n",
    "from gensim.models import KeyedVectors\n",
    "from transformers import BertTokenizer, TFBertModel\n",
    "\n",
    "import tensorflow_hub as hub\n",
    "\n",
    "import pickle\n",
    "import requests\n",
    "import zipfile\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numpy version: 1.26.4\n",
      "TensorFlow version: 2.18.0\n",
      "Gensim version: 4.3.3\n",
      "Numba version: 0.60.0\n"
     ]
    }
   ],
   "source": [
    "import numpy\n",
    "import tensorflow\n",
    "import gensim\n",
    "import numba\n",
    "print(\"Numpy version:\", numpy.__version__)\n",
    "print(\"TensorFlow version:\", tensorflow.__version__)\n",
    "print(\"Gensim version:\", gensim.__version__)\n",
    "print(\"Numba version:\", numba.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.set_tracking_uri(\"http://mlflow-server:5000\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 786516 entries, 367103 to 1380859\n",
      "Data columns (total 6 columns):\n",
      " #   Column  Non-Null Count   Dtype \n",
      "---  ------  --------------   ----- \n",
      " 0   target  786516 non-null  int64 \n",
      " 1   ids     786516 non-null  int64 \n",
      " 2   date    786516 non-null  object\n",
      " 3   flag    786516 non-null  object\n",
      " 4   user    786516 non-null  object\n",
      " 5   text    786516 non-null  object\n",
      "dtypes: int64(2), object(4)\n",
      "memory usage: 42.0+ MB\n"
     ]
    }
   ],
   "source": [
    "# Recharger le DataFrame depuis le fichier pickle\n",
    "df_sample = pd.read_pickle('df_sample.pkl')\n",
    "df_sample.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre d'échantillons conservés: 16000\n",
      "target\n",
      "1    0.501062\n",
      "0    0.498937\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    " #Vérifier si le DataFrame a au moins 16 000 lignes\n",
    "if len(df_sample) < 16000:\n",
    "    raise ValueError(\"Le DataFrame contient moins de 16 000 lignes.\")\n",
    "\n",
    "# Calculer la proportion nécessaire pour obtenir 16 000 lignes\n",
    "sample_size = 16000 / len(df_sample)\n",
    "\n",
    "# Utiliser train_test_split pour sélectionner un échantillon équilibré de 16 000 lignes\n",
    "df_16000, _ = train_test_split(df_sample, train_size=sample_size, stratify=df_sample['target'], random_state=42)\n",
    "\n",
    "# Vérifier le nombre d'éléments et l'équilibre des classes\n",
    "print(f\"Nombre d'échantillons conservés: {len(df_16000)}\")\n",
    "print(df_16000['target'].value_counts(normalize=True))  # Vérifier l'équilibre des classes\n",
    "\n",
    "df_sample = df_16000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAsAAAAIjCAYAAAAN/63DAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8hTgPZAAAACXBIWXMAAA9hAAAPYQGoP6dpAABkc0lEQVR4nO3deXxM5////2cispLElowQkYolUUvRatQuFWspqkrt5U2pomh92mpQlNbaWlpthZYWXZVaYt9ifduKorZQSVQtkZBNzu8Pv8zXSGKJkLydx/12m9vNXOd1rnOdmWQ858o1Z+wMwzAEAAAAmIR9bg8AAAAAeJQIwAAAADAVAjAAAABMhQAMAAAAUyEAAwAAwFQIwAAAADAVAjAAAABMhQAMAAAAUyEAAwAAwFQIwMADCgsLk52d3SM5Vv369VW/fn3r/fXr18vOzk4//PDDIzl+t27dVLp06UdyrHuRfv7r16/P7aFkW3h4uOzs7HTq1KncHkqOyOnn5NSpU7Kzs1N4eHiO9JfTSpcurW7duuX2MADcJwIwcIv0MJJ+c3Z2lo+Pj0JDQzVt2jRdvXo1R45z7tw5hYWFae/evTnSX07Ky2MD8PB069bN5g32tWvXFBYW9j/zBvNO4w0LC8tTb96R+wjAQCZGjRqlb775RjNnztQbb7whSRo4cKAqVaqk/fv329S+9957un79+n31f+7cOY0cOfK+Q+aqVau0atWq+9rnft1pbLNnz9aRI0ce6vEB5A3Xrl3TyJEj/6cC8P/SeJG7HHJ7AEBe1LRpU9WoUcN6f/jw4Vq7dq1atGihF154QYcPH5aLi4skycHBQQ4OD/dX6dq1a3J1dZWjo+NDPc7d5M+fP1ePj5yTmpqqtLS0XP+ZgvkkJCTIzc0tt4cBk2MGGLhHDRs21Pvvv6/Tp0/r22+/tbZntgY4IiJCtWvXlqenpwoUKKDy5cvr//7v/yTdXCP59NNPS5K6d+9uXW6Rvsaxfv36evLJJ7V7927VrVtXrq6u1n1vXwOc7saNG/q///s/WSwWubm56YUXXtCZM2dsarJaq3hrn3cbW2ZrgBMSEvTWW2/J19dXTk5OKl++vD755BMZhmFTZ2dnp/79++uXX37Rk08+KScnJ1WsWFErVqzI/AG/zdmzZ9W6dWu5ubnJy8tLgwYNUlJSUqa127dvV5MmTeTh4SFXV1fVq1dPW7Zssam5evWqBg4cqNKlS8vJyUleXl56/vnn9d///jfLMfzwww+ys7PThg0bMmz7/PPPZWdnpz/++EOStH//fnXr1k1PPPGEnJ2dZbFY1KNHD/3777/3dL7Lly9XnTp15ObmpoIFC6p58+Y6ePCgTU1WPw+3P0/p62g/+eQTTZkyRWXKlJGTk5MOHTokSfr0009VsWJFubq6qlChQqpRo4YWLFhw1zHm9HNyrx70sU1MTFRYWJjKlSsnZ2dnFS9eXG3atNHx48etNff6c52ZEydO6KWXXlLhwoXl6uqqZ599VsuWLbOpSV8rvWjRIo0ZM0YlS5aUs7OzGjVqpL/++sumNv014dChQ2rQoIFcXV1VokQJTZgwIcOxk5KS9MEHHyggIEBOTk7y9fXVsGHDsnxesnLq1CkVK1ZMkjRy5Ejra0FYWJike38O0l8fDx06pI4dO6pQoUKqXbu2JCktLU1hYWHy8fGRq6urGjRooEOHDmX6WnX58mUNHDjQ+nwEBARo/PjxSktLu6fxArdjBhi4D507d9b//d//adWqVerVq1emNQcPHlSLFi1UuXJljRo1Sk5OTvrrr7+s/9kHBgZq1KhRGjFihHr37q06depIkmrVqmXt499//1XTpk3VoUMHvfrqq/L29r7juMaMGSM7Ozu9/fbbOn/+vKZMmaKQkBDt3bvXOlN9L+5lbLcyDEMvvPCC1q1bp549e6pq1apauXKlhg4dqr///luTJ0+2qd+8ebN++uknvf766ypYsKCmTZumtm3bKioqSkWKFMlyXNevX1ejRo0UFRWlAQMGyMfHR998843Wrl2boXbt2rVq2rSpqlevrg8++ED29vaaM2eOGjZsqE2bNumZZ56RJPXp00c//PCD+vfvr6CgIP3777/avHmzDh8+rGrVqmU6jubNm6tAgQJatGiR6tWrZ7Nt4cKFqlixop588klJN98EnThxQt27d5fFYtHBgwf1xRdf6ODBg9q2bdsdPzj5zTffqGvXrgoNDdX48eN17do1zZw5U7Vr19aePXuyvZZxzpw5SkxMVO/eveXk5KTChQtr9uzZGjBggNq1a6c333xTiYmJ2r9/v7Zv366OHTtm2dfDeE7u1YM8tjdu3FCLFi20Zs0adejQQW+++aauXr2qiIgI/fHHHypTpsx9/1zfKjY2VrVq1dK1a9c0YMAAFSlSRHPnztULL7ygH374QS+++KJN/UcffSR7e3sNGTJEV65c0YQJE9SpUydt377dpu7SpUtq0qSJ2rRpo/bt2+uHH37Q22+/rUqVKqlp06aSbgbKF154QZs3b1bv3r0VGBioAwcOaPLkyTp69Kh++eWXe36MixUrppkzZ6pv37568cUX1aZNG0lS5cqVs/UcvPTSSypbtqzGjh1rfRMxfPhwTZgwQS1btlRoaKj27dun0NBQJSYm2ux77do11atXT3///bf+85//qFSpUtq6dauGDx+u6OhoTZky5a7jBTIwAFjNmTPHkGTs3LkzyxoPDw/jqaeest7/4IMPjFt/lSZPnmxIMv75558s+9i5c6chyZgzZ06GbfXq1TMkGbNmzcp0W7169az3161bZ0gySpQoYcTFxVnbFy1aZEgypk6dam3z8/Mzunbtetc+7zS2rl27Gn5+ftb7v/zyiyHJ+PDDD23q2rVrZ9jZ2Rl//fWXtU2S4ejoaNO2b98+Q5Lx6aefZjjWraZMmWJIMhYtWmRtS0hIMAICAgxJxrp16wzDMIy0tDSjbNmyRmhoqJGWlmatvXbtmuHv7288//zz1jYPDw+jX79+dzxuZl555RXDy8vLSE1NtbZFR0cb9vb2xqhRo2yOebvvvvvOkGRs3LjR2pb+M3fy5EnDMAzj6tWrhqenp9GrVy+bfWNiYgwPDw+b9tufu3S3P08nT540JBnu7u7G+fPnbWpbtWplVKxY8Z7O/VYP4znJTPrYb/15vNfHNjNff/21IcmYNGlShm3p47ufn+vbf68GDhxoSDI2bdpkbbt69arh7+9vlC5d2rhx44ZhGP/vdzcwMNBISkqy1k6dOtWQZBw4cMDalv6aMG/ePGtbUlKSYbFYjLZt21rbvvnmG8Pe3t7m2IZhGLNmzTIkGVu2bLnjY3O7f/75x5BkfPDBBxm23etzkP76+Morr9jUxsTEGA4ODkbr1q1t2sPCwgxJNo/p6NGjDTc3N+Po0aM2te+8846RL18+Iyoq6q7jBW7HEgjgPhUoUOCOV4Pw9PSUJP3666/WP8/dLycnJ3Xv3v2e67t06aKCBQta77dr107FixfX77//nq3j36vff/9d+fLl04ABA2za33rrLRmGoeXLl9u0h4SEqEyZMtb7lStXlru7u06cOHHX4xQvXlzt2rWztrm6uqp37942dXv37tWxY8fUsWNH/fvvv7pw4YIuXLighIQENWrUSBs3brQ+J56entq+fbvOnTt3X+f88ssv6/z58zYftPnhhx+Ulpaml19+2dp268x7YmKiLly4oGeffVaS7rjMIiIiQpcvX9Yrr7xiHf+FCxeUL18+1axZU+vWrbuv8d6qbdu21j8Tp/P09NTZs2e1c+fO++rrYTwn9yq7j60k/fjjjypatKj1w623Sp+1vN+f61v9/vvveuaZZ6x/5pduvmb07t1bp06dsi47Sde9e3ebddjpf3W5/XeiQIECevXVV633HR0d9cwzz9jULV68WIGBgapQoYLNz07Dhg0l6YF+dm53v89Bnz59bO6vWbNGqampev31123aM3teFi9erDp16qhQoUI25xUSEqIbN25o48aNOXFKMBmWQAD3KT4+Xl5eXlluf/nll/Xll1/qtdde0zvvvKNGjRqpTZs2ateunezt7+09Z4kSJe7rw0lly5a1uW9nZ6eAgICHfm3Z06dPy8fHxyZ8SzeXUqRvv1WpUqUy9FGoUCFdunTprscJCAjI8GfV8uXL29w/duyYJKlr165Z9nXlyhUVKlRIEyZMUNeuXeXr66vq1aurWbNm6tKli5544ok7jiV9HevChQvVqFEjSTeXP1StWlXlypWz1l28eFEjR47U999/r/Pnz2cYQ1bSzyE9tNzO3d39juO7E39//wxtb7/9tlavXq1nnnlGAQEBaty4sTp27Kjnnnvujn09jOfkXmX3sZWk48ePq3z58nf84Or9/lzfvm/NmjUztN+6b/oyGSnj70T643D770TJkiUzPNaFChWyuSrNsWPHdPjw4QxvctLd/lg9iPt9Dm7/2Ut/DAMCAmzaCxcunOFn4dixY9q/f/8jOS+YBwEYuA9nz57VlStXMrxo38rFxUUbN27UunXrtGzZMq1YsUILFy5Uw4YNtWrVKuXLl++ux7mfdbv3Kqt1kTdu3LinMeWErI5j3MMHi+5F+kzixx9/rKpVq2ZaU6BAAUlS+/btVadOHf38889atWqVPv74Y40fP14//fSTdU1lZpycnNS6dWv9/PPPmjFjhmJjY7VlyxaNHTvWpq59+/baunWrhg4dqqpVq6pAgQJKS0tTkyZN7jjjmb7tm2++kcViybD91uBmZ2eX6WN348aNTPvO7OcqMDBQR44c0dKlS7VixQr9+OOPmjFjhkaMGKGRI0dmOc57dT/Pyb3K7mObF93r78S91KWlpalSpUqaNGlSprW+vr7ZHGVG9/scPMhrWlpamp5//nkNGzYs0+23vvEE7hUBGLgP33zzjSQpNDT0jnX29vZq1KiRGjVqpEmTJmns2LF69913tW7dOoWEhOT4N8elz7KlMwxDf/31l80HQAoVKqTLly9n2Pf06dM2s573MzY/Pz+tXr1aV69etZkt+/PPP63bc4Kfn5/++OMPGYZhM77br0mcvrzC3d1dISEhd+23ePHiev311/X666/r/PnzqlatmsaMGXPHACzdnOWfO3eu1qxZo8OHD8swDJvlD5cuXdKaNWs0cuRIjRgxwtp++/OUmfRz8PLyuus5FCpUKNPlI3eaocyMm5ubXn75Zb388stKTk5WmzZtNGbMGA0fPlzOzs6Z7vOwnpO7eZDHNn0827dvV0pKSpaX9XuQn2s/P79Mr5Wd078TmSlTpoz27dunRo0a5chrTFZ9POhzIP2/x+Gvv/6ymR3+999/M8x+lylTRvHx8Xf9+XlU38iJxwNrgIF7tHbtWo0ePVr+/v7q1KlTlnUXL17M0JY+85V+KaL0a2BmFkizY968eTbrkn/44QdFR0fbBLkyZcpo27ZtSk5OtrYtXbo0w+XS7mdszZo1040bN/TZZ5/ZtE+ePFl2dnZ3DZL3qlmzZjp37pzNVz5fu3ZNX3zxhU1d9erVVaZMGX3yySeKj4/P0M8///wj6eYM6e1/pvXy8pKPj889XS4qJCREhQsX1sKFC7Vw4UI988wzNv+Jp8/W3T6LN2XKlLv2HRoaKnd3d40dO1YpKSlZnoN08zn9888/bdr27dt3X5cXu/2yVY6OjgoKCpJhGJkeP11OPyf36kEeW+nmOugLFy5k+Jm9tc8H+blu1qyZduzYocjISGtbQkKCvvjiC5UuXVpBQUH3NM7saN++vf7++2/Nnj07w7br168rISHhvvpzdXWVlPG14EGfA0lq1KiRHBwcNHPmTJv2zJ6X9u3bKzIyUitXrsyw7fLly0pNTb3jeIHMMAMMZGL58uX6888/lZqaqtjYWK1du1YRERHy8/PTkiVLspwVk25+i9zGjRvVvHlz+fn56fz585oxY4ZKlixp/WBMmTJl5OnpqVmzZqlgwYJyc3NTzZo1M12jeS8KFy6s2rVrq3v37oqNjdWUKVMUEBBgc6m21157TT/88IOaNGmi9u3b6/jx4/r2229tPpR2v2Nr2bKlGjRooHfffVenTp1SlSpVtGrVKv36668aOHBghr6zq1evXvrss8/UpUsX7d69W8WLF9c333xj/Q8vnb29vb788ks1bdpUFStWVPfu3VWiRAn9/fffWrdundzd3fXbb7/p6tWrKlmypNq1a6cqVaqoQIECWr16tXbu3KmJEyfedTz58+dXmzZt9P333yshIUGffPKJzXZ3d3fVrVtXEyZMUEpKikqUKKFVq1bp5MmTd+3b3d1dM2fOVOfOnVWtWjV16NBBxYoVU1RUlJYtW6bnnnvOGhJ69OihSZMmKTQ0VD179tT58+c1a9YsVaxYUXFxcff02DZu3FgWi0XPPfecvL29dfjwYX322Wdq3rx5hjWwt8rp5+RePchjK938wOi8efM0ePBg7dixQ3Xq1FFCQoJWr16t119/Xa1atXqgn+t33nlH3333nZo2baoBAwaocOHCmjt3rk6ePKkff/zxnj8HkB2dO3fWokWL1KdPH61bt07PPfecbty4oT///FOLFi3SypUrbb7g525cXFwUFBSkhQsXqly5cipcuLCefPJJPfnkkw/0HEiSt7e33nzzTU2cOFEvvPCCmjRpon379mn58uUqWrSozWzu0KFDtWTJErVo0ULdunVT9erVlZCQoAMHDuiHH37QqVOnVLRo0TuOF8ggF648AeRZ6ZekSr85OjoaFovFeP75542pU6faXGos3e2XQVuzZo3RqlUrw8fHx3B0dDR8fHyMV155JcMlfH799VcjKCjIcHBwsLnMU7169bK8LFVWl0H77rvvjOHDhxteXl6Gi4uL0bx5c+P06dMZ9p84caJRokQJw8nJyXjuueeMXbt2ZXoprazGdvvltQzj5iWeBg0aZPj4+Bj58+c3ypYta3z88cc2l7wyjJuXQcvssmNZXZ7tdqdPnzZeeOEFw9XV1ShatKjx5ptvGitWrLC55Fa6PXv2GG3atDGKFCliODk5GX5+fkb79u2NNWvWGIZx8xJSQ4cONapUqWIULFjQcHNzM6pUqWLMmDHjruNIFxERYUgy7OzsjDNnzmTYfvbsWePFF180PD09DQ8PD+Oll14yzp07l+EyTbdfBi3dunXrjNDQUMPDw8NwdnY2ypQpY3Tr1s3YtWuXTd23335rPPHEE4ajo6NRtWpVY+XKlVleBu3jjz/OMM7PP//cqFu3rvWxKlOmjDF06FDjypUrd30McvI5yUpml0G718c2K9euXTPeffddw9/f38ifP79hsViMdu3aGcePH7fW3OvPdWY/v8ePHzfatWtneHp6Gs7OzsYzzzxjLF261KYm/Xd38eLFdz3frF4TMvt9TE5ONsaPH29UrFjRcHJyMgoVKmRUr17dGDly5D09p7fbunWrUb16dcPR0dHm8b3X5yD99TGzy0KmpqYa77//vmGxWAwXFxejYcOGxuHDh40iRYoYffr0sam9evWqMXz4cCMgIMBwdHQ0ihYtatSqVcv45JNPjOTk5LuOF7idnWHk0KdPAAAAHsDly5dVqFAhffjhh3r33Xdzezh4jLEGGAAAPHLXr1/P0Ja+jjizr/gGchJrgAEAwCO3cOFChYeHq1mzZipQoIA2b96s7777To0bN77rdaiBB0UABgAAj1zlypXl4OCgCRMmKC4uzvrBuA8//DC3hwYTYA0wAAAATIU1wAAAADAVAjAAAABMhTXA9yAtLU3nzp1TwYIF+apFAACAPMgwDF29elU+Pj53/dIZAvA9OHfunHx9fXN7GAAAALiLM2fOqGTJknesIQDfg/SvAz1z5ozc3d1zeTQAAAC4XVxcnHx9fe/4Ne7pCMD3IH3Zg7u7OwEYAAAgD7uX5ap8CA4AAACmQgAGAACAqRCAAQBAlo4dO6YOHTqoZMmScnV1VYUKFTRq1Chdu3bNpm7r1q2qXbu2XF1dZbFYNGDAAMXHx9vUxMfH64MPPlCTJk1UuHBh2dnZKTw8PNPj2tnZZXl7/vnnH9bpwiRYAwwAADJ15swZPfPMM/Lw8FD//v1VuHBhRUZG6oMPPtDu3bv166+/SpL27t2rRo0aKTAwUJMmTdLZs2f1ySef6NixY1q+fLm1vwsXLmjUqFEqVaqUqlSpovXr12d57G+++SZD265duzR16lQ1btw4x88VJmPgrq5cuWJIMq5cuZLbQ0Ee07VrV0NSlrezZ88ahmEYycnJRlhYmOHv7284Ojoa/v7+xujRo42UlJQMfR49etR4+eWXjRIlShguLi5G+fLljZEjRxoJCQk2dWPGjDFq1qxpFC1a1HBycjICAgKMN9980zh//vwjOXcAj78xY8YYkow//vjDpr1Lly6GJOPixYuGYRhG06ZNjeLFi9v8Pzl79mxDkrFy5UprW2JiohEdHW0YhmHs3LnTkGTMmTPnnsfTs2dPw87Ozjhz5swDnBUeV/eT15gBBh7Af/7zH4WEhNi0GYahPn36qHTp0ipRooQk6dVXX9XixYvVo0cP1ahRQ9u2bdP777+vqKgoffHFF9Z973W2RZJ2796tqlWrqkOHDipYsKAOHz6s2bNna9myZdq7d6/c3NwezYMA4LEVFxcnSfL29rZpL168uOzt7eXo6Ki4uDhFRERo0KBBNldK6tKliwYNGqRFixZZZ2ydnJxksViyNZakpCT9+OOPqlev3l2v8Qrc1cPP4//7mAHG/di0aZMhyRgzZoxhGIaxY8cOQ5Lx/vvv29S99dZbhp2dnbFv3z5r273OtmTlhx9+MCQZ3333XQ6dDQAzW758uSHJeOGFF4w9e/YYUVFRxvfff2+4u7sbAwcONAzDMDZv3mxIMhYuXJhh/9q1axvVqlXLtO/7nQH+6aefDEnG7Nmzs30+eLzdT17jQ3BADluwYIHs7OzUsWNHSdKmTZskSR06dLCp69ChgwzD0MKFC61t9zLbcielS5eWJF2+fPlBTgEAJElNmjTR6NGjFRERoaeeekqlSpVShw4d9MYbb2jy5MmSpOjoaEk3X6duV7x4cZ07dy5HxjJ//nw5OTmpXbt2OdIfzI0ADOSglJQULVq0SLVq1bKG0aSkJEmSi4uLTa2rq6ukm0sZ0tWvX1+S1LNnT+3du1dnzpzRwoULNXPmTA0YMCDDsgbDMHThwgXFxMRo06ZNGjBggPLly2ftBwAeVOnSpVW3bl198cUX+vHHH9WjRw+NHTtWn332mSTp+vXrkm4ub7ids7OzdfuDiIuL07Jly9SsWTN5eno+cH8Aa4CBHLRy5Ur9+++/6tSpk7WtfPnykqQtW7bI39/f2p4+M/z3339b29JnW8aOHaslS5ZY29999119+OGHGY4XGxtrM+tSsmRJLViwQBUqVMi5kwJgWt9//7169+6to0ePWtfdtmnTRmlpaXr77bf1yiuvWN/cp7/Zv1ViYmKGN//Z8eOPPyoxMdHmtRV4EARgIActWLBA+fPnV/v27a1tzZo1k5+fn4YMGSJXV1dVr15d27dv17vvvisHB4cMsyPpsy1t27ZVkSJFtGzZMo0dO1YWi0X9+/e3qS1cuLAiIiKUmJioPXv26Keffspw3U0AyK4ZM2boqaeeyvChsxdeeEHh4eHas2eP9U14+lKIW0VHR8vHx+eBxzF//nx5eHioRYsWD9wXIBGAgRwTHx+vX3/9VaGhoSpSpIi13dnZWcuWLVP79u3Vtm1bSTf/VDhhwgSNGTNGBQoUsNbey2zLrX07Ojpar0LRokULNWrUSM8995y8vLz4jwLAA4uNjVWhQoUytKekpEiSUlNT9eSTT8rBwUG7du2yefOfnJysvXv32rRlR3R0tNatW6du3bpluswCyA7WAAM55JdfftG1a9cy/RNdxYoV9ccff+iPP/7Qpk2bdO7cOfXq1UsXLlxQuXLlrHV3mm25du2a9uzZc8cx1KpVS8WLF9f8+fNz5qQAmFq5cuW0Z88eHT161Kb9u+++k729vSpXriwPDw+FhITo22+/1dWrV60133zzjeLj4/XSSy890Bi+//57paWlsfwBOYoZYCCHzJ8/XwUKFNALL7yQ6XY7OztVrFjRev/3339XWlqazXWE72W25W4SExN15cqV+x0+AGQwdOhQLV++XHXq1FH//v1VpEgRLV26VMuXL9drr71mXd4wZswY1apVS/Xq1VPv3r119uxZTZw4UY0bN1aTJk1s+vzss890+fJl69UhfvvtN509e1aS9MYbb8jDw8Omfv78+fLx8eHDvchZD/2ibI8BrgOMuzl//rzh4OBgdO7c+Z7qr127ZlSrVs0oXry4ERcXZ21v0aKF4ejoaBw5csSmvnXr1oa9vb3x999/G4ZhGPHx8Rm+Gc4w/t91gG+/5jAAZNf27duNpk2bGhaLxcifP79Rrlw5Y8yYMRm+yXLTpk1GrVq1DGdnZ6NYsWJGv379bF7f0vn5+WX57ZknT560qf3zzz8NScbgwYMf5iniMXE/ec3OMAwjt8L3/4q4uDh5eHjoypUrNt9yA6T77LPP9MYbb2jFihUKDQ3NsL19+/by8fFRUFCQ4uLi9PXXX+vEiRNatmyZGjVqZK3buHGjGjZsqCJFimQ62zJ79mxJ0t69exUSEqKXX35ZFSpUkL29vXbt2qVvv/1WJUuW1K5du2zWCgMA8Li7n7yWq2uAb9y4offff1/+/v5ycXFRmTJlNHr0aN2ayQ3D0IgRI1S8eHG5uLgoJCREx44ds+nn4sWL6tSpk9zd3eXp6amePXtm+CT8/v37VadOHTk7O8vX11cTJkx4JOcIc5g/f768vLwyfC1yuho1amjlypV68803NXbsWJUtW1bbtm2zCb+SVLduXW3dulXVq1fXjBkzNHDgQB0/flxjxozRzJkzrXUlS5ZU27ZttXbtWg0fPlyDBw/Wli1b1L9/f+3cuZPwCwDAHeTqDPDYsWM1adIkzZ07VxUrVtSuXbvUvXt3jRkzRgMGDJAkjR8/XuPGjdPcuXPl7++v999/XwcOHNChQ4fk7OwsSWratKmio6P1+eefKyUlRd27d9fTTz+tBQsWSLr5jqBcuXIKCQnR8OHDdeDAAfXo0UNTpkxR79697zpOZoABAADytvvJa7kagFu0aCFvb2999dVX1ra2bdvKxcVF3377rQzDkI+Pj9566y0NGTJEknTlyhV5e3srPDxcHTp00OHDhxUUFKSdO3eqRo0akqQVK1aoWbNmOnv2rHx8fDRz5ky9++67iomJsX6V7DvvvKNffvlFf/75513HSQAGgJwXFRWlCxcu5PYwADxERYsWValSpR7Jse4nr+XqVSBq1aqlL774QkePHlW5cuW0b98+bd68WZMmTZIknTx5UjExMTZ/Vvbw8FDNmjUVGRmpDh06KDIyUp6entbwK0khISGyt7fX9u3b9eKLLyoyMlJ169a1hl9JCg0N1fjx43Xp0qUMn7pPSkqy+UabuLi4h/UQAIApRUVFqUJgoK5fu5bbQwHwELm4uurPw4cfWQi+V7kagN955x3FxcWpQoUKypcvn27cuKExY8ZYr/UXExMjSfL29rbZz9vb27otJiZGXl5eNtsdHBxUuHBhm5pbv4L21j5jYmIyBOBx48Zp5MiROXSW2cfsCPD4e5SzI3nJhQsXdP3aNbX/cKa8/Mvm9nAAPATnTx7Tovf66sKFC3nudS5XA/CiRYs0f/58LViwQBUrVtTevXs1cOBA+fj4qGvXrrk2rvQPFaWLi4uTr6/vIx0DsyOAOeTV2ZFHxcu/rEoEVsntYQAwmVwNwEOHDtU777yjDh06SJIqVaqk06dPa9y4ceratassFoukm18OkP5d4+n3q1atKkmyWCw6f/68Tb+pqam6ePGidX+LxaLY2FibmvT76TW3cnJyyvWvW2R2BHj85eXZEQB4nOVqAL527Zrs7W2vxJYvXz6lpaVJkvz9/WWxWLRmzRpr4I2Li9P27dvVt29fSVJwcLAuX76s3bt3q3r16pKktWvXKi0tTTVr1rTWvPvuu0pJSVH+/PklSRERESpfvnym37qVlzA7AgAAkLNy9TrALVu21JgxY7Rs2TKdOnVKP//8syZNmqQXX3xR0s2vjh04cKA+/PBDLVmyRAcOHFCXLl3k4+Oj1q1bS5ICAwPVpEkT9erVSzt27LBeC7VDhw7Wr2js2LGjHB0d1bNnTx08eFALFy7U1KlTbZY5AAAAwBxydQb4008/1fvvv6/XX39d58+fl4+Pj/7zn/9oxIgR1pphw4YpISFBvXv31uXLl1W7dm2tWLHCeg1g6eaXEPTv31+NGjWSvb292rZtq2nTplm3e3h4aNWqVerXr5+qV6+uokWLasSIEfd0DWAAAAA8XnI1ABcsWFBTpkzRlClTsqyxs7PTqFGjNGrUqCxrChcubP3Si6xUrlxZmzZtyu5QAQAA8JjI1SUQAAAAwKNGAAYAAICpEIABAABgKgRgAAAAmAoBGAAAAKZCAAYAAICpEIABAABgKgRgAAAAmAoBGAAAAKZCAAYAAICpEIABAABgKgRgAAAAmAoBGAAAAKZCAAYAAICpEIABAABgKgRgAAAAmAoBGAAAAKZCAAYAAICpEIABAABgKgRgAAAAmAoBGAAAAKZCAAYAAICpEIABAABgKgRgAAAAmAoBGAAAAKZCAAYAAICpEIABAABgKgRgAAAAmAoBGAAAAKZCAAYAAICpEIABAABgKgRgAAAAmAoBGAAAAKZCAAYAAICpEIABAABgKgRgAAAAmAoBGAAAAKZCAAYAAICpEIABAABgKgRgAAAAmAoBGAAAAKZCAAYAAICpEIABAABgKgRgAAAAmEquBuDSpUvLzs4uw61fv36SpMTERPXr109FihRRgQIF1LZtW8XGxtr0ERUVpebNm8vV1VVeXl4aOnSoUlNTbWrWr1+vatWqycnJSQEBAQoPD39UpwgAAIA8JlcD8M6dOxUdHW29RURESJJeeuklSdKgQYP022+/afHixdqwYYPOnTunNm3aWPe/ceOGmjdvruTkZG3dulVz585VeHi4RowYYa05efKkmjdvrgYNGmjv3r0aOHCgXnvtNa1cufLRniwAAADyBIfcPHixYsVs7n/00UcqU6aM6tWrpytXruirr77SggUL1LBhQ0nSnDlzFBgYqG3btunZZ5/VqlWrdOjQIa1evVre3t6qWrWqRo8erbffflthYWFydHTUrFmz5O/vr4kTJ0qSAgMDtXnzZk2ePFmhoaGP/JwBAACQu/LMGuDk5GR9++236tGjh+zs7LR7926lpKQoJCTEWlOhQgWVKlVKkZGRkqTIyEhVqlRJ3t7e1prQ0FDFxcXp4MGD1ppb+0ivSe8jM0lJSYqLi7O5AQAA4PGQZwLwL7/8osuXL6tbt26SpJiYGDk6OsrT09OmztvbWzExMdaaW8Nv+vb0bXeqiYuL0/Xr1zMdy7hx4+Th4WG9+fr6PujpAQAAII/IMwH4q6++UtOmTeXj45PbQ9Hw4cN15coV6+3MmTO5PSQAAADkkFxdA5zu9OnTWr16tX766Sdrm8ViUXJysi5fvmwzCxwbGyuLxWKt2bFjh01f6VeJuLXm9itHxMbGyt3dXS4uLpmOx8nJSU5OTg98XgAAAMh78sQM8Jw5c+Tl5aXmzZtb26pXr678+fNrzZo11rYjR44oKipKwcHBkqTg4GAdOHBA58+ft9ZERETI3d1dQUFB1ppb+0ivSe8DAAAA5pLrATgtLU1z5sxR165d5eDw/yakPTw81LNnTw0ePFjr1q3T7t271b17dwUHB+vZZ5+VJDVu3FhBQUHq3Lmz9u3bp5UrV+q9995Tv379rDO4ffr00YkTJzRs2DD9+eefmjFjhhYtWqRBgwblyvkCAAAgd+X6EojVq1crKipKPXr0yLBt8uTJsre3V9u2bZWUlKTQ0FDNmDHDuj1fvnxaunSp+vbtq+DgYLm5ualr164aNWqUtcbf31/Lli3ToEGDNHXqVJUsWVJffvkll0ADAAAwqVwPwI0bN5ZhGJluc3Z21vTp0zV9+vQs9/fz89Pvv/9+x2PUr19fe/bseaBxAgAA4PGQ60sgAAAAgEeJAAwAAABTIQADAADAVAjAAAAAMBUCMAAAAEyFAAwAAABTIQADAADAVAjAAAAAMBUCMAAAAEyFAAwAAABTIQADAADAVAjAAAAAMBUCMAAAAEyFAAwAAABTIQADAADAVAjAAAAAMBUCMAAAAEyFAAwAAABTIQADAADAVAjAAAAAMBUCMAAAAEyFAAwAAABTIQADAADAVAjAAAAAMBUCMAAAAEyFAAwAAABTIQADAADAVAjAAAAAMBUCMAAAAEyFAAwAAABTIQADAADAVAjAAAAAMBUCMAAAAEyFAAwAAABTIQADAADAVAjAAAAAMBUCMAAAAEyFAAwAAABTIQADAADAVAjAAAAAMBUCMAAAAEyFAAwAAABTIQADAADAVAjAAAAAMJVcD8B///23Xn31VRUpUkQuLi6qVKmSdu3aZd1uGIZGjBih4sWLy8XFRSEhITp27JhNHxcvXlSnTp3k7u4uT09P9ezZU/Hx8TY1+/fvV506deTs7CxfX19NmDDhkZwfAAAA8pZcDcCXLl3Sc889p/z582v58uU6dOiQJk6cqEKFCllrJkyYoGnTpmnWrFnavn273NzcFBoaqsTERGtNp06ddPDgQUVERGjp0qXauHGjevfubd0eFxenxo0by8/PT7t379bHH3+ssLAwffHFF4/0fAEAAJD7HHLz4OPHj5evr6/mzJljbfP397f+2zAMTZkyRe+9955atWolSZo3b568vb31yy+/qEOHDjp8+LBWrFihnTt3qkaNGpKkTz/9VM2aNdMnn3wiHx8fzZ8/X8nJyfr666/l6OioihUrau/evZo0aZJNUE6XlJSkpKQk6/24uLiH9RAAAADgEcvVGeAlS5aoRo0aeumll+Tl5aWnnnpKs2fPtm4/efKkYmJiFBISYm3z8PBQzZo1FRkZKUmKjIyUp6enNfxKUkhIiOzt7bV9+3ZrTd26deXo6GitCQ0N1ZEjR3Tp0qUM4xo3bpw8PDysN19f3xw/dwAAAOSOXA3AJ06c0MyZM1W2bFmtXLlSffv21YABAzR37lxJUkxMjCTJ29vbZj9vb2/rtpiYGHl5edlsd3BwUOHChW1qMuvj1mPcavjw4bpy5Yr1dubMmRw4WwAAAOQFuboEIi0tTTVq1NDYsWMlSU899ZT++OMPzZo1S127ds21cTk5OcnJySnXjg8AAICHJ1dngIsXL66goCCbtsDAQEVFRUmSLBaLJCk2NtamJjY21rrNYrHo/PnzNttTU1N18eJFm5rM+rj1GAAAADCHXA3Azz33nI4cOWLTdvToUfn5+Um6+YE4i8WiNWvWWLfHxcVp+/btCg4OliQFBwfr8uXL2r17t7Vm7dq1SktLU82aNa01GzduVEpKirUmIiJC5cuXt7niBAAAAB5/uRqABw0apG3btmns2LH666+/tGDBAn3xxRfq16+fJMnOzk4DBw7Uhx9+qCVLlujAgQPq0qWLfHx81Lp1a0k3Z4ybNGmiXr16aceOHdqyZYv69++vDh06yMfHR5LUsWNHOTo6qmfPnjp48KAWLlyoqVOnavDgwbl16gAAAMgluboG+Omnn9bPP/+s4cOHa9SoUfL399eUKVPUqVMna82wYcOUkJCg3r176/Lly6pdu7ZWrFghZ2dna838+fPVv39/NWrUSPb29mrbtq2mTZtm3e7h4aFVq1apX79+ql69uooWLaoRI0Zkegk0AAAAPN5yNQBLUosWLdSiRYsst9vZ2WnUqFEaNWpUljWFCxfWggUL7nicypUra9OmTdkeJwAAAB4Puf5VyAAAAMCjRAAGAACAqRCAAQAAYCoEYAAAAJgKARgAAACmQgAGAACAqRCAAQAAYCoEYAAAAJgKARgAAACmQgAGAACAqRCAAQAAYCoEYAAAAJgKARgAAACmQgAGAACAqRCAAQAAYCoEYAAAAJgKARgAAACmQgAGAACAqRCAAQAAYCoEYAAAAJgKARgAAACmQgAGAACAqRCAAQAAYCoEYAAAAJgKARgAAACmQgAGAACAqRCAAQAAYCoEYAAAAJgKARgAAACmQgAGAACAqRCAAQAAYCoEYAAAAJgKARgAAACmQgAGAACAqRCAAQAAYCoEYAAAAJgKARgAAACmQgAGAACAqRCAAQAAYCoEYAAAAJgKARgAAACmQgAGAACAqRCAAQAAYCq5GoDDwsJkZ2dnc6tQoYJ1e2Jiovr166ciRYqoQIECatu2rWJjY236iIqKUvPmzeXq6iovLy8NHTpUqampNjXr169XtWrV5OTkpICAAIWHhz+K0wMAAEAelOszwBUrVlR0dLT1tnnzZuu2QYMG6bffftPixYu1YcMGnTt3Tm3atLFuv3Hjhpo3b67k5GRt3bpVc+fOVXh4uEaMGGGtOXnypJo3b64GDRpo7969GjhwoF577TWtXLnykZ4nAAAA8gaHXB+Ag4MsFkuG9itXruirr77SggUL1LBhQ0nSnDlzFBgYqG3btunZZ5/VqlWrdOjQIa1evVre3t6qWrWqRo8erbffflthYWFydHTUrFmz5O/vr4kTJ0qSAgMDtXnzZk2ePFmhoaGP9FwBAACQ+3J9BvjYsWPy8fHRE088oU6dOikqKkqStHv3bqWkpCgkJMRaW6FCBZUqVUqRkZGSpMjISFWqVEne3t7WmtDQUMXFxengwYPWmlv7SK9J7yMzSUlJiouLs7kBAADg8ZCrAbhmzZoKDw/XihUrNHPmTJ08eVJ16tTR1atXFRMTI0dHR3l6etrs4+3trZiYGElSTEyMTfhN356+7U41cXFxun79eqbjGjdunDw8PKw3X1/fnDhdAAAA5AG5ugSiadOm1n9XrlxZNWvWlJ+fnxYtWiQXF5dcG9fw4cM1ePBg6/24uDhCMAAAwGMi15dA3MrT01PlypXTX3/9JYvFouTkZF2+fNmmJjY21rpm2GKxZLgqRPr9u9W4u7tnGbKdnJzk7u5ucwMAAMDjIU8F4Pj4eB0/flzFixdX9erVlT9/fq1Zs8a6/ciRI4qKilJwcLAkKTg4WAcOHND58+etNREREXJ3d1dQUJC15tY+0mvS+wAAAIC55GoAHjJkiDZs2KBTp05p69atevHFF5UvXz698sor8vDwUM+ePTV48GCtW7dOu3fvVvfu3RUcHKxnn31WktS4cWMFBQWpc+fO2rdvn1auXKn33ntP/fr1k5OTkySpT58+OnHihIYNG6Y///xTM2bM0KJFizRo0KDcPHUAAADkklxdA3z27Fm98sor+vfff1WsWDHVrl1b27ZtU7FixSRJkydPlr29vdq2baukpCSFhoZqxowZ1v3z5cunpUuXqm/fvgoODpabm5u6du2qUaNGWWv8/f21bNkyDRo0SFOnTlXJkiX15Zdfcgk0AAAAk8rVAPz999/fcbuzs7OmT5+u6dOnZ1nj5+en33///Y791K9fX3v27MnWGAEAAPB4yVNrgAEAAICHjQAMAAAAUyEAAwAAwFQIwAAAADCVbAXgEydO5PQ4AAAAgEciWwE4ICBADRo00LfffqvExMScHhMAAADw0GQrAP/3v/9V5cqVNXjwYFksFv3nP//Rjh07cnpsAAAAQI7LVgCuWrWqpk6dqnPnzunrr79WdHS0ateurSeffFKTJk3SP//8k9PjBAAAAHLEA30IzsHBQW3atNHixYs1fvx4/fXXXxoyZIh8fX3VpUsXRUdH59Q4AQAAgBzxQAF4165dev3111W8eHFNmjRJQ4YM0fHjxxUREaFz586pVatWOTVOAAAAIEdk66uQJ02apDlz5ujIkSNq1qyZ5s2bp2bNmsne/mae9vf3V3h4uEqXLp2TYwUAAAAeWLYC8MyZM9WjRw9169ZNxYsXz7TGy8tLX3311QMNDgAAAMhp2QrAx44du2uNo6Ojunbtmp3uAQAAgIcmW2uA58yZo8WLF2doX7x4sebOnfvAgwIAAAAelmwF4HHjxqlo0aIZ2r28vDR27NgHHhQAAADwsGQrAEdFRcnf3z9Du5+fn6Kioh54UAAAAMDDkq0A7OXlpf3792do37dvn4oUKfLAgwIAAAAelmwF4FdeeUUDBgzQunXrdOPGDd24cUNr167Vm2++qQ4dOuT0GAEAAIAck62rQIwePVqnTp1So0aN5OBws4u0tDR16dKFNcAAAADI07IVgB0dHbVw4UKNHj1a+/btk4uLiypVqiQ/P7+cHh8AAACQo7IVgNOVK1dO5cqVy6mxAAAAAA9dtgLwjRs3FB4erjVr1uj8+fNKS0uz2b527docGRwAAACQ07IVgN98802Fh4erefPmevLJJ2VnZ5fT4wIAAAAeimwF4O+//16LFi1Ss2bNcno8AAAAwEOVrcugOTo6KiAgIKfHAgAAADx02QrAb731lqZOnSrDMHJ6PAAAAMBDla0lEJs3b9a6deu0fPlyVaxYUfnz57fZ/tNPP+XI4AAAAICclq0A7OnpqRdffDGnxwIAAAA8dNkKwHPmzMnpcQAAAACPRLbWAEtSamqqVq9erc8//1xXr16VJJ07d07x8fE5NjgAAAAgp2VrBvj06dNq0qSJoqKilJSUpOeff14FCxbU+PHjlZSUpFmzZuX0OAEAAIAcka0Z4DfffFM1atTQpUuX5OLiYm1/8cUXtWbNmhwbHAAAAJDTsjUDvGnTJm3dulWOjo427aVLl9bff/+dIwMDAAAAHoZszQCnpaXpxo0bGdrPnj2rggULPvCgAAAAgIclWwG4cePGmjJlivW+nZ2d4uPj9cEHH/D1yAAAAMjTsrUEYuLEiQoNDVVQUJASExPVsWNHHTt2TEWLFtV3332X02MEAAAAcky2AnDJkiW1b98+ff/999q/f7/i4+PVs2dPderUyeZDcQAAAEBek60ALEkODg569dVXc3IsAAAAwEOXrQA8b968O27v0qVLtgYDAAAAPGzZCsBvvvmmzf2UlBRdu3ZNjo6OcnV1JQADAAAgz8rWVSAuXbpkc4uPj9eRI0dUu3ZtPgQHAACAPC1bATgzZcuW1UcffZRhdhgAAADIS3IsAEs3Pxh37ty5nOwSAAAAyFHZWgO8ZMkSm/uGYSg6OlqfffaZnnvuuRwZGAAAAPAwZGsGuHXr1ja3Nm3aKCwsTJUrV9bXX3+drYF89NFHsrOz08CBA61tiYmJ6tevn4oUKaICBQqobdu2io2NtdkvKipKzZs3l6urq7y8vDR06FClpqba1Kxfv17VqlWTk5OTAgICFB4enq0xAgAA4H9ftmaA09LScnQQO3fu1Oeff67KlSvbtA8aNEjLli3T4sWL5eHhof79+6tNmzbasmWLJOnGjRtq3ry5LBaLtm7dqujoaHXp0kX58+fX2LFjJUknT55U8+bN1adPH82fP19r1qzRa6+9puLFiys0NDRHzwMAAAB5X46uAc6O+Ph4derUSbNnz1ahQoWs7VeuXNFXX32lSZMmqWHDhqpevbrmzJmjrVu3atu2bZKkVatW6dChQ/r2229VtWpVNW3aVKNHj9b06dOVnJwsSZo1a5b8/f01ceJEBQYGqn///mrXrp0mT56cK+cLAACA3JWtGeDBgwffc+2kSZPuuL1fv35q3ry5QkJC9OGHH1rbd+/erZSUFIWEhFjbKlSooFKlSikyMlLPPvusIiMjValSJXl7e1trQkND1bdvXx08eFBPPfWUIiMjbfpIr7l1qcXtkpKSlJSUZL0fFxd3r6cLAACAPC5bAXjPnj3as2ePUlJSVL58eUnS0aNHlS9fPlWrVs1aZ2dnd8d+vv/+e/33v//Vzp07M2yLiYmRo6OjPD09bdq9vb0VExNjrbk1/KZvT992p5q4uDhdv35dLi4uGY49btw4jRw58o5jBwAAwP+mbAXgli1bqmDBgpo7d6512cKlS5fUvXt31alTR2+99dZd+zhz5ozefPNNRUREyNnZOTvDeGiGDx9uM8sdFxcnX1/fXBwRAAAAckq21gBPnDhR48aNs1mzW6hQIX344YeaOHHiPfWxe/dunT9/XtWqVZODg4McHBy0YcMGTZs2TQ4ODvL29lZycrIuX75ss19sbKwsFoskyWKxZLgqRPr9u9W4u7tnOvsrSU5OTnJ3d7e5AQAA4PGQrQAcFxenf/75J0P7P//8o6tXr95TH40aNdKBAwe0d+9e661GjRrq1KmT9d/58+fXmjVrrPscOXJEUVFRCg4OliQFBwfrwIEDOn/+vLUmIiJC7u7uCgoKstbc2kd6TXofAAAAMJdsLYF48cUX1b17d02cOFHPPPOMJGn79u0aOnSo2rRpc099FCxYUE8++aRNm5ubm4oUKWJt79mzpwYPHqzChQvL3d1db7zxhoKDg/Xss89Kkho3bqygoCB17txZEyZMUExMjN577z3169dPTk5OkqQ+ffros88+07Bhw9SjRw+tXbtWixYt0rJly7Jz6gAAAPgfl60APGvWLA0ZMkQdO3ZUSkrKzY4cHNSzZ099/PHHOTa4yZMny97eXm3btlVSUpJCQ0M1Y8YM6/Z8+fJp6dKl6tu3r4KDg+Xm5qauXbtq1KhR1hp/f38tW7ZMgwYN0tSpU1WyZEl9+eWXXAMYAADApLIVgF1dXTVjxgx9/PHHOn78uCSpTJkycnNze6DBrF+/3ua+s7Ozpk+frunTp2e5j5+fn37//fc79lu/fn3t2bPngcYGAACAx8MDfRFGdHS0oqOjVbZsWbm5uckwjJwaFwAAAPBQZCsA//vvv2rUqJHKlSunZs2aKTo6WtLNNbv3cgk0AAAAILdkKwAPGjRI+fPnV1RUlFxdXa3tL7/8slasWJFjgwMAAAByWrbWAK9atUorV65UyZIlbdrLli2r06dP58jAAAAAgIchWzPACQkJNjO/6S5evGi9/BgAAACQF2UrANepU0fz5s2z3rezs1NaWpomTJigBg0a5NjgAAAAgJyWrSUQEyZMUKNGjbRr1y4lJydr2LBhOnjwoC5evKgtW7bk9BgBAACAHJOtGeAnn3xSR48eVe3atdWqVSslJCSoTZs22rNnj8qUKZPTYwQAAAByzH3PAKekpKhJkyaaNWuW3n333YcxJgAAAOChue8Z4Pz582v//v0PYywAAADAQ5etJRCvvvqqvvrqq5weCwAAAPDQZetDcKmpqfr666+1evVqVa9eXW5ubjbbJ02alCODAwAAAHLafQXgEydOqHTp0vrjjz9UrVo1SdLRo0dtauzs7HJudAAAAEAOu68AXLZsWUVHR2vdunWSbn718bRp0+Tt7f1QBgcAAADktPtaA2wYhs395cuXKyEhIUcHBAAAADxM2foQXLrbAzEAAACQ191XALazs8uwxpc1vwAAAPhfcl9rgA3DULdu3eTk5CRJSkxMVJ8+fTJcBeKnn37KuRECAAAAOei+AnDXrl1t7r/66qs5OhgAAADgYbuvADxnzpyHNQ4AAADgkXigD8EBAAAA/2sIwAAAADAVAjAAAABMhQAMAAAAUyEAAwAAwFQIwAAAADAVAjAAAABMhQAMAAAAUyEAAwAAwFQIwAAAADAVAjAAAABMhQAMAAAAUyEAAwAAwFQIwAAAADAVAjAAAABMhQAMAAAAUyEAAwAAwFQIwAAAADAVAjAAAABMhQAMAAAAUyEAAwAAwFQIwAAAADAVAjAAAABMhQAMAAAAU8nVADxz5kxVrlxZ7u7ucnd3V3BwsJYvX27dnpiYqH79+qlIkSIqUKCA2rZtq9jYWJs+oqKi1Lx5c7m6usrLy0tDhw5VamqqTc369etVrVo1OTk5KSAgQOHh4Y/i9AAAAJAH5WoALlmypD766CPt3r1bu3btUsOGDdWqVSsdPHhQkjRo0CD99ttvWrx4sTZs2KBz586pTZs21v1v3Lih5s2bKzk5WVu3btXcuXMVHh6uESNGWGtOnjyp5s2bq0GDBtq7d68GDhyo1157TStXrnzk5wsAAIDc55CbB2/ZsqXN/TFjxmjmzJnatm2bSpYsqa+++koLFixQw4YNJUlz5sxRYGCgtm3bpmeffVarVq3SoUOHtHr1anl7e6tq1aoaPXq03n77bYWFhcnR0VGzZs2Sv7+/Jk6cKEkKDAzU5s2bNXnyZIWGhj7ycwYAAEDuyjNrgG/cuKHvv/9eCQkJCg4O1u7du5WSkqKQkBBrTYUKFVSqVClFRkZKkiIjI1WpUiV5e3tba0JDQxUXF2edRY6MjLTpI70mvY/MJCUlKS4uzuYGAACAx0OuB+ADBw6oQIECcnJyUp8+ffTzzz8rKChIMTExcnR0lKenp029t7e3YmJiJEkxMTE24Td9e/q2O9XExcXp+vXrmY5p3Lhx8vDwsN58fX1z4lQBAACQB+R6AC5fvrz27t2r7du3q2/fvuratasOHTqUq2MaPny4rly5Yr2dOXMmV8cDAACAnJOra4AlydHRUQEBAZKk6tWra+fOnZo6dapefvllJScn6/LlyzazwLGxsbJYLJIki8WiHTt22PSXfpWIW2tuv3JEbGys3N3d5eLikumYnJyc5OTklCPnBwAAgLwl12eAb5eWlqakpCRVr15d+fPn15o1a6zbjhw5oqioKAUHB0uSgoODdeDAAZ0/f95aExERIXd3dwUFBVlrbu0jvSa9DwAAAJhLrs4ADx8+XE2bNlWpUqV09epVLViwQOvXr9fKlSvl4eGhnj17avDgwSpcuLDc3d31xhtvKDg4WM8++6wkqXHjxgoKClLnzp01YcIExcTE6L333lO/fv2sM7h9+vTRZ599pmHDhqlHjx5au3atFi1apGXLluXmqQMAACCX5GoAPn/+vLp06aLo6Gh5eHiocuXKWrlypZ5//nlJ0uTJk2Vvb6+2bdsqKSlJoaGhmjFjhnX/fPnyaenSperbt6+Cg4Pl5uamrl27atSoUdYaf39/LVu2TIMGDdLUqVNVsmRJffnll1wCDQAAwKRyNQB/9dVXd9zu7Oys6dOna/r06VnW+Pn56ffff79jP/Xr19eePXuyNUYAAAA8XvLcGmAAAADgYSIAAwAAwFQIwAAAADAVAjAAAABMhQAMAAAAUyEAAwAAwFQIwAAAADAVAjAAAABMhQAMAAAAUyEAAwAAwFQIwAAAADAVAjAAAABMhQAMAAAAUyEAAwAAwFQIwAAAADAVAjAAAABMhQAMAAAAUyEAAwAAwFQIwAAAADAVAjAAAABMhQAMAAAAUyEAAwAAwFQIwAAAADAVAjAAAABMhQAMAAAAUyEAAwAAwFQIwAAAADAVAjAAAABMhQAMAAAAUyEAAwAAwFQIwAAAADAVAjAAAABMhQAMAAAAUyEAAwAAwFQIwAAAADAVAjAAAABMhQAMAAAAUyEAAwAAwFQIwAAAADAVAjAAAABMhQAMAAAAUyEAAwAAwFQIwAAAADAVAjAAAABMJVcD8Lhx4/T000+rYMGC8vLyUuvWrXXkyBGbmsTERPXr109FihRRgQIF1LZtW8XGxtrUREVFqXnz5nJ1dZWXl5eGDh2q1NRUm5r169erWrVqcnJyUkBAgMLDwx/26QEAACAPytUAvGHDBvXr10/btm1TRESEUlJS1LhxYyUkJFhrBg0apN9++02LFy/Whg0bdO7cObVp08a6/caNG2revLmSk5O1detWzZ07V+Hh4RoxYoS15uTJk2revLkaNGigvXv3auDAgXrttde0cuXKR3q+AAAAyH0OuXnwFStW2NwPDw+Xl5eXdu/erbp16+rKlSv66quvtGDBAjVs2FCSNGfOHAUGBmrbtm169tlntWrVKh06dEirV6+Wt7e3qlatqtGjR+vtt99WWFiYHB0dNWvWLPn7+2vixImSpMDAQG3evFmTJ09WaGjoIz9vAAAA5J48tQb4ypUrkqTChQtLknbv3q2UlBSFhIRYaypUqKBSpUopMjJSkhQZGalKlSrJ29vbWhMaGqq4uDgdPHjQWnNrH+k16X3cLikpSXFxcTY3AAAAPB7yTABOS0vTwIED9dxzz+nJJ5+UJMXExMjR0VGenp42td7e3oqJibHW3Bp+07enb7tTTVxcnK5fv55hLOPGjZOHh4f15uvrmyPnCAAAgNyXZwJwv3799Mcff+j777/P7aFo+PDhunLlivV25syZ3B4SAAAAckiurgFO179/fy1dulQbN25UyZIlre0Wi0XJycm6fPmyzSxwbGysLBaLtWbHjh02/aVfJeLWmtuvHBEbGyt3d3e5uLhkGI+Tk5OcnJxy5NwAAACQt+TqDLBhGOrfv79+/vlnrV27Vv7+/jbbq1evrvz582vNmjXWtiNHjigqKkrBwcGSpODgYB04cEDnz5+31kRERMjd3V1BQUHWmlv7SK9J7wMAAADmkaszwP369dOCBQv066+/qmDBgtY1ux4eHnJxcZGHh4d69uypwYMHq3DhwnJ3d9cbb7yh4OBgPfvss5Kkxo0bKygoSJ07d9aECRMUExOj9957T/369bPO4vbp00efffaZhg0bph49emjt2rVatGiRli1blmvnDgAAgNyRqzPAM2fO1JUrV1S/fn0VL17celu4cKG1ZvLkyWrRooXatm2runXrymKx6KeffrJuz5cvn5YuXap8+fIpODhYr776qrp06aJRo0ZZa/z9/bVs2TJFRESoSpUqmjhxor788ksugQYAAGBCuToDbBjGXWucnZ01ffp0TZ8+PcsaPz8//f7773fsp379+tqzZ899jxEAAACPlzxzFQgAAADgUSAAAwAAwFQIwAAAADAVAjAAAABMhQAMAAAAUyEAAwAAwFQIwAAAADAVAjAAAABMhQAMAAAAUyEAAwAAwFQIwAAAADAVAjAAAABMhQAMAAAAUyEAAwAAwFQIwAAAADAVAjAAAABMhQAMAAAAUyEAAwAAwFQIwAAAADAVAjAAAABMhQAMAAAAUyEAAwAAwFQIwAAAADAVAjAAAABMhQAMAAAAUyEAAwAAwFQIwAAAADAVAjAAAABMhQAMAAAAUyEAAwAAwFQIwAAAADAVAjAAAABMhQAMAAAAUyEAAwAAwFQIwAAAADAVAjAAAABMhQAMAAAAUyEAAwAAwFQIwAAAADAVAjAAAABMhQAMAAAAUyEAAwAAwFQIwAAAADAVAjAAAABMJVcD8MaNG9WyZUv5+PjIzs5Ov/zyi812wzA0YsQIFS9eXC4uLgoJCdGxY8dsai5evKhOnTrJ3d1dnp6e6tmzp+Lj421q9u/frzp16sjZ2Vm+vr6aMGHCwz41AAAA5FG5GoATEhJUpUoVTZ8+PdPtEyZM0LRp0zRr1ixt375dbm5uCg0NVWJiorWmU6dOOnjwoCIiIrR06VJt3LhRvXv3tm6Pi4tT48aN5efnp927d+vjjz9WWFiYvvjii4d+fgAAAMh7HHLz4E2bNlXTpk0z3WYYhqZMmaL33ntPrVq1kiTNmzdP3t7e+uWXX9ShQwcdPnxYK1as0M6dO1WjRg1J0qeffqpmzZrpk08+kY+Pj+bPn6/k5GR9/fXXcnR0VMWKFbV3715NmjTJJigDAADAHPLsGuCTJ08qJiZGISEh1jYPDw/VrFlTkZGRkqTIyEh5enpaw68khYSEyN7eXtu3b7fW1K1bV46Ojtaa0NBQHTlyRJcuXcr02ElJSYqLi7O5AQAA4PGQZwNwTEyMJMnb29um3dvb27otJiZGXl5eNtsdHBxUuHBhm5rM+rj1GLcbN26cPDw8rDdfX98HPyEAAADkCXk2AOem4cOH68qVK9bbmTNncntIAAAAyCF5NgBbLBZJUmxsrE17bGysdZvFYtH58+dttqempurixYs2NZn1cesxbufk5CR3d3ebGwAAAB4PeTYA+/v7y2KxaM2aNda2uLg4bd++XcHBwZKk4OBgXb58Wbt377bWrF27VmlpaapZs6a1ZuPGjUpJSbHWREREqHz58ipUqNAjOhsAAADkFbkagOPj47V3717t3btX0s0Pvu3du1dRUVGys7PTwIED9eGHH2rJkiU6cOCAunTpIh8fH7Vu3VqSFBgYqCZNmqhXr17asWOHtmzZov79+6tDhw7y8fGRJHXs2FGOjo7q2bOnDh48qIULF2rq1KkaPHhwLp01AAAAclOuXgZt165datCggfV+eijt2rWrwsPDNWzYMCUkJKh37966fPmyateurRUrVsjZ2dm6z/z589W/f381atRI9vb2atu2raZNm2bd7uHhoVWrVqlfv36qXr26ihYtqhEjRnAJNAAAAJPK1QBcv359GYaR5XY7OzuNGjVKo0aNyrKmcOHCWrBgwR2PU7lyZW3atCnb4wQAAMDjI8+uAQYAAAAeBgIwAAAATIUADAAAAFMhAAMAAMBUCMAAAAAwFQIwAAAATIUADAAAAFMhAAMAAMBUCMAAAAAwFQIwAAAATIUADAAAAFMhAAMAAMBUCMAAAAAwFQIwAAAATIUADAAAAFMhAAMAAMBUCMAAAAAwFQIwAAAATIUADAAAAFMhAAMAAMBUCMAAAAAwFQIwAAAATIUADAAAAFMhAAMAAMBUCMAAAAAwFQIwAAAATIUADAAAAFMhAAMAAMBUCMAAAAAwFQIwAAAATIUADAAAAFMhAAMAAMBUCMAAAAAwFQIwAAAATIUADAAAAFMhAAMAAMBUCMAAAAAwFQIwAAAATIUADAAAAFMhAAMAAMBUCMAAAAAwFQIwAAAATIUADAAAAFMhAAMAAMBUTBWAp0+frtKlS8vZ2Vk1a9bUjh07cntIAAAAeMRME4AXLlyowYMH64MPPtB///tfValSRaGhoTp//nxuDw0AAACPkGkC8KRJk9SrVy91795dQUFBmjVrllxdXfX111/n9tAAAADwCDnk9gAeheTkZO3evVvDhw+3ttnb2yskJESRkZEZ6pOSkpSUlGS9f+XKFUlSXFzcwx/s/y8+Pl6S9Pfh/Uq+lvDIjgvg0fnn9HFJN3/fH+XrS17Aaxzw+HvUr3HpxzAM4661dsa9VP2PO3funEqUKKGtW7cqODjY2j5s2DBt2LBB27dvt6kPCwvTyJEjH/UwAQAA8IDOnDmjkiVL3rHGFDPA92v48OEaPHiw9X5aWpouXryoIkWKyM7OLhdHhsdZXFycfH19debMGbm7u+f2cAAgR/Eah4fNMAxdvXpVPj4+d601RQAuWrSo8uXLp9jYWJv22NhYWSyWDPVOTk5ycnKyafP09HyYQwSs3N3d+c8BwGOL1zg8TB4eHvdUZ4oPwTk6Oqp69epas2aNtS0tLU1r1qyxWRIBAACAx58pZoAlafDgweratatq1KihZ555RlOmTFFCQoK6d++e20MDAADAI2SaAPzyyy/rn3/+0YgRIxQTE6OqVatqxYoV8vb2zu2hAZJuLr354IMPMiy/AYDHAa9xyEtMcRUIAAAAIJ0p1gADAAAA6QjAAAAAMBUCMAAAAEyFAAzkIaVLl9aUKVMe+nGOHDkii8Wiq1ev3vM+77zzjt54442HOCoAAB4NAjBMoVu3brKzs9NHH31k0/7LL7/kyrf7hYeHZ/rlKjt37lTv3r0f+vGHDx+uN954QwULFrS27d+/X3Xq1JGzs7N8fX01YcIEm32GDBmiuXPn6sSJEw99fADyrvXr18vOzk6XL1++Y11efkM/a9YstWzZ8iGOCnkdARim4ezsrPHjx+vSpUu5PZQsFStWTK6urg/1GFFRUVq6dKm6detmbYuLi1Pjxo3l5+en3bt36+OPP1ZYWJi++OILa03RokUVGhqqmTNnPtTxAXhw6W/67ezs5OjoqICAAI0aNUqpqakP3HetWrUUHR1t/catvPaGPjExUd26dVOlSpXk4OCg1q1bZ9inR48e+u9//6tNmzY99PEhbyIAwzRCQkJksVg0bty4O9Zt3rxZderUkYuLi3x9fTVgwAAlJCRYt0dHR6t58+ZycXGRv7+/FixYkGGmY9KkSapUqZLc3Nzk6+ur119/XfHx8ZJuzp50795dV65csf4HFRYWJsl2xqRjx456+eWXbcaWkpKiokWLat68eZJufqPhuHHj5O/vLxcXF1WpUkU//PDDHc9v0aJFqlKlikqUKGFtmz9/vpKTk/X111+rYsWK6tChgwYMGKBJkybZ7NuyZUt9//33d+wfQN7QpEkTRUdH69ixY3rrrbcUFhamjz/++IH7dXR0lMViuetfz3LrDf2NGzfk4uKiAQMGKCQkJNP9HB0d1bFjR02bNu2hjg95FwEYppEvXz6NHTtWn376qc6ePZtpzfHjx9WkSRO1bdtW+/fv18KFC7V582b179/fWtOlSxedO3dO69ev148//qgvvvhC58+ft+nH3t5e06ZN08GDBzV37lytXbtWw4YNk3Rz9mTKlClyd3dXdHS0oqOjNWTIkAxj6dSpk3777TdrcJaklStX6tq1a3rxxRclSePGjdO8efM0a9YsHTx4UIMGDdKrr76qDRs2ZPk4bNq0STVq1LBpi4yMVN26deXo6GhtCw0N1ZEjR2xmzJ955hmdPXtWp06dyrJ/AHmDk5OTLBaL/Pz81LdvX4WEhGjJkiWSpEuXLqlLly4qVKiQXF1d1bRpUx07dsy67+nTp9WyZUsVKlRIbm5uqlixon7//XdJtksg8uIbejc3N82cOVO9evWSxWLJct+WLVtqyZIlun79+r09oHisEIBhKi+++KKqVq2qDz74INPt48aNU6dOnTRw4ECVLVtWtWrV0rRp0zRv3jwlJibqzz//1OrVqzV79mzVrFlT1apV05dffpnhBXTgwIFq0KCBSpcurYYNG+rDDz/UokWLJN2cefDw8JCdnZ0sFossFosKFCiQYSyhoaFyc3PTzz//bG1bsGCBXnjhBRUsWFBJSUkaO3asvv76a4WGhuqJJ55Qt27d9Oqrr+rzzz/P8jE4ffq0fHx8bNpiYmIyfCti+v2YmBhrW/p+p0+fzrJ/AHmTi4uLkpOTJd1cIrFr1y4tWbJEkZGRMgxDzZo1U0pKiiSpX79+SkpK0saNG3XgwAGNHz8+09epvPiG/l7VqFFDqamp2r59e7b2x/8203wVMpBu/PjxatiwYaYv0vv27dP+/fs1f/58a5thGEpLS9PJkyd19OhROTg4qFq1atbtAQEBKlSokE0/q1ev1rhx4/Tnn38qLi5OqampSkxM1LVr1+75T4IODg5q37695s+fr86dOyshIUG//vqrdQnCX3/9pWvXrun555+32S85OVlPPfVUlv1ev35dzs7O9zSG27m4uEiSrl27lq39ATx6hmFozZo1Wrlypd544w0dO3ZMS5Ys0ZYtW1SrVi1JN5dB+fr66pdfftFLL72kqKgotW3bVpUqVZIkPfHEE5n2ffsb+qzc+oa+c+fOkjJ/Q7969WoFBwdbj7l582Z9/vnnqlevXqb9nj59OtsB2NXVVR4eHryhNykCMEynbt26Cg0N1fDhw23WjUlSfHy8/vOf/2jAgAEZ9itVqpSOHj161/5PnTqlFi1aqG/fvhozZowKFy6szZs3q2fPnkpOTr6vNXGdOnVSvXr1dP78eUVERMjFxUVNmjSxjlWSli1bZvPnP+nmnz6zUrRo0QwfBLRYLIqNjbVpS79/639qFy9elHRzbR+AvG3p0qUqUKCAUlJSlJaWpo4dOyosLExr1qyRg4ODatasaa0tUqSIypcvr8OHD0uSBgwYoL59+2rVqlUKCQlR27ZtVbly5WyPJS++oZduvqnnDb05EYBhSh999JGqVq2q8uXL27RXq1ZNhw4dUkBAQKb7lS9fXqmpqdqzZ4+qV68u6eYL962Bcvfu3UpLS9PEiRNlb39zlVH68od0jo6OunHjxl3HWatWLfn6+mrhwoVavny5XnrpJeXPn1+SFBQUJCcnJ0VFRWU5O5KZp556SocOHbJpCw4O1rvvvquUlBRr/xERESpfvrzN7PYff/yh/Pnzq2LFivd8PAC5o0GDBpo5c6YcHR3l4+MjB4d7/y//tddeU2hoqJYtW6ZVq1Zp3Lhxmjhx4gNdC/xRvaG/HxcvXuQNvUmxBhimVKlSJXXq1CnDJ4Dffvttbd26Vf3799fevXt17Ngx/frrr9YPwVWoUEEhISHq3bu3duzYoT179qh3795ycXGxfiI6ICBAKSkp+vTTT3XixAl98803mjVrls1xSpcurfj4eK1Zs0YXLly44wxEx44dNWvWLEVERKhTp07W9oIFC2rIkCEaNGiQ5s6dq+PHj+u///2vPv30U82dOzfL/kJDQxUZGWkTwDt27ChHR0f17NlTBw8e1MKFCzV16lQNHjzYZt9NmzZZr5ABIG9zc3NTQECASpUqZRN+AwMDM6x9/ffff3XkyBEFBQVZ23x9fdWnTx/99NNPeuuttzR79uxMj5OdN/Tz58/P8g19QECAzc3X1zfLPjN7Q3+vjh8/rsTExDvOMOMxZgAm0LVrV6NVq1Y2bSdPnjQcHR2N238NduzYYTz//PNGgQIFDDc3N6Ny5crGmDFjrNvPnTtnNG3a1HBycjL8/PyMBQsWGF5eXsasWbOsNZMmTTKKFy9uuLi4GKGhoca8efMMScalS5esNX369DGKFCliSDI++OADwzAMw8/Pz5g8ebLNeA4dOmRIMvz8/Iy0tDSbbWlpacaUKVOM8uXLG/nz5zeKFStmhIaGGhs2bMjysUhJSTF8fHyMFStW2LTv27fPqF27tuHk5GSUKFHC+OijjzLsW758eeO7777Lsm8AeUNmr3m3atWqlREUFGRs2rTJ2Lt3r9GkSRMjICDASE5ONgzDMN58801jxYoVxokTJ4zdu3cbNWvWNNq3b28YhmGsW7fO5vVsy5YthiRj9erVxj///GMkJCQYhpH569m7775rBAUFGQ4ODsamTZsybCtSpIgRHh5u/PXXX8bu3buNadOmGeHh4Vmex5IlSwwvLy8jNTXVpv3gwYPGnj17jJYtWxr169c39uzZY+zZs8emZs6cOcYTTzyRZd94vBGAgQd05swZ64v//4rPPvvMaNy48X3t8/vvvxuBgYFGSkrKQxoVgJxytwB88eJFo3PnzoaHh4f1jfrRo0et2/v372+UKVPGcHJyMooVK2Z07tzZuHDhgmEYGQOwYeS9N/R+fn6GpAy3WzVu3NgYN25cln3j8WZnGIaRCxPPwP+stWvXKj4+XpUqVVJ0dLSGDRumv//+W0ePHrX+OS+vS01N1fjx4zVgwACbr0O+kx9++EG+vr42H5wBgNw2ffp0LVmyRCtXrrznfQ4ePKiGDRvq6NGj1m+0g7nwITjgPqWkpOj//u//dOLECRUsWFC1atXS/Pnz/2fCr3TzE9nvvvvufe3Trl27hzQaAMi+//znP7p8+bKuXr16z2/oo6OjNW/ePMKviTEDDAAAAFPhKhAAAAAwFQIwAAAATIUADAAAAFMhAAMAAMBUCMAAAAAwFQIwADwk4eHh8vT0fOB+Tp06JTs7O+3du/eB+8qOsLAweXt7y87OTr/88kuujAEAchIBGACy0K1bN9nZ2cnOzk6Ojo4KCAjQqFGjlJqa+kjH4evrq+joaD355JOSpPXr18vOzk6XL19+6Mc+fPiwRo4cqc8//1zR0dFq2rSpzfawsDDrY5TV7VHq1q2bWrdu/UiPCeB/DwEYAO6gSZMmio6O1rFjx/TWW28pLCxMH3/88SM7fnJysvLlyyeLxSIHh0f/3UXHjx+XJLVq1UoWi0VOTk4224cMGaLo6GjrrWTJkho1apRNGwDkNQRgALgDJycnWSwW+fn5qW/fvgoJCdGSJUskSZcuXVKXLl1UqFAhubq6qmnTpjp27FiWfR0/flytWrWSt7e3ChQooKefflqrV6+2qSldurRGjx6tLl26yN3dXb1797ZZAnHq1Ck1aNBAklSoUCHZ2dmpW7dumjdvnooUKaKkpCSb/lq3bq3OnTtnOaYDBw6oYcOGcnFxUZEiRdS7d2/Fx8dLujm727JlS0mSvb19prO5BQoUkMVisd7y5cunggULymKx6JNPPtFrr71mrZ0yZYrs7Oy0YsUKa1tAQIC+/PJL6/0vv/xSgYGBcnZ2VoUKFTRjxgyb4505c0bt27eXp6enChcurFatWunUqVPW8c6dO1e//vqrdfZ5/fr1WZ47APMiAAPAfXBxcVFycrKkm39u37Vrl5YsWaLIyEgZhqFmzZopJSUl033j4+PVrFkzrVmzRnv27FGTJk3UsmVLRUVF2dR98sknqlKlivbs2aP333/fZpuvr69+/PFHSdKRI0cUHR2tqVOn6qWXXtKNGzes4VySzp8/r2XLlqlHjx6ZjichIUGhoaEqVKiQdu7cqcWLF2v16tXq37+/pJuzu3PmzJGkbM3m1qtXT5s3b9aNGzckSRs2bFDRokWtofTvv//W8ePHVb9+fUnS/PnzNWLECI0ZM0aHDx/W2LFj9f7772vu3LmSbn4NeWhoqAoWLKhNmzZpy5YtKlCggJo0aaLk5GQNGTJE7du3t87aR0dHq1atWvc1ZgAmYQAAMtW1a1ejVatWhmEYRlpamhEREWE4OTkZQ4YMMY4ePWpIMrZs2WKtv3DhguHi4mIsWrTIMAzDmDNnjuHh4XHHY1SsWNH49NNPrff9/PyM1q1b29ScPHnSkGTs2bPHMAzDWLdunSHJuHTpkk1d3759jaZNm1rvT5w40XjiiSeMtLS0TI/9xRdfGIUKFTLi4+OtbcuWLTPs7e2NmJgYwzAM4+effzbu578KPz8/Y/LkyYZhGMalS5cMe3t7Y+fOnUZaWppRuHBhY9y4cUbNmjUNwzCMb7/91ihRooR13zJlyhgLFiyw6W/06NFGcHCwYRiG8c033xjly5e3OZ+kpCTDxcXFWLlypWEYts8ZAGTl0S8oA4D/IUuXLlWBAgWUkpKitLQ0dezYUWFhYVqzZo0cHBxUs2ZNa22RIkVUvnx5HT58ONO+4uPjFRYWpmXLlik6Olqpqam6fv16hhngGjVqZGusvXr10tNPP62///5bJUqUUHh4uPWDfJk5fPiwqlSpIjc3N2vbc889p7S0NB05ckTe3t7ZGkc6T09PValSRevXr5ejo6McHR3Vu3dvffDBB4qPj9eGDRtUr149STdno48fP66ePXuqV69e1j5SU1Pl4eEhSdq3b5/++usvFSxY0OY4iYmJ1rXKAHAvCMAAcAcNGjTQzJkz5ejoKB8fnwf6INqQIUMUERGhTz75RAEBAXJxcVG7du2sSyrS3RpI78dTTz2lKlWqaN68eWrcuLEOHjyoZcuWZXu8OaF+/fpav369nJycVK9ePRUuXFiBgYHavHmzNmzYoLfeekuSrOuOZ8+ebfOmQpLy5ctnralevbrmz5+f4TjFihV7yGcC4HFCAAaAO3Bzc1NAQECG9sDAQKWmpmr79u3Wdab//vuvjhw5oqCgoEz72rJli7p166YXX3xR0s1Al/4Brvvh6OgoSda1tbd67bXXNGXKFP39998KCQmRr69vlv0EBgYqPDxcCQkJ1tC9ZcsW2dvbq3z58vc9rszUq1dPX3/9tRwcHNSkSRNJN0Pxd999p6NHj1rX/3p7e8vHx0cnTpxQp06dMu2rWrVqWrhwoby8vOTu7p5pjaOjY6aPCwDcig/BAUA2lC1bVq1atVKvXr20efNm7du3T6+++qpKlCihVq1aZbnPTz/9pL1792rfvn3q2LGj0tLS7vvYfn5+srOz09KlS/XPP/9YZ08lqWPHjjp79qxmz56d5Yff0nXq1EnOzs7q2rWr/vjjD61bt05vvPGGOnfu/MDLH9LVrVtXV69e1dKlS61ht379+po/f76KFy+ucuXKWWtHjhypcePGadq0aTp69KgOHDigOXPmaNKkSdbxFi1aVK1atdKmTZt08uRJrV+/XgMGDNDZs2cl3byKxv79+3XkyBFduHAhyw8kAjA3AjAAZNOcOXNUvXp1tWjRQsHBwTIMQ7///rvy58+faf2kSZNUqFAh1apVSy1btlRoaKiqVat238ctUaKERo4cqXfeeUfe3t7WqzZIkoeHh9q2basCBQrc9QshXF1dtXLlSl28eFFPP/202rVrp0aNGumzzz677zFlpVChQqpUqZKKFSumChUqSLoZitPS0qzrf9O99tpr+vLLLzVnzhxVqlRJ9erVU3h4uPz9/a3j3bhxo0qVKqU2bdooMDBQPXv2VGJionVGuFevXipfvrxq1KihYsWKacuWLTl2LgAeH3aGYRi5PQgAQM5p1KiRKlasqGnTpuX2UAAgTyIAA8Bj4tKlS1q/fr3atWunQ4cO5dg6XgB43PAhOAB4TDz11FO6dOmSxo8fT/gFgDtgBhgAAACmwofgAAAAYCoEYAAAAJgKARgAAACmQgAGAACAqRCAAQAAYCoEYAAAAJgKARgAAACmQgAGAACAqfx/BaHNxbB8j68AAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Créer un histogramme des valeurs de la colonne 'target' avec des étiquettes spécifiques et le nombre total de valeurs\n",
    "\n",
    "# Compter les occurrences de chaque valeur unique dans 'target' avec les valeurs 0, 1\n",
    "target_counts = df_sample['target'].value_counts().reindex([0, 1], fill_value=0)\n",
    "\n",
    "# Configurer le graphique\n",
    "plt.figure(figsize=(8, 6))\n",
    "bars = plt.bar(['Negative (0)', 'Positive (1)'], target_counts, color='skyblue', edgecolor='black')\n",
    "\n",
    "# Ajouter les annotations (le nombre total au-dessus de chaque colonne)\n",
    "for bar, count in zip(bars, target_counts):\n",
    "    plt.text(bar.get_x() + bar.get_width() / 2, bar.get_height(), f'{count}', ha='center', va='bottom', fontsize=12)\n",
    "\n",
    "# Personnaliser l'apparence du graphique\n",
    "plt.title(\"Distribution des valeurs de la colonne 'target'\")\n",
    "plt.xlabel(\"Polarity of Tweet\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classe de prétraitement et vectorisation des tweets avec différentes méthodes\n",
    "types_of_embeddings = ['w2v', 'fasttext', 'bert', 'use']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classe de prétraitement et vectorisation des tweets avec différentes méthodes\n",
    "class TweetVectorizer:\n",
    "    def __init__(self, vectorizer_type='w2v', method='lemmatize'):\n",
    "        self.vectorizer_type = vectorizer_type\n",
    "        self.method = method\n",
    "        self.stemmer = PorterStemmer()\n",
    "        self.lemmatizer = WordNetLemmatizer()\n",
    "        \n",
    "        # Initialiser le vectorizer en fonction du type\n",
    "        if vectorizer_type == 'w2v':\n",
    "            self.model = None  # Placeholder pour Word2Vec qui sera entraîné explicitement\n",
    "        elif vectorizer_type == 'fasttext':\n",
    "            self.fasttext_model = FastText(vector_size=100, window=5, min_count=1)\n",
    "        elif vectorizer_type == 'bert':\n",
    "            self.tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "            self.model = TFAutoModelForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=2)\n",
    "        elif vectorizer_type == 'use':\n",
    "            self.use_model = hub.load(\"https://tfhub.dev/google/universal-sentence-encoder/4\")\n",
    "        else:\n",
    "            raise ValueError(\"vectorizer_type doit être 'w2v', 'fasttext', 'bert', ou 'use'\")\n",
    "    \n",
    "    def clean_tweet(self, tweet):\n",
    "        tweet = tweet.lower()\n",
    "        tweet = re.sub(r'www\\S+|http\\S+', '', tweet)\n",
    "        tweet = re.sub(r'@\\w+', '', tweet)\n",
    "        tweet = re.sub(r'#\\w+', '', tweet)\n",
    "        tweet = re.sub(r'[^A-Za-z ]+', ' ', tweet)\n",
    "        tweet = re.sub(r'\\s+', ' ', tweet)\n",
    "        return tweet.strip()\n",
    "        \n",
    "    def preprocess(self, tweet):\n",
    "        cleaned_tweet = self.clean_tweet(tweet)\n",
    "        tokens = cleaned_tweet.split()\n",
    "        \n",
    "        # Appliquer le stemming ou la lemmatisation\n",
    "        if self.method == 'stem':\n",
    "            tokens = [self.stemmer.stem(token) for token in tokens]\n",
    "        elif self.method == 'lemmatize':\n",
    "            tokens = [self.lemmatizer.lemmatize(token) for token in tokens]\n",
    "        \n",
    "        return ' '.join(tokens)\n",
    "    \n",
    "    # Méthode `fit_transform` mise à jour dans TweetVectorizer pour vérifier et ajuster la forme\n",
    "    def fit_transform(self, documents):\n",
    "        documents_preprocessed = [self.preprocess(doc) for doc in documents]\n",
    "        \n",
    "        if self.vectorizer_type == 'w2v':\n",
    "            tokenized_docs = [doc.split() for doc in documents_preprocessed]\n",
    "            self.model = Word2Vec(sentences=tokenized_docs, vector_size=100, window=5, min_count=1, workers=4)\n",
    "            X = np.array([np.mean([self.model.wv[word] for word in words if word in self.model.wv] or [np.zeros(100)], axis=0) for words in tokenized_docs])\n",
    "        elif self.vectorizer_type == 'fasttext':\n",
    "            tokenized_docs = [doc.split() for doc in documents_preprocessed]\n",
    "            self.fasttext_model.build_vocab(tokenized_docs)\n",
    "            self.fasttext_model.train(tokenized_docs, total_examples=len(tokenized_docs), epochs=10)\n",
    "            X = np.array([np.mean([self.fasttext_model.wv[word] for word in words if word in self.fasttext_model.wv] or [np.zeros(100)], axis=0) for words in tokenized_docs])\n",
    "        elif self.vectorizer_type == 'bert':\n",
    "            X = self._bert_vectorize(documents_preprocessed)\n",
    "        elif self.vectorizer_type == 'use':\n",
    "            X = self.use_model(documents_preprocessed)\n",
    "            X = np.array(X)\n",
    "        \n",
    "        # Assurer que X est bien en 2D\n",
    "        if X.ndim == 1:\n",
    "            X = X.reshape(-1, 1)\n",
    "        elif X.ndim == 2 and X.shape[1] == 1:\n",
    "            # S'assurer que la deuxième dimension correspond bien à l'embedding dimension\n",
    "            X = X.reshape(-1, X.shape[1])\n",
    "        \n",
    "        return X\n",
    "\n",
    "    def transform(self, documents):\n",
    "        documents_preprocessed = [self.preprocess(doc) for doc in documents]\n",
    "        \n",
    "        if self.vectorizer_type == 'w2v':\n",
    "            tokenized_docs = [doc.split() for doc in documents_preprocessed]\n",
    "            X = np.array([np.mean([self.model.wv[word] for word in words if word in self.model.wv] or [np.zeros(100)], axis=0) for words in tokenized_docs])\n",
    "        elif self.vectorizer_type == 'fasttext':\n",
    "            tokenized_docs = [doc.split() for doc in documents_preprocessed]\n",
    "            X = np.array([np.mean([self.fasttext_model.wv[word] for word in words if word in self.fasttext_model.wv] or [np.zeros(100)], axis=0) for words in tokenized_docs])\n",
    "        elif self.vectorizer_type == 'bert':\n",
    "            X = self._bert_vectorize(documents_preprocessed)\n",
    "        elif self.vectorizer_type == 'use':\n",
    "            X = self.use_model(documents_preprocessed)\n",
    "            X = np.array(X)\n",
    "    \n",
    "        # Assurer que X est bien en 2D\n",
    "        if X.ndim == 1:\n",
    "            X = X.reshape(-1, 1)\n",
    "        elif X.ndim == 2 and X.shape[1] == 1:\n",
    "            X = X.reshape(-1, X.shape[1])\n",
    "        \n",
    "        return X\n",
    "\n",
    "    def _bert_vectorize(self, documents):\n",
    "        batch_size = 16  # Réduction de la taille du batch pour éviter les erreurs OOM\n",
    "        batches = [documents[i:i + batch_size] for i in range(0, len(documents), batch_size)]\n",
    "        \n",
    "        outputs_list = []\n",
    "        for batch in batches:\n",
    "            tokenized_inputs = self.tokenizer(batch, return_tensors='tf', padding=True, truncation=True, max_length=32)\n",
    "            outputs = self.model(tokenized_inputs).logits\n",
    "            outputs_list.append(tf.reduce_mean(outputs, axis=1).numpy())\n",
    "        \n",
    "        return np.concatenate(outputs_list, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classe pour la classification avec régression logistique\n",
    "class TweetClassifier:\n",
    "    def __init__(self):\n",
    "        self.model = LogisticRegression(C=1.0, solver='lbfgs', penalty='l2')\n",
    "\n",
    "    def train_and_evaluate(self, X_train, X_val, y_train, y_val):\n",
    "        # Suivi de l'entraînement du modèle dans MLflow comme sous-exécution\n",
    "        with mlflow.start_run(run_name=\"Classification\", nested=True):\n",
    "            mlflow.set_tag(\"Stage\", \"Classification\")\n",
    "            mlflow.set_tag(\"model\", \"Logistic Regression\")\n",
    "            \n",
    "            # Enregistrer les hyperparamètres du modèle\n",
    "            mlflow.log_param(\"C\", self.model.get_params()['C'])\n",
    "            mlflow.log_param(\"solver\", self.model.get_params()['solver'])\n",
    "            mlflow.log_param(\"penalty\", self.model.get_params()['penalty'])\n",
    "            \n",
    "            # Entraîner le modèle avec Cross-Validation sur le set d'entraînement\n",
    "            cross_val_scores = cross_val_score(self.model, X_train, y_train, cv=5, scoring='accuracy')\n",
    "            mlflow.log_metric(\"cross_val_accuracy_mean\", cross_val_scores.mean())\n",
    "            mlflow.log_metric(\"cross_val_accuracy_std\", cross_val_scores.std())\n",
    "\n",
    "            # Entraîner sur l'ensemble d'entraînement complet\n",
    "            start_time = time.time()\n",
    "            self.model.fit(X_train, y_train)\n",
    "            end_time = time.time()\n",
    "            training_time = end_time - start_time\n",
    "            mlflow.log_metric(\"training_time_seconds\", training_time)\n",
    "            \n",
    "            # Évaluation sur l'ensemble de validation\n",
    "            y_val_pred = self.model.predict(X_val)\n",
    "            val_accuracy = accuracy_score(y_val, y_val_pred)\n",
    "            mlflow.log_metric(\"validation_accuracy\", val_accuracy)\n",
    "            mlflow.log_text(classification_report(y_val, y_val_pred), \"validation_classification_report.txt\")\n",
    "            \n",
    "            # Calcul de la courbe ROC-AUC sur l'ensemble de validation\n",
    "            y_val_prob = self.model.predict_proba(X_val)[:, 1]\n",
    "            fpr, tpr, _ = roc_curve(y_val, y_val_prob)\n",
    "            roc_auc_val = auc(fpr, tpr)\n",
    "            mlflow.log_metric(\"validation_roc_auc\", roc_auc_val)\n",
    "\n",
    "            # Tracer et enregistrer la courbe ROC\n",
    "            plt.figure()\n",
    "            plt.plot(fpr, tpr, label=f\"ROC curve (area = {roc_auc_val:.2f})\")\n",
    "            plt.plot([0, 1], [0, 1], 'k--')\n",
    "            plt.xlabel(\"False Positive Rate\")\n",
    "            plt.ylabel(\"True Positive Rate\")\n",
    "            plt.title(\"ROC Curve - Validation Set\")\n",
    "            plt.legend(loc=\"lower right\")\n",
    "            plt.savefig(\"roc_curve_val.png\")\n",
    "            mlflow.log_artifact(\"roc_curve_val.png\")\n",
    "            plt.close()\n",
    "            \n",
    "            print(f\"Validation Accuracy : {val_accuracy}\")\n",
    "            print(classification_report(y_val, y_val_pred))\n",
    "    \n",
    "    def final_evaluation(self, X_test, y_test):\n",
    "        # Évaluation finale sur le set de test\n",
    "        with mlflow.start_run(run_name=\"Final Test Evaluation\", nested=True):\n",
    "            mlflow.set_tag(\"Stage\", \"Final Test Evaluation\")\n",
    "            y_test_pred = self.model.predict(X_test)\n",
    "            test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "            mlflow.log_metric(\"test_accuracy\", test_accuracy)\n",
    "            mlflow.log_text(classification_report(y_test, y_test_pred), \"test_classification_report.txt\")\n",
    "            \n",
    "            # Calcul de la courbe ROC-AUC sur l'ensemble de test\n",
    "            y_test_prob = self.model.predict_proba(X_test)[:, 1]\n",
    "            fpr, tpr, _ = roc_curve(y_test, y_test_prob)\n",
    "            roc_auc_test = auc(fpr, tpr)\n",
    "            mlflow.log_metric(\"test_roc_auc\", roc_auc_test)\n",
    "\n",
    "            # Tracer et enregistrer la courbe ROC pour le set de test\n",
    "            plt.figure()\n",
    "            plt.plot(fpr, tpr, label=f\"ROC curve (area = {roc_auc_test:.2f})\")\n",
    "            plt.plot([0, 1], [0, 1], 'k--')\n",
    "            plt.xlabel(\"False Positive Rate\")\n",
    "            plt.ylabel(\"True Positive Rate\")\n",
    "            plt.title(\"ROC Curve - Test Set\")\n",
    "            plt.legend(loc=\"lower right\")\n",
    "            plt.savefig(\"roc_curve_test.png\")\n",
    "            mlflow.log_artifact(\"roc_curve_test.png\")\n",
    "            plt.close()\n",
    "            \n",
    "            # Enregistrer le modèle final\n",
    "            mlflow.sklearn.log_model(self.model, \"logistic_regression_model\")\n",
    "            \n",
    "            print(f\"Test Accuracy : {test_accuracy}\")\n",
    "            print(classification_report(y_test, y_test_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Définition des combinaisons à tester\n",
    "configurations = [\n",
    "    {'vectorizer_type': 'w2v', 'method': 'lemmatize'},\n",
    "    {'vectorizer_type': 'w2v', 'method': 'stem'},\n",
    "    {'vectorizer_type': 'fasttext', 'method': 'lemmatize'},\n",
    "    {'vectorizer_type': 'fasttext', 'method': 'stem'},\n",
    "    {'vectorizer_type': 'bert', 'method': 'lemmatize'},\n",
    "    {'vectorizer_type': 'bert', 'method': 'stem'},\n",
    "    {'vectorizer_type': 'use', 'method': 'lemmatize'},\n",
    "    {'vectorizer_type': 'use', 'method': 'stem'}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing configuration: {'vectorizer_type': 'w2v', 'method': 'lemmatize'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/11/05 09:18:50 INFO mlflow.tracking._tracking_service.client: 🏃 View run Classification at: http://mlflow-server:5000/#/experiments/0/runs/c8a7a7ecb4fb459ebdf21b02760a3e72.\n",
      "2024/11/05 09:18:50 INFO mlflow.tracking._tracking_service.client: 🧪 View experiment at: http://mlflow-server:5000/#/experiments/0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy : 0.610625\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.57      0.60      1637\n",
      "           1       0.59      0.65      0.62      1563\n",
      "\n",
      "    accuracy                           0.61      3200\n",
      "   macro avg       0.61      0.61      0.61      3200\n",
      "weighted avg       0.61      0.61      0.61      3200\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/11/05 09:18:51 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2024/11/05 09:18:51 INFO mlflow.tracking._tracking_service.client: 🏃 View run Final Test Evaluation at: http://mlflow-server:5000/#/experiments/0/runs/d317dc077d30411db3065d109bea09a2.\n",
      "2024/11/05 09:18:51 INFO mlflow.tracking._tracking_service.client: 🧪 View experiment at: http://mlflow-server:5000/#/experiments/0.\n",
      "2024/11/05 09:18:51 INFO mlflow.tracking._tracking_service.client: 🏃 View run w2v + lemmatize at: http://mlflow-server:5000/#/experiments/0/runs/7ffb45c3d62d45718b696ccea1f727ac.\n",
      "2024/11/05 09:18:51 INFO mlflow.tracking._tracking_service.client: 🧪 View experiment at: http://mlflow-server:5000/#/experiments/0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy : 0.609375\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.57      0.59      1611\n",
      "           1       0.60      0.65      0.62      1589\n",
      "\n",
      "    accuracy                           0.61      3200\n",
      "   macro avg       0.61      0.61      0.61      3200\n",
      "weighted avg       0.61      0.61      0.61      3200\n",
      "\n",
      "Testing configuration: {'vectorizer_type': 'w2v', 'method': 'stem'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/11/05 09:18:54 INFO mlflow.tracking._tracking_service.client: 🏃 View run Classification at: http://mlflow-server:5000/#/experiments/0/runs/55ded85df61c4a1cae27229550a6195c.\n",
      "2024/11/05 09:18:54 INFO mlflow.tracking._tracking_service.client: 🧪 View experiment at: http://mlflow-server:5000/#/experiments/0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy : 0.61625\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.57      0.60      1637\n",
      "           1       0.60      0.66      0.63      1563\n",
      "\n",
      "    accuracy                           0.62      3200\n",
      "   macro avg       0.62      0.62      0.62      3200\n",
      "weighted avg       0.62      0.62      0.62      3200\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/11/05 09:18:55 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2024/11/05 09:18:56 INFO mlflow.tracking._tracking_service.client: 🏃 View run Final Test Evaluation at: http://mlflow-server:5000/#/experiments/0/runs/7c2a2041ee734302b4ee91d6ae97117c.\n",
      "2024/11/05 09:18:56 INFO mlflow.tracking._tracking_service.client: 🧪 View experiment at: http://mlflow-server:5000/#/experiments/0.\n",
      "2024/11/05 09:18:56 INFO mlflow.tracking._tracking_service.client: 🏃 View run w2v + stem at: http://mlflow-server:5000/#/experiments/0/runs/0a2b0fe53e134c07a9e38a79036a4d7d.\n",
      "2024/11/05 09:18:56 INFO mlflow.tracking._tracking_service.client: 🧪 View experiment at: http://mlflow-server:5000/#/experiments/0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy : 0.6075\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.56      0.59      1611\n",
      "           1       0.59      0.66      0.62      1589\n",
      "\n",
      "    accuracy                           0.61      3200\n",
      "   macro avg       0.61      0.61      0.61      3200\n",
      "weighted avg       0.61      0.61      0.61      3200\n",
      "\n",
      "Testing configuration: {'vectorizer_type': 'fasttext', 'method': 'lemmatize'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/venv/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "2024/11/05 09:19:00 INFO mlflow.tracking._tracking_service.client: 🏃 View run Classification at: http://mlflow-server:5000/#/experiments/0/runs/8a91715c8f58489ab9df39b6db8fee81.\n",
      "2024/11/05 09:19:00 INFO mlflow.tracking._tracking_service.client: 🧪 View experiment at: http://mlflow-server:5000/#/experiments/0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy : 0.643125\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.63      0.64      1637\n",
      "           1       0.63      0.66      0.64      1563\n",
      "\n",
      "    accuracy                           0.64      3200\n",
      "   macro avg       0.64      0.64      0.64      3200\n",
      "weighted avg       0.64      0.64      0.64      3200\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/11/05 09:19:01 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2024/11/05 09:19:01 INFO mlflow.tracking._tracking_service.client: 🏃 View run Final Test Evaluation at: http://mlflow-server:5000/#/experiments/0/runs/08082999aa75415f8e26eeb3d4b2f49e.\n",
      "2024/11/05 09:19:01 INFO mlflow.tracking._tracking_service.client: 🧪 View experiment at: http://mlflow-server:5000/#/experiments/0.\n",
      "2024/11/05 09:19:01 INFO mlflow.tracking._tracking_service.client: 🏃 View run fasttext + lemmatize at: http://mlflow-server:5000/#/experiments/0/runs/45ea4b4adfa94da385b0d3ed0f5825e0.\n",
      "2024/11/05 09:19:01 INFO mlflow.tracking._tracking_service.client: 🧪 View experiment at: http://mlflow-server:5000/#/experiments/0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy : 0.6303125\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.61      0.63      1611\n",
      "           1       0.62      0.65      0.63      1589\n",
      "\n",
      "    accuracy                           0.63      3200\n",
      "   macro avg       0.63      0.63      0.63      3200\n",
      "weighted avg       0.63      0.63      0.63      3200\n",
      "\n",
      "Testing configuration: {'vectorizer_type': 'fasttext', 'method': 'stem'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/venv/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/venv/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "2024/11/05 09:19:07 INFO mlflow.tracking._tracking_service.client: 🏃 View run Classification at: http://mlflow-server:5000/#/experiments/0/runs/33740103b66a4cf6b81b49a53c385f52.\n",
      "2024/11/05 09:19:07 INFO mlflow.tracking._tracking_service.client: 🧪 View experiment at: http://mlflow-server:5000/#/experiments/0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy : 0.64125\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.64      0.64      1637\n",
      "           1       0.63      0.65      0.64      1563\n",
      "\n",
      "    accuracy                           0.64      3200\n",
      "   macro avg       0.64      0.64      0.64      3200\n",
      "weighted avg       0.64      0.64      0.64      3200\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/11/05 09:19:08 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2024/11/05 09:19:08 INFO mlflow.tracking._tracking_service.client: 🏃 View run Final Test Evaluation at: http://mlflow-server:5000/#/experiments/0/runs/74f8322ea56a463bac83375f9235f388.\n",
      "2024/11/05 09:19:08 INFO mlflow.tracking._tracking_service.client: 🧪 View experiment at: http://mlflow-server:5000/#/experiments/0.\n",
      "2024/11/05 09:19:08 INFO mlflow.tracking._tracking_service.client: 🏃 View run fasttext + stem at: http://mlflow-server:5000/#/experiments/0/runs/960600531c3645c59689e0912059ebdd.\n",
      "2024/11/05 09:19:08 INFO mlflow.tracking._tracking_service.client: 🧪 View experiment at: http://mlflow-server:5000/#/experiments/0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy : 0.6359375\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.63      0.63      1611\n",
      "           1       0.63      0.65      0.64      1589\n",
      "\n",
      "    accuracy                           0.64      3200\n",
      "   macro avg       0.64      0.64      0.64      3200\n",
      "weighted avg       0.64      0.64      0.64      3200\n",
      "\n",
      "Testing configuration: {'vectorizer_type': 'bert', 'method': 'lemmatize'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-05 09:19:09.265155: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:152] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)\n",
      "All PyTorch model weights were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some weights or buffers of the TF 2.0 model TFBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "2024/11/05 09:26:54 INFO mlflow.tracking._tracking_service.client: 🏃 View run Classification at: http://mlflow-server:5000/#/experiments/0/runs/d6040dfc64e94fc79b865f8cfe9b5f41.\n",
      "2024/11/05 09:26:54 INFO mlflow.tracking._tracking_service.client: 🧪 View experiment at: http://mlflow-server:5000/#/experiments/0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy : 0.5065625\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.31      0.39      1637\n",
      "           1       0.50      0.71      0.59      1563\n",
      "\n",
      "    accuracy                           0.51      3200\n",
      "   macro avg       0.51      0.51      0.49      3200\n",
      "weighted avg       0.51      0.51      0.49      3200\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/11/05 09:26:55 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2024/11/05 09:26:55 INFO mlflow.tracking._tracking_service.client: 🏃 View run Final Test Evaluation at: http://mlflow-server:5000/#/experiments/0/runs/7bd2fb67c9674e4f8228d03310b8e0ae.\n",
      "2024/11/05 09:26:55 INFO mlflow.tracking._tracking_service.client: 🧪 View experiment at: http://mlflow-server:5000/#/experiments/0.\n",
      "2024/11/05 09:26:55 INFO mlflow.tracking._tracking_service.client: 🏃 View run bert + lemmatize at: http://mlflow-server:5000/#/experiments/0/runs/88637234561242839c2c383d97827ea6.\n",
      "2024/11/05 09:26:55 INFO mlflow.tracking._tracking_service.client: 🧪 View experiment at: http://mlflow-server:5000/#/experiments/0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy : 0.5090625\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      0.30      0.38      1611\n",
      "           1       0.50      0.72      0.59      1589\n",
      "\n",
      "    accuracy                           0.51      3200\n",
      "   macro avg       0.51      0.51      0.49      3200\n",
      "weighted avg       0.51      0.51      0.49      3200\n",
      "\n",
      "Testing configuration: {'vectorizer_type': 'bert', 'method': 'stem'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some weights or buffers of the TF 2.0 model TFBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "2024/11/05 09:34:36 INFO mlflow.tracking._tracking_service.client: 🏃 View run Classification at: http://mlflow-server:5000/#/experiments/0/runs/c033b4bb752f45918599adc2b952e816.\n",
      "2024/11/05 09:34:36 INFO mlflow.tracking._tracking_service.client: 🧪 View experiment at: http://mlflow-server:5000/#/experiments/0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy : 0.5025\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      0.37      0.43      1637\n",
      "           1       0.49      0.65      0.56      1563\n",
      "\n",
      "    accuracy                           0.50      3200\n",
      "   macro avg       0.51      0.51      0.49      3200\n",
      "weighted avg       0.51      0.50      0.49      3200\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/11/05 09:34:38 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2024/11/05 09:34:38 INFO mlflow.tracking._tracking_service.client: 🏃 View run Final Test Evaluation at: http://mlflow-server:5000/#/experiments/0/runs/080a8e76c79e4c808181370d9cb686ed.\n",
      "2024/11/05 09:34:38 INFO mlflow.tracking._tracking_service.client: 🧪 View experiment at: http://mlflow-server:5000/#/experiments/0.\n",
      "2024/11/05 09:34:38 INFO mlflow.tracking._tracking_service.client: 🏃 View run bert + stem at: http://mlflow-server:5000/#/experiments/0/runs/e80f200a822f45faa90f26d01624df7d.\n",
      "2024/11/05 09:34:38 INFO mlflow.tracking._tracking_service.client: 🧪 View experiment at: http://mlflow-server:5000/#/experiments/0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy : 0.4996875\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.38      0.43      1611\n",
      "           1       0.50      0.62      0.55      1589\n",
      "\n",
      "    accuracy                           0.50      3200\n",
      "   macro avg       0.50      0.50      0.49      3200\n",
      "weighted avg       0.50      0.50      0.49      3200\n",
      "\n",
      "Testing configuration: {'vectorizer_type': 'use', 'method': 'lemmatize'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/11/05 09:34:43 INFO mlflow.tracking._tracking_service.client: 🏃 View run Classification at: http://mlflow-server:5000/#/experiments/0/runs/cd5fc205f3954dd88fb729a82e657c26.\n",
      "2024/11/05 09:34:43 INFO mlflow.tracking._tracking_service.client: 🧪 View experiment at: http://mlflow-server:5000/#/experiments/0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy : 0.77125\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.77      0.78      1637\n",
      "           1       0.76      0.77      0.77      1563\n",
      "\n",
      "    accuracy                           0.77      3200\n",
      "   macro avg       0.77      0.77      0.77      3200\n",
      "weighted avg       0.77      0.77      0.77      3200\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/11/05 09:34:45 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2024/11/05 09:34:45 INFO mlflow.tracking._tracking_service.client: 🏃 View run Final Test Evaluation at: http://mlflow-server:5000/#/experiments/0/runs/8c73c5633a074740aa0c5cc2cb47765a.\n",
      "2024/11/05 09:34:45 INFO mlflow.tracking._tracking_service.client: 🧪 View experiment at: http://mlflow-server:5000/#/experiments/0.\n",
      "2024/11/05 09:34:45 INFO mlflow.tracking._tracking_service.client: 🏃 View run use + lemmatize at: http://mlflow-server:5000/#/experiments/0/runs/a7ed952ade9845ae88f825c6611fc7f1.\n",
      "2024/11/05 09:34:45 INFO mlflow.tracking._tracking_service.client: 🧪 View experiment at: http://mlflow-server:5000/#/experiments/0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy : 0.775\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.78      0.78      1611\n",
      "           1       0.77      0.77      0.77      1589\n",
      "\n",
      "    accuracy                           0.78      3200\n",
      "   macro avg       0.77      0.77      0.77      3200\n",
      "weighted avg       0.77      0.78      0.77      3200\n",
      "\n",
      "Testing configuration: {'vectorizer_type': 'use', 'method': 'stem'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/11/05 09:34:51 INFO mlflow.tracking._tracking_service.client: 🏃 View run Classification at: http://mlflow-server:5000/#/experiments/0/runs/edbd700fcab34949b98517fc3be2fdad.\n",
      "2024/11/05 09:34:51 INFO mlflow.tracking._tracking_service.client: 🧪 View experiment at: http://mlflow-server:5000/#/experiments/0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy : 0.750625\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.76      0.76      1637\n",
      "           1       0.75      0.74      0.74      1563\n",
      "\n",
      "    accuracy                           0.75      3200\n",
      "   macro avg       0.75      0.75      0.75      3200\n",
      "weighted avg       0.75      0.75      0.75      3200\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/11/05 09:34:52 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2024/11/05 09:34:52 INFO mlflow.tracking._tracking_service.client: 🏃 View run Final Test Evaluation at: http://mlflow-server:5000/#/experiments/0/runs/eaa75ef7460c4130beeb651d672a86bb.\n",
      "2024/11/05 09:34:52 INFO mlflow.tracking._tracking_service.client: 🧪 View experiment at: http://mlflow-server:5000/#/experiments/0.\n",
      "2024/11/05 09:34:52 INFO mlflow.tracking._tracking_service.client: 🏃 View run use + stem at: http://mlflow-server:5000/#/experiments/0/runs/5b1f0e71557247b9a6a0c7e13d72a3c6.\n",
      "2024/11/05 09:34:52 INFO mlflow.tracking._tracking_service.client: 🧪 View experiment at: http://mlflow-server:5000/#/experiments/0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy : 0.75125\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.76      0.75      1611\n",
      "           1       0.75      0.74      0.75      1589\n",
      "\n",
      "    accuracy                           0.75      3200\n",
      "   macro avg       0.75      0.75      0.75      3200\n",
      "weighted avg       0.75      0.75      0.75      3200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Séparer les données en Train, Validation et Test une seule fois\n",
    "# Utiliser les tweets originaux pour diviser les ensembles de manière cohérente\n",
    "y = df_sample['target']\n",
    "tweets = df_sample['text']\n",
    "y_train_val, y_test = train_test_split(y, test_size=0.2, random_state=42)\n",
    "tweets_train_val, tweets_test = train_test_split(tweets, test_size=0.2, random_state=42)\n",
    "\n",
    "# Rediviser l'ensemble Train + Validation en Train et Validation\n",
    "y_train, y_val = train_test_split(y_train_val, test_size=0.25, random_state=42)\n",
    "tweets_train, tweets_val = train_test_split(tweets_train_val, test_size=0.25, random_state=42)\n",
    "\n",
    "# Boucle pour tester chaque configuration\n",
    "for config in configurations:\n",
    "    # Démarrer une nouvelle exécution parent pour chaque configuration\n",
    "    with mlflow.start_run(run_name=f\"{config['vectorizer_type']} + {config['method']}\", nested=False):\n",
    "        print(f\"Testing configuration: {config}\")\n",
    "        \n",
    "        # Enregistrer les paramètres de configuration comme tags\n",
    "        mlflow.set_tag(\"vectorizer_type\", config['vectorizer_type'])\n",
    "        mlflow.set_tag(\"preprocessing_method\", config['method'])\n",
    "        \n",
    "        # Initialiser et appliquer la vectorisation avec TweetVectorizer\n",
    "        tweet_vectorizer = TweetVectorizer(vectorizer_type=config['vectorizer_type'], method=config['method'])\n",
    "        \n",
    "        # Vectorisation des ensembles Train, Validation et Test\n",
    "        X_train = tweet_vectorizer.fit_transform(tweets_train)\n",
    "        X_val = tweet_vectorizer.transform(tweets_val)\n",
    "        X_test = tweet_vectorizer.transform(tweets_test)\n",
    "        \n",
    "        # Initialiser le classificateur\n",
    "        classifier = TweetClassifier()\n",
    "        \n",
    "        # Entraîner et évaluer le modèle avec Train et Validation\n",
    "        classifier.train_and_evaluate(X_train, X_val, y_train, y_val)\n",
    "\n",
    "        # Évaluation finale sur le set de Test\n",
    "        classifier.final_evaluation(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Embedding, Bidirectional  # Ajout de Bidirectional\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from gensim.models import Word2Vec, FastText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMTweetClassifier:\n",
    "    def __init__(self, embedding_type='w2v', embedding_dim=100, max_length=100):\n",
    "        self.embedding_type = embedding_type\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.max_length = max_length\n",
    "        self.tokenizer = Tokenizer()\n",
    "        self.model = None\n",
    "        self.stop_words = set(stopwords.words('english'))\n",
    "\n",
    "    def clean_tweet(self, tweet):\n",
    "        \"\"\"Nettoie le texte du tweet en supprimant les liens, mentions, hashtags et caractères spéciaux.\"\"\"\n",
    "        tweet = tweet.lower()\n",
    "        tweet = re.sub(r'www\\S+|http\\S+', '', tweet)  # Supprime les liens\n",
    "        tweet = re.sub(r'@\\w+', '', tweet)            # Supprime les mentions\n",
    "        tweet = re.sub(r'#\\w+', '', tweet)            # Supprime les hashtags\n",
    "        tweet = re.sub(r'[^A-Za-z ]+', ' ', tweet)    # Supprime les caractères spéciaux\n",
    "        tweet = re.sub(r'\\s+', ' ', tweet)            # Remplace les multiples espaces par un seul espace\n",
    "        return tweet.strip()\n",
    "\n",
    "    def preprocess_and_tokenize(self, documents):\n",
    "        # Nettoyage et suppression des stopwords\n",
    "        cleaned_docs = []\n",
    "        for doc in documents:\n",
    "            cleaned_doc = self.clean_tweet(doc)\n",
    "            # Supprimer les stopwords après le nettoyage\n",
    "            words = cleaned_doc.split()\n",
    "            filtered_words = [word for word in words if word not in self.stop_words]\n",
    "            cleaned_docs.append(' '.join(filtered_words))\n",
    "        \n",
    "        # Convertir les documents nettoyés en tokens\n",
    "        self.tokenizer.fit_on_texts(cleaned_docs)\n",
    "        sequences = self.tokenizer.texts_to_sequences(cleaned_docs)\n",
    "        padded_sequences = pad_sequences(sequences, maxlen=self.max_length, padding='post')\n",
    "        return padded_sequences\n",
    "\n",
    "    def build_embedding_matrix(self, documents):\n",
    "        word_index = self.tokenizer.word_index\n",
    "        vocab_size = len(word_index) + 1\n",
    "        embedding_matrix = np.zeros((vocab_size, self.embedding_dim))\n",
    "        \n",
    "        # Préparation des phrases pour l'entraînement d'embeddings\n",
    "        sentences = [self.clean_tweet(doc).split() for doc in documents]\n",
    "        \n",
    "        if self.embedding_type == 'w2v':\n",
    "            model = Word2Vec(sentences=sentences, vector_size=self.embedding_dim, window=5, min_count=1, workers=4)\n",
    "        elif self.embedding_type == 'fasttext':\n",
    "            model = FastText(sentences=sentences, vector_size=self.embedding_dim, window=5, min_count=1, workers=4)\n",
    "        else:\n",
    "            raise ValueError(\"embedding_type must be 'w2v' or 'fasttext'\")\n",
    "        \n",
    "        for word, i in word_index.items():\n",
    "            if word in model.wv:\n",
    "                embedding_matrix[i] = model.wv[word]\n",
    "        \n",
    "        return embedding_matrix\n",
    "\n",
    "    def build_model(self, vocab_size, embedding_matrix):\n",
    "        self.model = Sequential()\n",
    "        self.model.add(Embedding(input_dim=vocab_size, output_dim=self.embedding_dim, \n",
    "                                 weights=[embedding_matrix], input_length=self.max_length, trainable=False))\n",
    "        self.model.add(Bidirectional(LSTM(128, return_sequences=False)))\n",
    "        self.model.add(Dense(1, activation='sigmoid'))\n",
    "        self.model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    def train_and_evaluate(self, X_train, y_train, X_val, y_val, epochs=10, batch_size=32):\n",
    "        if self.model is None:\n",
    "            raise RuntimeError(\"Model has not been built. Call build_model() before training.\")\n",
    "        \n",
    "        with mlflow.start_run():\n",
    "            # Enregistrement des hyperparamètres\n",
    "            mlflow.log_param(\"epochs\", epochs)\n",
    "            mlflow.log_param(\"batch_size\", batch_size)\n",
    "            mlflow.log_param(\"embedding_type\", self.embedding_type)\n",
    "            \n",
    "            # Entraînement du modèle\n",
    "            history = self.model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=epochs, batch_size=batch_size)\n",
    "            \n",
    "            # Enregistrement des métriques\n",
    "            for epoch, acc in enumerate(history.history['accuracy']):\n",
    "                mlflow.log_metric(\"train_accuracy\", acc, step=epoch)\n",
    "            for epoch, val_acc in enumerate(history.history['val_accuracy']):\n",
    "                mlflow.log_metric(\"val_accuracy\", val_acc, step=epoch)\n",
    "            \n",
    "            # Enregistrement du modèle\n",
    "            mlflow.keras.log_model(self.model, \"model\")\n",
    "\n",
    "    def fit(self, documents, labels, val_split=0.2, epochs=10, batch_size=32):\n",
    "        # Prétraitement et tokenisation\n",
    "        padded_sequences = self.preprocess_and_tokenize(documents)\n",
    "        vocab_size = len(self.tokenizer.word_index) + 1\n",
    "        embedding_matrix = self.build_embedding_matrix(documents)\n",
    "        \n",
    "        # Construction du modèle LSTM avec embedding Word2Vec ou FastText\n",
    "        self.build_model(vocab_size, embedding_matrix)\n",
    "        \n",
    "        # Division en ensembles d'entraînement et de validation\n",
    "        split_index = int(len(padded_sequences) * (1 - val_split))\n",
    "        X_train, X_val = padded_sequences[:split_index], padded_sequences[split_index:]\n",
    "        y_train, y_val = labels[:split_index], labels[split_index:]\n",
    "        \n",
    "        # Entraînement et évaluation\n",
    "        self.train_and_evaluate(X_train, y_train, X_val, y_val, epochs=epochs, batch_size=batch_size)\n",
    "\n",
    "    def predict(self, documents):\n",
    "        padded_sequences = self.preprocess_and_tokenize(documents)\n",
    "        predictions = self.model.predict(padded_sequences)\n",
    "        return (predictions > 0.5).astype(int).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Définition des combinaisons à tester\n",
    "configurations = [\n",
    "    {\n",
    "        \"embedding_type\": \"w2v\",\n",
    "        \"embedding_dim\": 50,\n",
    "        \"lstm_units\": 64,\n",
    "        \"epochs\": 5,\n",
    "        \"batch_size\": 32\n",
    "    },\n",
    "    {\n",
    "        \"embedding_type\": \"w2v\",\n",
    "        \"embedding_dim\": 100,\n",
    "        \"lstm_units\": 128,\n",
    "        \"epochs\": 10,\n",
    "        \"batch_size\": 32\n",
    "    },\n",
    "    {\n",
    "        \"embedding_type\": \"fasttext\",\n",
    "        \"embedding_dim\": 50,\n",
    "        \"lstm_units\": 64,\n",
    "        \"epochs\": 5,\n",
    "        \"batch_size\": 32\n",
    "    },\n",
    "    {\n",
    "        \"embedding_type\": \"fasttext\",\n",
    "        \"embedding_dim\": 100,\n",
    "        \"lstm_units\": 128,\n",
    "        \"epochs\": 10,\n",
    "        \"batch_size\": 32\n",
    "    },\n",
    "    # Vous pouvez ajouter d'autres configurations ici\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing configuration: {'embedding_type': 'w2v', 'embedding_dim': 50, 'lstm_units': 64, 'epochs': 5, 'batch_size': 32}\n",
      "Epoch 1/5\n",
      "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 41ms/step - accuracy: 0.5525 - loss: 0.6840 - val_accuracy: 0.5975 - val_loss: 0.6856\n",
      "Epoch 2/5\n",
      "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 38ms/step - accuracy: 0.5827 - loss: 0.6735 - val_accuracy: 0.6081 - val_loss: 0.6639\n",
      "Epoch 3/5\n",
      "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 45ms/step - accuracy: 0.6106 - loss: 0.6599 - val_accuracy: 0.6031 - val_loss: 0.6626\n",
      "Epoch 4/5\n",
      "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 40ms/step - accuracy: 0.6157 - loss: 0.6533 - val_accuracy: 0.5919 - val_loss: 0.6693\n",
      "Epoch 5/5\n",
      "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 41ms/step - accuracy: 0.6234 - loss: 0.6470 - val_accuracy: 0.6019 - val_loss: 0.6629\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/11/05 10:18:27 WARNING mlflow.keras.save: You are saving a Keras model without specifying model signature.\n",
      "2024/11/05 10:18:30 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2024/11/05 10:18:30 INFO mlflow.tracking._tracking_service.client: 🏃 View run monumental-mink-456 at: http://mlflow-server:5000/#/experiments/0/runs/8957a71f7be34b4280ea0caec90c6d78.\n",
      "2024/11/05 10:18:30 INFO mlflow.tracking._tracking_service.client: 🧪 View experiment at: http://mlflow-server:5000/#/experiments/0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished testing configuration: {'embedding_type': 'w2v', 'embedding_dim': 50, 'lstm_units': 64, 'epochs': 5, 'batch_size': 32}\n",
      "Testing configuration: {'embedding_type': 'w2v', 'embedding_dim': 100, 'lstm_units': 128, 'epochs': 10, 'batch_size': 32}\n",
      "Epoch 1/10\n",
      "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 44ms/step - accuracy: 0.5496 - loss: 0.6837 - val_accuracy: 0.5938 - val_loss: 0.6717\n",
      "Epoch 2/10\n",
      "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 44ms/step - accuracy: 0.5902 - loss: 0.6686 - val_accuracy: 0.6025 - val_loss: 0.6608\n",
      "Epoch 3/10\n",
      "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 52ms/step - accuracy: 0.6062 - loss: 0.6578 - val_accuracy: 0.5922 - val_loss: 0.6613\n",
      "Epoch 4/10\n",
      "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 46ms/step - accuracy: 0.6146 - loss: 0.6509 - val_accuracy: 0.6125 - val_loss: 0.6584\n",
      "Epoch 5/10\n",
      "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 43ms/step - accuracy: 0.6171 - loss: 0.6500 - val_accuracy: 0.6269 - val_loss: 0.6387\n",
      "Epoch 6/10\n",
      "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 50ms/step - accuracy: 0.6260 - loss: 0.6388 - val_accuracy: 0.6175 - val_loss: 0.6457\n",
      "Epoch 7/10\n",
      "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 58ms/step - accuracy: 0.6261 - loss: 0.6425 - val_accuracy: 0.6388 - val_loss: 0.6306\n",
      "Epoch 8/10\n",
      "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 57ms/step - accuracy: 0.6300 - loss: 0.6344 - val_accuracy: 0.6284 - val_loss: 0.6416\n",
      "Epoch 9/10\n",
      "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 57ms/step - accuracy: 0.6380 - loss: 0.6371 - val_accuracy: 0.6041 - val_loss: 0.6614\n",
      "Epoch 10/10\n",
      "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 55ms/step - accuracy: 0.6286 - loss: 0.6351 - val_accuracy: 0.6494 - val_loss: 0.6223\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/11/05 10:21:56 WARNING mlflow.keras.save: You are saving a Keras model without specifying model signature.\n",
      "2024/11/05 10:21:59 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2024/11/05 10:21:59 INFO mlflow.tracking._tracking_service.client: 🏃 View run traveling-chimp-363 at: http://mlflow-server:5000/#/experiments/0/runs/311fa0d200d949f79050e2a43e3bc11f.\n",
      "2024/11/05 10:21:59 INFO mlflow.tracking._tracking_service.client: 🧪 View experiment at: http://mlflow-server:5000/#/experiments/0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished testing configuration: {'embedding_type': 'w2v', 'embedding_dim': 100, 'lstm_units': 128, 'epochs': 10, 'batch_size': 32}\n",
      "Testing configuration: {'embedding_type': 'fasttext', 'embedding_dim': 50, 'lstm_units': 64, 'epochs': 5, 'batch_size': 32}\n",
      "Epoch 1/5\n",
      "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 53ms/step - accuracy: 0.5259 - loss: 0.6911 - val_accuracy: 0.5288 - val_loss: 0.6917\n",
      "Epoch 2/5\n",
      "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 49ms/step - accuracy: 0.5709 - loss: 0.6789 - val_accuracy: 0.5719 - val_loss: 0.6770\n",
      "Epoch 3/5\n",
      "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 49ms/step - accuracy: 0.5662 - loss: 0.6787 - val_accuracy: 0.5966 - val_loss: 0.6699\n",
      "Epoch 4/5\n",
      "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 56ms/step - accuracy: 0.5867 - loss: 0.6721 - val_accuracy: 0.6078 - val_loss: 0.6657\n",
      "Epoch 5/5\n",
      "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 52ms/step - accuracy: 0.5859 - loss: 0.6692 - val_accuracy: 0.5844 - val_loss: 0.6679\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/11/05 10:23:48 WARNING mlflow.keras.save: You are saving a Keras model without specifying model signature.\n",
      "2024/11/05 10:23:52 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2024/11/05 10:23:52 INFO mlflow.tracking._tracking_service.client: 🏃 View run unruly-fowl-230 at: http://mlflow-server:5000/#/experiments/0/runs/bd64d64e0ef54438b0f504a2fca5771f.\n",
      "2024/11/05 10:23:52 INFO mlflow.tracking._tracking_service.client: 🧪 View experiment at: http://mlflow-server:5000/#/experiments/0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished testing configuration: {'embedding_type': 'fasttext', 'embedding_dim': 50, 'lstm_units': 64, 'epochs': 5, 'batch_size': 32}\n",
      "Testing configuration: {'embedding_type': 'fasttext', 'embedding_dim': 100, 'lstm_units': 128, 'epochs': 10, 'batch_size': 32}\n",
      "Epoch 1/10\n",
      "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 58ms/step - accuracy: 0.5333 - loss: 0.6913 - val_accuracy: 0.5478 - val_loss: 0.6892\n",
      "Epoch 2/10\n",
      "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 50ms/step - accuracy: 0.5703 - loss: 0.6785 - val_accuracy: 0.5612 - val_loss: 0.6826\n",
      "Epoch 3/10\n",
      "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 48ms/step - accuracy: 0.5677 - loss: 0.6762 - val_accuracy: 0.5866 - val_loss: 0.6722\n",
      "Epoch 4/10\n",
      "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 50ms/step - accuracy: 0.5809 - loss: 0.6725 - val_accuracy: 0.5875 - val_loss: 0.6697\n",
      "Epoch 5/10\n",
      "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 46ms/step - accuracy: 0.5906 - loss: 0.6691 - val_accuracy: 0.5909 - val_loss: 0.6670\n",
      "Epoch 6/10\n",
      "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 49ms/step - accuracy: 0.5934 - loss: 0.6655 - val_accuracy: 0.5863 - val_loss: 0.6665\n",
      "Epoch 7/10\n",
      "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 49ms/step - accuracy: 0.5957 - loss: 0.6619 - val_accuracy: 0.6112 - val_loss: 0.6583\n",
      "Epoch 8/10\n",
      "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 47ms/step - accuracy: 0.6050 - loss: 0.6588 - val_accuracy: 0.5934 - val_loss: 0.6615\n",
      "Epoch 9/10\n",
      "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 49ms/step - accuracy: 0.5880 - loss: 0.6606 - val_accuracy: 0.5825 - val_loss: 0.6639\n",
      "Epoch 10/10\n",
      "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 47ms/step - accuracy: 0.6008 - loss: 0.6596 - val_accuracy: 0.6078 - val_loss: 0.6548\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/11/05 10:27:15 WARNING mlflow.keras.save: You are saving a Keras model without specifying model signature.\n",
      "2024/11/05 10:27:18 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2024/11/05 10:27:18 INFO mlflow.tracking._tracking_service.client: 🏃 View run placid-dolphin-898 at: http://mlflow-server:5000/#/experiments/0/runs/1a3f4732bed34232837be43df21f725c.\n",
      "2024/11/05 10:27:18 INFO mlflow.tracking._tracking_service.client: 🧪 View experiment at: http://mlflow-server:5000/#/experiments/0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished testing configuration: {'embedding_type': 'fasttext', 'embedding_dim': 100, 'lstm_units': 128, 'epochs': 10, 'batch_size': 32}\n"
     ]
    }
   ],
   "source": [
    "documents = df_sample['text']\n",
    "labels = df_sample['target']\n",
    "\n",
    "# Boucle sur chaque configuration pour tester\n",
    "for config in configurations:\n",
    "    print(f\"Testing configuration: {config}\")\n",
    "    model = LSTMTweetClassifier(\n",
    "        embedding_type=config[\"embedding_type\"],\n",
    "        embedding_dim=config[\"embedding_dim\"],\n",
    "        max_length=100  # Vous pouvez ajuster cette valeur si nécessaire\n",
    "    )\n",
    "    \n",
    "    # # Préparation des données d'entraînement et de validation\n",
    "    # documents = [...]  # Remplacez par votre liste de tweets\n",
    "    # labels = [...]     # Remplacez par votre liste de labels (0 ou 1)\n",
    "    \n",
    "    # Entraînement du modèle avec la configuration actuelle\n",
    "    model.fit(\n",
    "        documents, \n",
    "        labels, \n",
    "        epochs=config[\"epochs\"], \n",
    "        batch_size=config[\"batch_size\"]\n",
    "    )\n",
    "    \n",
    "    # Ici, vous pouvez ajouter des étapes pour enregistrer ou comparer les résultats, par exemple :\n",
    "    # - Enregistrer les métriques dans un dictionnaire ou un fichier pour une analyse ultérieure\n",
    "    # - Comparer les résultats dans MLFlow\n",
    "    print(f\"Finished testing configuration: {config}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some weights or buffers of the TF 2.0 model TFBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/opt/venv/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:2834: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "200/200 [==============================] - 1812s 9s/step - loss: 0.7233 - accuracy: 0.5113 - val_loss: 0.7004 - val_accuracy: 0.4952\n",
      "Epoch 2/3\n",
      "200/200 [==============================] - 1715s 9s/step - loss: 0.7146 - accuracy: 0.4988 - val_loss: 0.6943 - val_accuracy: 0.5048\n",
      "Epoch 3/3\n",
      "200/200 [==============================] - 1688s 8s/step - loss: 0.7063 - accuracy: 0.5063 - val_loss: 0.7175 - val_accuracy: 0.4952\n",
      "Train Accuracy: 0.5063\n",
      "Validation Accuracy: 0.4952\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer, TFBertForSequenceClassification\n",
    "from tensorflow.keras.losses import SparseCategoricalCrossentropy\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "\n",
    "class SimpleBERTTrainer:\n",
    "    def __init__(self, model_name='bert-base-uncased', max_length=128, learning_rate=2e-5):\n",
    "        self.model_name = model_name\n",
    "        self.max_length = max_length\n",
    "        self.learning_rate = learning_rate\n",
    "        self.tokenizer = BertTokenizer.from_pretrained(model_name)\n",
    "        self.model = TFBertForSequenceClassification.from_pretrained(model_name, num_labels=2)\n",
    "        self.stop_words = set(stopwords.words('english'))\n",
    "\n",
    "    def clean_tweet(self, tweet):\n",
    "        tweet = tweet.lower()\n",
    "        tweet = re.sub(r'www\\S+|http\\S+', '', tweet)  # Supprime les liens\n",
    "        tweet = re.sub(r'@\\w+', '', tweet)            # Supprime les mentions\n",
    "        tweet = re.sub(r'#\\w+', '', tweet)            # Supprime les hashtags\n",
    "        tweet = re.sub(r'[^A-Za-z ]+', ' ', tweet)    # Supprime les caractères spéciaux\n",
    "        tweet = re.sub(r'\\s+', ' ', tweet)            # Remplace les multiples espaces par un seul espace\n",
    "        return tweet.strip()\n",
    "\n",
    "    def preprocess(self, documents):\n",
    "        input_ids = []\n",
    "        attention_masks = []\n",
    "        \n",
    "        for doc in documents:\n",
    "            # Nettoyage et suppression des stopwords\n",
    "            cleaned_doc = self.clean_tweet(doc)\n",
    "            words = cleaned_doc.split()\n",
    "            filtered_words = [word for word in words if word not in self.stop_words]\n",
    "            cleaned_text = ' '.join(filtered_words)\n",
    "            \n",
    "            # Encodage du texte nettoyé\n",
    "            encoded = self.tokenizer.encode_plus(\n",
    "                cleaned_text,\n",
    "                add_special_tokens=True,\n",
    "                max_length=self.max_length,\n",
    "                pad_to_max_length=True,\n",
    "                return_attention_mask=True,\n",
    "                truncation=True\n",
    "            )\n",
    "            input_ids.append(encoded['input_ids'])\n",
    "            attention_masks.append(encoded['attention_mask'])\n",
    "        \n",
    "        input_ids = np.array(input_ids)\n",
    "        attention_masks = np.array(attention_masks)\n",
    "        return input_ids, attention_masks\n",
    "\n",
    "\n",
    "\n",
    "    def train(self, documents, labels, test_size=0.8, epochs=3, batch_size=16):\n",
    "        # Assurez-vous que labels est de type int32\n",
    "        labels = np.array(labels, dtype=np.int32)\n",
    "        \n",
    "        # Prétraitement des données\n",
    "        input_ids, attention_masks = self.preprocess(documents)\n",
    "        \n",
    "        # Division des données en ensemble d'entraînement et de validation\n",
    "        X_train_ids, X_val_ids, X_train_masks, X_val_masks, y_train, y_val = train_test_split(\n",
    "            input_ids, attention_masks, labels, test_size=test_size, random_state=42\n",
    "        )\n",
    "        \n",
    "        # Compilation du modèle avec une fonction de perte explicite\n",
    "        loss_fn = SparseCategoricalCrossentropy(from_logits=True)\n",
    "        self.model.compile(optimizer='adam', loss=loss_fn, metrics=['accuracy'])\n",
    "        \n",
    "        # Entraînement du modèle sans Early Stopping\n",
    "        history = self.model.fit(\n",
    "            [X_train_ids, X_train_masks], y_train,\n",
    "            validation_data=([X_val_ids, X_val_masks], y_val),\n",
    "            epochs=epochs,\n",
    "            batch_size=batch_size\n",
    "        )\n",
    "        \n",
    "        # Affichage des résultats d'entraînement et de validation\n",
    "        train_accuracy = history.history['accuracy'][-1]\n",
    "        val_accuracy = history.history['val_accuracy'][-1]\n",
    "        print(f\"Train Accuracy: {train_accuracy:.4f}\")\n",
    "        print(f\"Validation Accuracy: {val_accuracy:.4f}\")\n",
    "\n",
    "\n",
    "\n",
    "# Utilisation de la classe SimpleBERTTrainer pour entraîner et évaluer BERT\n",
    "# documents = [...]  # Remplacez par la liste de tweets\n",
    "# labels = [...]     # Remplacez par la liste des labels (0 ou 1)\n",
    "documents = df_sample['text']\n",
    "labels = df_sample['target']\n",
    "\n",
    "# Initialisation et entraînement du modèle\n",
    "bert_trainer = SimpleBERTTrainer()\n",
    "bert_trainer.train(documents, labels, epochs=3, batch_size=16)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install transformers==4.10.0\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
